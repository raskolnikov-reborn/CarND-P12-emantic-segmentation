{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "import project_tests as ptests\n",
    "import helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Global variables for paths\n",
    "data_dir = './data'\n",
    "runs_dir = './runs'\n",
    "training_dir = data_dir + '/data_road/training'\n",
    "training_size = len(glob.glob(training_dir + '/calib/*.*'))\n",
    "vgg_dir = data_dir + '/vgg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assertion Successful: TF Version: 1.2.1\n"
     ]
    }
   ],
   "source": [
    "# Check Tensorflow Version\n",
    "from distutils.version import LooseVersion\n",
    "assert LooseVersion(tf.__version__) >= LooseVersion('1.0'), 'Assertion Failed. Tensorflow > 1.0 current version is {}'.format(tf.__version__)\n",
    "\n",
    "# Print version if assertion is successful\n",
    "print('Assertion Successful: TF Version: {}'.format(tf.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default GPU : /gpu:0\n"
     ]
    }
   ],
   "source": [
    "# Check GPU availability\n",
    "from tensorflow import test as tft\n",
    "if not tft.gpu_device_name():\n",
    "  warnings.warn('GPU not found... Please reconsider working with a GPU for training')\n",
    "else:\n",
    "  print('Default GPU : {}'.format(tft.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training constants\n",
    "num_classes_ = 2\n",
    "img_shape_ = (160, 576)\n",
    "\n",
    "epochs_ = 20\n",
    "batch_size_ = 1\n",
    "\n",
    "learning_rate_ = 0.0001\n",
    "dropout_ = 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Place_holders (_ph)\n",
    "label_ph = tf.placeholder(tf.float32, [None, \n",
    "                                       img_shape_[0],\n",
    "                                       img_shape_[1], \n",
    "                                       num_classes_])\n",
    "\n",
    "# Learning Rate\n",
    "learning_rate_ph = tf.placeholder(tf.float32)\n",
    "\n",
    "# keep_prob\n",
    "keep_prob_ph = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize training losses to null\n",
    "all_training_losses = [] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_vgg(sess, vgg_dir):\n",
    "    \"\"\"\n",
    "    Load Pretrained VGG Model\n",
    "    @param sess:  Tf Session\n",
    "    @param vgg_dir: Directory containing vgg \"variables/\" and \"saved_model.pb\"\n",
    "    return: VGG Tensor Tuple(image_input, keep_prob, layer3, layer4, layer7)\n",
    "    \"\"\"\n",
    "    # Load Model with Weights from vgg directory\n",
    "    model = tf.saved_model.loader.load(sess, ['vgg16'], vgg_dir)\n",
    "\n",
    "    # Setup tensors to get from graph ( vgg after loading)\n",
    "    graph = tf.get_default_graph()\n",
    "\n",
    "    # get image input\n",
    "    image_input = graph.get_tensor_by_name('image_input:0')\n",
    "\n",
    "    # get keep probability\n",
    "    keep_prob_ph = graph.get_tensor_by_name('keep_prob:0')\n",
    "\n",
    "    # Get layer outputs\n",
    "    layer_3 = graph.get_tensor_by_name('layer3_out:0')\n",
    "    layer_4 = graph.get_tensor_by_name('layer4_out:0')\n",
    "    layer_7 = graph.get_tensor_by_name('layer7_out:0')\n",
    "\n",
    "    # return as 5D list\n",
    "    return image_input, keep_prob_ph, layer_3, layer_4, layer_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_1x1(layer, layer_name):\n",
    "  \"\"\" convolve layer by (1x1) to preserve spatial information \"\"\"\n",
    "  return tf.layers.conv2d(inputs = layer,\n",
    "                          filters =  num_classes_,\n",
    "                          kernel_size = (1, 1),\n",
    "                          strides = (1, 1),\n",
    "                          name = layer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def deconvolve(layer, k, s, layer_name):\n",
    "  \"\"\" Transpose Convolve/ deconvolve a layer with arguments as params \"\"\"\n",
    "  return tf.layers.conv2d_transpose(inputs = layer,\n",
    "                                    filters = num_classes_,\n",
    "                                    kernel_size = (k, k),\n",
    "                                    strides = (s, s),\n",
    "                                    padding = 'same',\n",
    "                                    name = layer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def layers(vgg_layer_3_out, vgg_layer_4_out, vgg_layer_7_out, num_classes = num_classes_):\n",
    "    \"\"\"\n",
    "    # Create layers for the FCN.\n",
    "    vgg_layer_n_out: TF Tensor for VGG Layer n output\n",
    "    num_classes: Number of classes to classify\n",
    "    return: The Tensor for the last layer of output\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Apply a 1x1 convolution to all argument layers\n",
    "    layer_3x = conv_1x1(layer = vgg_layer_3_out, layer_name = \"layer3conv1x1\")\n",
    "    layer_4x = conv_1x1(layer = vgg_layer_4_out, layer_name = \"layer4conv1x1\")\n",
    "    layer_7x = conv_1x1(layer = vgg_layer_7_out, layer_name = \"layer7conv1x1\")\n",
    "\n",
    "    # Add decoder layers to the network with skip connections\n",
    "    # Deconvolve\n",
    "    decoder_layer_1 = deconvolve(layer = layer_7x, k = 4, s = 2, layer_name = \"decoderlayer1\")\n",
    "    \n",
    "    # Sum (skip connection)\n",
    "    decoder_layer_2 = tf.add(decoder_layer_1, layer_4x, name = \"decoderlayer2\")\n",
    "    \n",
    "    # Deconvolve\n",
    "    decoder_layer_3 = deconvolve(layer = decoder_layer_2, k = 4, s = 2, layer_name = \"decoderlayer3\")\n",
    "\n",
    "    # Sum (skip connection)\n",
    "    decoder_layer_4 = tf.add(decoder_layer_3, layer_3x, name = \"decoderlayer4\")\n",
    "    \n",
    "    # Deconvolve\n",
    "    decoderlayer_output = deconvolve(layer = decoder_layer_4, k = 16, s = 8, layer_name = \"decoderlayer_output\")\n",
    "\n",
    "    return decoderlayer_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def layers_verbose(vgg_layer_3_out, vgg_layer_4_out, vgg_layer7_out, num_classes = num_classes_):\n",
    "\n",
    "    \"\"\"\n",
    "    # Create layers for the FCN.\n",
    "    vgg_layer_n_out: TF Tensor for VGG Layer n output\n",
    "    num_classes: Number of classes to classify\n",
    "    return: List of tensors for all layers\n",
    "    \"\"\"\n",
    "    # Apply a 1x1 convolution to encoder layers\n",
    "    layer3x = conv_1x1(layer = vgg_layer_3_out, layer_name = \"layer3conv1x1\")\n",
    "    layer4x = conv_1x1(layer = vgg_layer_4_out, layer_name = \"layer4conv1x1\")\n",
    "    layer7x = conv_1x1(layer = vgg_layer7_out, layer_name = \"layer7conv1x1\")\n",
    "\n",
    "    # Add decoder layers to the network with skip connections\n",
    "    # Deconvolve\n",
    "    decoder_layer_1 = deconvolve(layer = layer_7x, k = 4, s = 2, layer_name = \"decoderlayer1\")\n",
    "    \n",
    "    # Sum (skip connection)\n",
    "    decoder_layer_2 = tf.add(decoder_layer_1, layer_4x, name = \"decoderlayer2\")\n",
    "    \n",
    "    # Deconvolve\n",
    "    decoder_layer_3 = deconvolve(layer = decoder_layer_2, k = 4, s = 2, layer_name = \"decoderlayer3\")\n",
    "\n",
    "    # Sum (skip connection)\n",
    "    decoder_layer_4 = tf.add(decoder_layer_3, layer3x, name = \"decoderlayer4\")\n",
    "    \n",
    "    # Deconvolve\n",
    "    decoderlayer_output = deconvolve(layer = decoder_layer_4, k = 16, s = 8, layer_name = \"decoderlayer_output\")\n",
    "\n",
    "    # Return all the layers for a more detailed output\n",
    "    return vgg_layer_3_out, vgg_layer_4_out, vgg_layer_7_out, layer3x, layer4x, layer7x, \\\n",
    "         decoder_layer_1, decoder_layer_2, decoder_layer_3, decoder_layer_4, decoderlayer_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def optimize(nn_last_layer, correct_label, learning_rate, num_classes = num_classes_):\n",
    "    \"\"\"\n",
    "    TF loss and optimizer operations.\n",
    "    nn_last_layer: last layer tensor\n",
    "    correct_label: label image placeholder\n",
    "    learning_rate: learning rate placeholder\n",
    "    num_classes: Number of classes to classify\n",
    "    return: logits, train_op, cross_entropy_loss as python list\n",
    "    \"\"\"\n",
    "    # Flatten 4D tensors to 2D\n",
    "    # (pixel,class)\n",
    "    logits = tf.reshape(nn_last_layer, (-1, num_classes))\n",
    "    class_labels = tf.reshape(correct_label, (-1, num_classes))\n",
    "\n",
    "    # The cross_entropy_loss is the cost heuristic\n",
    "    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits = logits,\n",
    "                                                            labels = class_labels)\n",
    "    # use the reduce mean method\n",
    "    cross_entropy_loss = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "    # Use the standard Adam optimizer to minimize loss\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate).minimize(cross_entropy_loss)\n",
    "\n",
    "    # return logits, train_op, cross_entropy_loss as python list\n",
    "    return logits, train_op, cross_entropy_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_nn(sess, epochs, batch_size, get_batches_fn, train_op,\n",
    "             cross_entropy_loss, input_image,\n",
    "             correct_label, keep_prob_ph, learning_rate):\n",
    "    \"\"\"\n",
    "    Train the neural network and provide debug prints during training\n",
    "    Arguments: \n",
    "    sess: TF Session\n",
    "    epochs: Number of epochs\n",
    "    batch_size: Batch size\n",
    "    get_batches_fn: Function to get batches of training data\n",
    "    train_op: training operation\n",
    "    cross_entropy_loss: Loss Tensor\n",
    "    input_image: TF Placeholder for input images\n",
    "    correct_label: TF Placeholder for label images\n",
    "    keep_prob_ph: TF Placeholder for dropout keep probability\n",
    "    learning_rate: TF Placeholder for learning rate\n",
    "    \"\"\"\n",
    "    # For all epochs\n",
    "    for epoch in range(epochs):\n",
    "        #initialize losses and counter\n",
    "        losses, i = [], 0\n",
    "        \n",
    "        # For all images in the batch\n",
    "        for images, labels in get_batches_fn(batch_size_):\n",
    "            \n",
    "            # increment batch counter by 1\n",
    "            i += 1\n",
    "            \n",
    "            # Create the feed by assigining values to placeholders\n",
    "            feed = {input_image: images,\n",
    "                    correct_label: labels,\n",
    "                    keep_prob_ph: dropout_,\n",
    "                    learning_rate: learning_rate_ }\n",
    "\n",
    "            # Run the training op with the created feed\n",
    "            _, partial_loss = sess.run([train_op, cross_entropy_loss], feed_dict = feed)\n",
    "\n",
    "            # display output\n",
    "            print(\"- - - - - >Iteration: \", i, \"----->Partial loss:\", partial_loss)\n",
    "            \n",
    "            # Add to list of losses\n",
    "            losses.append(partial_loss)\n",
    "\n",
    "        # After each batch compute net average loss\n",
    "        training_loss = sum(losses) / len(losses)\n",
    "        \n",
    "        # Add to list of global training losses\n",
    "        all_training_losses.append(training_loss)\n",
    "\n",
    "        # Print Training loss at end of each Epoch\n",
    "        print(\"***************\")\n",
    "        print(\"Epoch: \", epoch + 1, \" of \", epochs_, \"training loss: \", training_loss)\n",
    "        print(\"***************\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_tests():\n",
    "    \"\"\"\n",
    "    Run tests to test whether functions are correctly created\n",
    "    \"\"\"\n",
    "    tests.test_layers(layers)\n",
    "    tests.test_optimize(optimize)\n",
    "    tests.test_for_kitti_dataset(data_dir)\n",
    "    tests.test_train_nn(train_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run():\n",
    "    \n",
    "    print(\"Training data size\", training_size)\n",
    "    \n",
    "    # download vgg model if it doesnt exist\n",
    "    helper.maybe_download_pretrained_vgg(data_dir)\n",
    "    \n",
    "    # use the get batches function from the helper.py provided\n",
    "    get_batches_fn = helper.gen_batch_function(training_dir, img_shape_)\n",
    "    \n",
    "    # Using the default session\n",
    "    with tf.Session() as session:\n",
    "        \n",
    "        # Returns the input dropout and output layers from vgg\n",
    "        image_input, keep_prob_ph, layer_3, layer_4, layer_7 = load_vgg(session, vgg_dir)\n",
    "\n",
    "        # Create the layers and get the output\n",
    "        model_output = layers(layer_3, layer_4, layer_7, num_classes_)\n",
    "\n",
    "        # Get the logits, training op and the loss\n",
    "        logits, train_op, cross_entropy_loss = optimize(model_output, label_ph, learning_rate_ph, num_classes_)\n",
    "\n",
    "        # Initilize all variables\n",
    "        session.run([tf.global_variables_initializer(), tf.local_variables_initializer()])\n",
    "\n",
    "        # Run the training step\n",
    "        train_nn(session, epochs_, batch_size_, get_batches_fn, \n",
    "                 train_op, cross_entropy_loss, image_input,\n",
    "                 label_ph, keep_prob_ph, learning_rate_ph)\n",
    "\n",
    "        # Save inference data\n",
    "        helper.save_inference_samples(runs_dir, data_dir, session, img_shape_, logits, keep_prob_ph, image_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "def network_shapes():\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        # Create a random 3 channel input\n",
    "        x = np.random.randn(1, 160, 576, 3)\n",
    "\n",
    "        # Create inputs, dropout and vgg out layers\n",
    "        image_input, keep_prob_ph, layer_3, layer_4, layer_7 = load_vgg(sess, vgg_dir)\n",
    "        \n",
    "        # Create verbose layers\n",
    "        op = layers_verbose(layer_3, layer_4, layer_7, num_classes_)\n",
    "\n",
    "        # initialize the variables \n",
    "        sess.run([tf.global_variables_initializer(), tf.local_variables_initializer()])\n",
    "\n",
    "        # Run the optimizer\n",
    "        l3, l4, l7, l3x, l4x, l7x, d1, s2, d3, s4, d5 = sess.run(op, feed_dict = {image_input: x, keep_prob_ph: 1.0})\n",
    "\n",
    "        print(\"------------------\")\n",
    "        print(\"shapes of layers:\") \n",
    "        print(\"------------------\")\n",
    "\n",
    "        print(\"layer3 -->\", l3.shape)\n",
    "        print(\"layer4 -->\", l4.shape)\n",
    "        print(\"layer7 -->\", l7.shape)\n",
    "        print(\"layer3 conv1x1 -->\", l3x.shape)\n",
    "        print(\"layer4 conv1x1 -->\", l4x.shape)\n",
    "        print(\"layer7 conv1x1-->\", l7x.shape)\n",
    "        print(\"decoderlayer1 transpose: layer7 k = 4 s = 2 -->\", d1.shape)\n",
    "        print(\"decoderlayer2 skip: decoderlayer1 and layer4conv1x1 -->\", s2.shape)\n",
    "        print(\"decoderlayer3 transpose: decoderlayer2 k = 4 s = 2 -->\", d3.shape)\n",
    "        print(\"decoderlayer4 skip: decoderlayer3 and layer3conv1x1 -->\", s4.shape)\n",
    "        print(\"decoderlayer5 transpose: decoderlayer4 k = 16 s = 8 -->\", d5.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size 289\n",
      "INFO:tensorflow:Restoring parameters from b'./data/vgg/variables/variables'\n",
      "- - - - - >Iteration:  1 ----->Partial loss: 73.7186\n",
      "- - - - - >Iteration:  2 ----->Partial loss: 57.7373\n",
      "- - - - - >Iteration:  3 ----->Partial loss: 37.2718\n",
      "- - - - - >Iteration:  4 ----->Partial loss: 37.1428\n",
      "- - - - - >Iteration:  5 ----->Partial loss: 25.4312\n",
      "- - - - - >Iteration:  6 ----->Partial loss: 20.9919\n",
      "- - - - - >Iteration:  7 ----->Partial loss: 19.5452\n",
      "- - - - - >Iteration:  8 ----->Partial loss: 20.5204\n",
      "- - - - - >Iteration:  9 ----->Partial loss: 19.028\n",
      "- - - - - >Iteration:  10 ----->Partial loss: 12.4205\n",
      "- - - - - >Iteration:  11 ----->Partial loss: 12.2238\n",
      "- - - - - >Iteration:  12 ----->Partial loss: 11.8303\n",
      "- - - - - >Iteration:  13 ----->Partial loss: 8.89572\n",
      "- - - - - >Iteration:  14 ----->Partial loss: 8.93831\n",
      "- - - - - >Iteration:  15 ----->Partial loss: 9.00388\n",
      "- - - - - >Iteration:  16 ----->Partial loss: 8.04923\n",
      "- - - - - >Iteration:  17 ----->Partial loss: 6.54868\n",
      "- - - - - >Iteration:  18 ----->Partial loss: 8.37412\n",
      "- - - - - >Iteration:  19 ----->Partial loss: 6.20592\n",
      "- - - - - >Iteration:  20 ----->Partial loss: 5.48602\n",
      "- - - - - >Iteration:  21 ----->Partial loss: 7.3849\n",
      "- - - - - >Iteration:  22 ----->Partial loss: 4.29455\n",
      "- - - - - >Iteration:  23 ----->Partial loss: 4.54346\n",
      "- - - - - >Iteration:  24 ----->Partial loss: 4.9022\n",
      "- - - - - >Iteration:  25 ----->Partial loss: 4.96658\n",
      "- - - - - >Iteration:  26 ----->Partial loss: 4.05344\n",
      "- - - - - >Iteration:  27 ----->Partial loss: 3.70896\n",
      "- - - - - >Iteration:  28 ----->Partial loss: 4.73101\n",
      "- - - - - >Iteration:  29 ----->Partial loss: 3.72086\n",
      "- - - - - >Iteration:  30 ----->Partial loss: 4.27898\n",
      "- - - - - >Iteration:  31 ----->Partial loss: 3.0783\n",
      "- - - - - >Iteration:  32 ----->Partial loss: 3.54434\n",
      "- - - - - >Iteration:  33 ----->Partial loss: 3.74642\n",
      "- - - - - >Iteration:  34 ----->Partial loss: 3.6282\n",
      "- - - - - >Iteration:  35 ----->Partial loss: 2.9497\n",
      "- - - - - >Iteration:  36 ----->Partial loss: 2.89976\n",
      "- - - - - >Iteration:  37 ----->Partial loss: 2.48558\n",
      "- - - - - >Iteration:  38 ----->Partial loss: 2.53819\n",
      "- - - - - >Iteration:  39 ----->Partial loss: 2.63873\n",
      "- - - - - >Iteration:  40 ----->Partial loss: 2.1355\n",
      "- - - - - >Iteration:  41 ----->Partial loss: 2.04954\n",
      "- - - - - >Iteration:  42 ----->Partial loss: 2.27062\n",
      "- - - - - >Iteration:  43 ----->Partial loss: 2.25229\n",
      "- - - - - >Iteration:  44 ----->Partial loss: 2.56606\n",
      "- - - - - >Iteration:  45 ----->Partial loss: 2.36156\n",
      "- - - - - >Iteration:  46 ----->Partial loss: 2.43705\n",
      "- - - - - >Iteration:  47 ----->Partial loss: 1.84995\n",
      "- - - - - >Iteration:  48 ----->Partial loss: 2.13399\n",
      "- - - - - >Iteration:  49 ----->Partial loss: 1.64197\n",
      "- - - - - >Iteration:  50 ----->Partial loss: 1.74306\n",
      "- - - - - >Iteration:  51 ----->Partial loss: 2.20258\n",
      "- - - - - >Iteration:  52 ----->Partial loss: 1.69791\n",
      "- - - - - >Iteration:  53 ----->Partial loss: 1.5119\n",
      "- - - - - >Iteration:  54 ----->Partial loss: 1.87451\n",
      "- - - - - >Iteration:  55 ----->Partial loss: 1.89\n",
      "- - - - - >Iteration:  56 ----->Partial loss: 1.64612\n",
      "- - - - - >Iteration:  57 ----->Partial loss: 1.50679\n",
      "- - - - - >Iteration:  58 ----->Partial loss: 1.67679\n",
      "- - - - - >Iteration:  59 ----->Partial loss: 1.45582\n",
      "- - - - - >Iteration:  60 ----->Partial loss: 1.44167\n",
      "- - - - - >Iteration:  61 ----->Partial loss: 1.43871\n",
      "- - - - - >Iteration:  62 ----->Partial loss: 1.65755\n",
      "- - - - - >Iteration:  63 ----->Partial loss: 1.27936\n",
      "- - - - - >Iteration:  64 ----->Partial loss: 1.38201\n",
      "- - - - - >Iteration:  65 ----->Partial loss: 1.30222\n",
      "- - - - - >Iteration:  66 ----->Partial loss: 1.47326\n",
      "- - - - - >Iteration:  67 ----->Partial loss: 1.63721\n",
      "- - - - - >Iteration:  68 ----->Partial loss: 1.55563\n",
      "- - - - - >Iteration:  69 ----->Partial loss: 1.38662\n",
      "- - - - - >Iteration:  70 ----->Partial loss: 1.26993\n",
      "- - - - - >Iteration:  71 ----->Partial loss: 1.26852\n",
      "- - - - - >Iteration:  72 ----->Partial loss: 1.15184\n",
      "- - - - - >Iteration:  73 ----->Partial loss: 1.96096\n",
      "- - - - - >Iteration:  74 ----->Partial loss: 1.40377\n",
      "- - - - - >Iteration:  75 ----->Partial loss: 1.25965\n",
      "- - - - - >Iteration:  76 ----->Partial loss: 1.20109\n",
      "- - - - - >Iteration:  77 ----->Partial loss: 1.27377\n",
      "- - - - - >Iteration:  78 ----->Partial loss: 1.3558\n",
      "- - - - - >Iteration:  79 ----->Partial loss: 1.11765\n",
      "- - - - - >Iteration:  80 ----->Partial loss: 1.29342\n",
      "- - - - - >Iteration:  81 ----->Partial loss: 1.11167\n",
      "- - - - - >Iteration:  82 ----->Partial loss: 1.25749\n",
      "- - - - - >Iteration:  83 ----->Partial loss: 1.41683\n",
      "- - - - - >Iteration:  84 ----->Partial loss: 1.18728\n",
      "- - - - - >Iteration:  85 ----->Partial loss: 1.09904\n",
      "- - - - - >Iteration:  86 ----->Partial loss: 1.20378\n",
      "- - - - - >Iteration:  87 ----->Partial loss: 1.08511\n",
      "- - - - - >Iteration:  88 ----->Partial loss: 1.17866\n",
      "- - - - - >Iteration:  89 ----->Partial loss: 0.942598\n",
      "- - - - - >Iteration:  90 ----->Partial loss: 1.03747\n",
      "- - - - - >Iteration:  91 ----->Partial loss: 1.21348\n",
      "- - - - - >Iteration:  92 ----->Partial loss: 1.13513\n",
      "- - - - - >Iteration:  93 ----->Partial loss: 0.881137\n",
      "- - - - - >Iteration:  94 ----->Partial loss: 1.10003\n",
      "- - - - - >Iteration:  95 ----->Partial loss: 1.08624\n",
      "- - - - - >Iteration:  96 ----->Partial loss: 1.06208\n",
      "- - - - - >Iteration:  97 ----->Partial loss: 1.03585\n",
      "- - - - - >Iteration:  98 ----->Partial loss: 0.971194\n",
      "- - - - - >Iteration:  99 ----->Partial loss: 0.973419\n",
      "- - - - - >Iteration:  100 ----->Partial loss: 0.947594\n",
      "- - - - - >Iteration:  101 ----->Partial loss: 0.999861\n",
      "- - - - - >Iteration:  102 ----->Partial loss: 0.916615\n",
      "- - - - - >Iteration:  103 ----->Partial loss: 1.08759\n",
      "- - - - - >Iteration:  104 ----->Partial loss: 1.00473\n",
      "- - - - - >Iteration:  105 ----->Partial loss: 0.948838\n",
      "- - - - - >Iteration:  106 ----->Partial loss: 1.08748\n",
      "- - - - - >Iteration:  107 ----->Partial loss: 1.20457\n",
      "- - - - - >Iteration:  108 ----->Partial loss: 0.958453\n",
      "- - - - - >Iteration:  109 ----->Partial loss: 1.072\n",
      "- - - - - >Iteration:  110 ----->Partial loss: 0.877123\n",
      "- - - - - >Iteration:  111 ----->Partial loss: 0.976716\n",
      "- - - - - >Iteration:  112 ----->Partial loss: 0.930666\n",
      "- - - - - >Iteration:  113 ----->Partial loss: 0.852715\n",
      "- - - - - >Iteration:  114 ----->Partial loss: 0.974574\n",
      "- - - - - >Iteration:  115 ----->Partial loss: 0.991107\n",
      "- - - - - >Iteration:  116 ----->Partial loss: 1.01168\n",
      "- - - - - >Iteration:  117 ----->Partial loss: 0.937607\n",
      "- - - - - >Iteration:  118 ----->Partial loss: 0.924363\n",
      "- - - - - >Iteration:  119 ----->Partial loss: 0.922552\n",
      "- - - - - >Iteration:  120 ----->Partial loss: 0.892727\n",
      "- - - - - >Iteration:  121 ----->Partial loss: 0.937979\n",
      "- - - - - >Iteration:  122 ----->Partial loss: 1.04513\n",
      "- - - - - >Iteration:  123 ----->Partial loss: 0.856269\n",
      "- - - - - >Iteration:  124 ----->Partial loss: 0.930102\n",
      "- - - - - >Iteration:  125 ----->Partial loss: 0.869341\n",
      "- - - - - >Iteration:  126 ----->Partial loss: 0.960571\n",
      "- - - - - >Iteration:  127 ----->Partial loss: 0.878027\n",
      "- - - - - >Iteration:  128 ----->Partial loss: 0.861136\n",
      "- - - - - >Iteration:  129 ----->Partial loss: 0.832647\n",
      "- - - - - >Iteration:  130 ----->Partial loss: 0.85401\n",
      "- - - - - >Iteration:  131 ----->Partial loss: 0.820226\n",
      "- - - - - >Iteration:  132 ----->Partial loss: 0.837174\n",
      "- - - - - >Iteration:  133 ----->Partial loss: 0.863565\n",
      "- - - - - >Iteration:  134 ----->Partial loss: 0.971419\n",
      "- - - - - >Iteration:  135 ----->Partial loss: 0.829497\n",
      "- - - - - >Iteration:  136 ----->Partial loss: 0.983993\n",
      "- - - - - >Iteration:  137 ----->Partial loss: 0.912013\n",
      "- - - - - >Iteration:  138 ----->Partial loss: 0.856389\n",
      "- - - - - >Iteration:  139 ----->Partial loss: 0.811794\n",
      "- - - - - >Iteration:  140 ----->Partial loss: 0.805728\n",
      "- - - - - >Iteration:  141 ----->Partial loss: 0.828732\n",
      "- - - - - >Iteration:  142 ----->Partial loss: 0.851708\n",
      "- - - - - >Iteration:  143 ----->Partial loss: 0.938343\n",
      "- - - - - >Iteration:  144 ----->Partial loss: 0.842832\n",
      "- - - - - >Iteration:  145 ----->Partial loss: 0.843886\n",
      "- - - - - >Iteration:  146 ----->Partial loss: 0.807612\n",
      "- - - - - >Iteration:  147 ----->Partial loss: 0.824133\n",
      "- - - - - >Iteration:  148 ----->Partial loss: 0.820448\n",
      "- - - - - >Iteration:  149 ----->Partial loss: 0.845998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- - - - - >Iteration:  150 ----->Partial loss: 0.845993\n",
      "- - - - - >Iteration:  151 ----->Partial loss: 0.81113\n",
      "- - - - - >Iteration:  152 ----->Partial loss: 0.807778\n",
      "- - - - - >Iteration:  153 ----->Partial loss: 0.851702\n",
      "- - - - - >Iteration:  154 ----->Partial loss: 0.867429\n",
      "- - - - - >Iteration:  155 ----->Partial loss: 0.800666\n",
      "- - - - - >Iteration:  156 ----->Partial loss: 0.809482\n",
      "- - - - - >Iteration:  157 ----->Partial loss: 0.806437\n",
      "- - - - - >Iteration:  158 ----->Partial loss: 0.807842\n",
      "- - - - - >Iteration:  159 ----->Partial loss: 0.802028\n",
      "- - - - - >Iteration:  160 ----->Partial loss: 0.795434\n",
      "- - - - - >Iteration:  161 ----->Partial loss: 0.882614\n",
      "- - - - - >Iteration:  162 ----->Partial loss: 0.766775\n",
      "- - - - - >Iteration:  163 ----->Partial loss: 0.781632\n",
      "- - - - - >Iteration:  164 ----->Partial loss: 0.861302\n",
      "- - - - - >Iteration:  165 ----->Partial loss: 0.789031\n",
      "- - - - - >Iteration:  166 ----->Partial loss: 0.822652\n",
      "- - - - - >Iteration:  167 ----->Partial loss: 0.832382\n",
      "- - - - - >Iteration:  168 ----->Partial loss: 0.789969\n",
      "- - - - - >Iteration:  169 ----->Partial loss: 0.807689\n",
      "- - - - - >Iteration:  170 ----->Partial loss: 0.875207\n",
      "- - - - - >Iteration:  171 ----->Partial loss: 0.799542\n",
      "- - - - - >Iteration:  172 ----->Partial loss: 0.846164\n",
      "- - - - - >Iteration:  173 ----->Partial loss: 0.865304\n",
      "- - - - - >Iteration:  174 ----->Partial loss: 0.76092\n",
      "- - - - - >Iteration:  175 ----->Partial loss: 0.802007\n",
      "- - - - - >Iteration:  176 ----->Partial loss: 0.842533\n",
      "- - - - - >Iteration:  177 ----->Partial loss: 0.811826\n",
      "- - - - - >Iteration:  178 ----->Partial loss: 0.803468\n",
      "- - - - - >Iteration:  179 ----->Partial loss: 0.790091\n",
      "- - - - - >Iteration:  180 ----->Partial loss: 0.774354\n",
      "- - - - - >Iteration:  181 ----->Partial loss: 0.799914\n",
      "- - - - - >Iteration:  182 ----->Partial loss: 0.757683\n",
      "- - - - - >Iteration:  183 ----->Partial loss: 0.785298\n",
      "- - - - - >Iteration:  184 ----->Partial loss: 0.770404\n",
      "- - - - - >Iteration:  185 ----->Partial loss: 0.763758\n",
      "- - - - - >Iteration:  186 ----->Partial loss: 0.763524\n",
      "- - - - - >Iteration:  187 ----->Partial loss: 0.82653\n",
      "- - - - - >Iteration:  188 ----->Partial loss: 0.773483\n",
      "- - - - - >Iteration:  189 ----->Partial loss: 0.818976\n",
      "- - - - - >Iteration:  190 ----->Partial loss: 0.743057\n",
      "- - - - - >Iteration:  191 ----->Partial loss: 0.751998\n",
      "- - - - - >Iteration:  192 ----->Partial loss: 0.819043\n",
      "- - - - - >Iteration:  193 ----->Partial loss: 0.860842\n",
      "- - - - - >Iteration:  194 ----->Partial loss: 0.810433\n",
      "- - - - - >Iteration:  195 ----->Partial loss: 0.751885\n",
      "- - - - - >Iteration:  196 ----->Partial loss: 0.737335\n",
      "- - - - - >Iteration:  197 ----->Partial loss: 0.784235\n",
      "- - - - - >Iteration:  198 ----->Partial loss: 0.762445\n",
      "- - - - - >Iteration:  199 ----->Partial loss: 0.809511\n",
      "- - - - - >Iteration:  200 ----->Partial loss: 0.722751\n",
      "- - - - - >Iteration:  201 ----->Partial loss: 0.742875\n",
      "- - - - - >Iteration:  202 ----->Partial loss: 0.759057\n",
      "- - - - - >Iteration:  203 ----->Partial loss: 0.799484\n",
      "- - - - - >Iteration:  204 ----->Partial loss: 0.771714\n",
      "- - - - - >Iteration:  205 ----->Partial loss: 0.756065\n",
      "- - - - - >Iteration:  206 ----->Partial loss: 0.744614\n",
      "- - - - - >Iteration:  207 ----->Partial loss: 0.83871\n",
      "- - - - - >Iteration:  208 ----->Partial loss: 0.737797\n",
      "- - - - - >Iteration:  209 ----->Partial loss: 0.795289\n",
      "- - - - - >Iteration:  210 ----->Partial loss: 0.742792\n",
      "- - - - - >Iteration:  211 ----->Partial loss: 0.743391\n",
      "- - - - - >Iteration:  212 ----->Partial loss: 0.748316\n",
      "- - - - - >Iteration:  213 ----->Partial loss: 0.741473\n",
      "- - - - - >Iteration:  214 ----->Partial loss: 0.772348\n",
      "- - - - - >Iteration:  215 ----->Partial loss: 0.785852\n",
      "- - - - - >Iteration:  216 ----->Partial loss: 0.766206\n",
      "- - - - - >Iteration:  217 ----->Partial loss: 0.832396\n",
      "- - - - - >Iteration:  218 ----->Partial loss: 0.750256\n",
      "- - - - - >Iteration:  219 ----->Partial loss: 0.770105\n",
      "- - - - - >Iteration:  220 ----->Partial loss: 0.733925\n",
      "- - - - - >Iteration:  221 ----->Partial loss: 0.774557\n",
      "- - - - - >Iteration:  222 ----->Partial loss: 0.737452\n",
      "- - - - - >Iteration:  223 ----->Partial loss: 0.756556\n",
      "- - - - - >Iteration:  224 ----->Partial loss: 0.745178\n",
      "- - - - - >Iteration:  225 ----->Partial loss: 0.772669\n",
      "- - - - - >Iteration:  226 ----->Partial loss: 0.799089\n",
      "- - - - - >Iteration:  227 ----->Partial loss: 0.80167\n",
      "- - - - - >Iteration:  228 ----->Partial loss: 0.734227\n",
      "- - - - - >Iteration:  229 ----->Partial loss: 0.738033\n",
      "- - - - - >Iteration:  230 ----->Partial loss: 0.734915\n",
      "- - - - - >Iteration:  231 ----->Partial loss: 0.731039\n",
      "- - - - - >Iteration:  232 ----->Partial loss: 0.723008\n",
      "- - - - - >Iteration:  233 ----->Partial loss: 0.727337\n",
      "- - - - - >Iteration:  234 ----->Partial loss: 0.721627\n",
      "- - - - - >Iteration:  235 ----->Partial loss: 0.774986\n",
      "- - - - - >Iteration:  236 ----->Partial loss: 0.73181\n",
      "- - - - - >Iteration:  237 ----->Partial loss: 0.73256\n",
      "- - - - - >Iteration:  238 ----->Partial loss: 0.763763\n",
      "- - - - - >Iteration:  239 ----->Partial loss: 0.749845\n",
      "- - - - - >Iteration:  240 ----->Partial loss: 0.718131\n",
      "- - - - - >Iteration:  241 ----->Partial loss: 0.755828\n",
      "- - - - - >Iteration:  242 ----->Partial loss: 0.745243\n",
      "- - - - - >Iteration:  243 ----->Partial loss: 0.745034\n",
      "- - - - - >Iteration:  244 ----->Partial loss: 0.769842\n",
      "- - - - - >Iteration:  245 ----->Partial loss: 0.733371\n",
      "- - - - - >Iteration:  246 ----->Partial loss: 0.724379\n",
      "- - - - - >Iteration:  247 ----->Partial loss: 0.75406\n",
      "- - - - - >Iteration:  248 ----->Partial loss: 0.745919\n",
      "- - - - - >Iteration:  249 ----->Partial loss: 0.727631\n",
      "- - - - - >Iteration:  250 ----->Partial loss: 0.719986\n",
      "- - - - - >Iteration:  251 ----->Partial loss: 0.705568\n",
      "- - - - - >Iteration:  252 ----->Partial loss: 0.723943\n",
      "- - - - - >Iteration:  253 ----->Partial loss: 0.745363\n",
      "- - - - - >Iteration:  254 ----->Partial loss: 0.723283\n",
      "- - - - - >Iteration:  255 ----->Partial loss: 0.723217\n",
      "- - - - - >Iteration:  256 ----->Partial loss: 0.741986\n",
      "- - - - - >Iteration:  257 ----->Partial loss: 0.725687\n",
      "- - - - - >Iteration:  258 ----->Partial loss: 0.738636\n",
      "- - - - - >Iteration:  259 ----->Partial loss: 0.745829\n",
      "- - - - - >Iteration:  260 ----->Partial loss: 0.742782\n",
      "- - - - - >Iteration:  261 ----->Partial loss: 0.725975\n",
      "- - - - - >Iteration:  262 ----->Partial loss: 0.749756\n",
      "- - - - - >Iteration:  263 ----->Partial loss: 0.734516\n",
      "- - - - - >Iteration:  264 ----->Partial loss: 0.73802\n",
      "- - - - - >Iteration:  265 ----->Partial loss: 0.756983\n",
      "- - - - - >Iteration:  266 ----->Partial loss: 0.742887\n",
      "- - - - - >Iteration:  267 ----->Partial loss: 0.708889\n",
      "- - - - - >Iteration:  268 ----->Partial loss: 0.705549\n",
      "- - - - - >Iteration:  269 ----->Partial loss: 0.740409\n",
      "- - - - - >Iteration:  270 ----->Partial loss: 0.710109\n",
      "- - - - - >Iteration:  271 ----->Partial loss: 0.728936\n",
      "- - - - - >Iteration:  272 ----->Partial loss: 0.721835\n",
      "- - - - - >Iteration:  273 ----->Partial loss: 0.723326\n",
      "- - - - - >Iteration:  274 ----->Partial loss: 0.714392\n",
      "- - - - - >Iteration:  275 ----->Partial loss: 0.705751\n",
      "- - - - - >Iteration:  276 ----->Partial loss: 0.719303\n",
      "- - - - - >Iteration:  277 ----->Partial loss: 0.71132\n",
      "- - - - - >Iteration:  278 ----->Partial loss: 0.730007\n",
      "- - - - - >Iteration:  279 ----->Partial loss: 0.713833\n",
      "- - - - - >Iteration:  280 ----->Partial loss: 0.729562\n",
      "- - - - - >Iteration:  281 ----->Partial loss: 0.716083\n",
      "- - - - - >Iteration:  282 ----->Partial loss: 0.726385\n",
      "- - - - - >Iteration:  283 ----->Partial loss: 0.700168\n",
      "- - - - - >Iteration:  284 ----->Partial loss: 0.711265\n",
      "- - - - - >Iteration:  285 ----->Partial loss: 0.763436\n",
      "- - - - - >Iteration:  286 ----->Partial loss: 0.748271\n",
      "- - - - - >Iteration:  287 ----->Partial loss: 0.724931\n",
      "- - - - - >Iteration:  288 ----->Partial loss: 0.716098\n",
      "- - - - - >Iteration:  289 ----->Partial loss: 0.713618\n",
      "***************\n",
      "Epoch:  1  of  20 training loss:  2.50964019063\n",
      "***************\n",
      "- - - - - >Iteration:  1 ----->Partial loss: 0.722365\n",
      "- - - - - >Iteration:  2 ----->Partial loss: 0.741452\n",
      "- - - - - >Iteration:  3 ----->Partial loss: 0.70848\n",
      "- - - - - >Iteration:  4 ----->Partial loss: 0.703724\n",
      "- - - - - >Iteration:  5 ----->Partial loss: 0.708867\n",
      "- - - - - >Iteration:  6 ----->Partial loss: 0.714437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- - - - - >Iteration:  7 ----->Partial loss: 0.700492\n",
      "- - - - - >Iteration:  8 ----->Partial loss: 0.727271\n",
      "- - - - - >Iteration:  9 ----->Partial loss: 0.734071\n",
      "- - - - - >Iteration:  10 ----->Partial loss: 0.724164\n",
      "- - - - - >Iteration:  11 ----->Partial loss: 0.729724\n",
      "- - - - - >Iteration:  12 ----->Partial loss: 0.707706\n",
      "- - - - - >Iteration:  13 ----->Partial loss: 0.715585\n",
      "- - - - - >Iteration:  14 ----->Partial loss: 0.707698\n",
      "- - - - - >Iteration:  15 ----->Partial loss: 0.724249\n",
      "- - - - - >Iteration:  16 ----->Partial loss: 0.696909\n",
      "- - - - - >Iteration:  17 ----->Partial loss: 0.718448\n",
      "- - - - - >Iteration:  18 ----->Partial loss: 0.697315\n",
      "- - - - - >Iteration:  19 ----->Partial loss: 0.699252\n",
      "- - - - - >Iteration:  20 ----->Partial loss: 0.697195\n",
      "- - - - - >Iteration:  21 ----->Partial loss: 0.707544\n",
      "- - - - - >Iteration:  22 ----->Partial loss: 0.73802\n",
      "- - - - - >Iteration:  23 ----->Partial loss: 0.720471\n",
      "- - - - - >Iteration:  24 ----->Partial loss: 0.741751\n",
      "- - - - - >Iteration:  25 ----->Partial loss: 0.721795\n",
      "- - - - - >Iteration:  26 ----->Partial loss: 0.691061\n",
      "- - - - - >Iteration:  27 ----->Partial loss: 0.697969\n",
      "- - - - - >Iteration:  28 ----->Partial loss: 0.718895\n",
      "- - - - - >Iteration:  29 ----->Partial loss: 0.694136\n",
      "- - - - - >Iteration:  30 ----->Partial loss: 0.719799\n",
      "- - - - - >Iteration:  31 ----->Partial loss: 0.706034\n",
      "- - - - - >Iteration:  32 ----->Partial loss: 0.701425\n",
      "- - - - - >Iteration:  33 ----->Partial loss: 0.712875\n",
      "- - - - - >Iteration:  34 ----->Partial loss: 0.700215\n",
      "- - - - - >Iteration:  35 ----->Partial loss: 0.705742\n",
      "- - - - - >Iteration:  36 ----->Partial loss: 0.71582\n",
      "- - - - - >Iteration:  37 ----->Partial loss: 0.699282\n",
      "- - - - - >Iteration:  38 ----->Partial loss: 0.716508\n",
      "- - - - - >Iteration:  39 ----->Partial loss: 0.694638\n",
      "- - - - - >Iteration:  40 ----->Partial loss: 0.701006\n",
      "- - - - - >Iteration:  41 ----->Partial loss: 0.692583\n",
      "- - - - - >Iteration:  42 ----->Partial loss: 0.721881\n",
      "- - - - - >Iteration:  43 ----->Partial loss: 0.729967\n",
      "- - - - - >Iteration:  44 ----->Partial loss: 0.702079\n",
      "- - - - - >Iteration:  45 ----->Partial loss: 0.708199\n",
      "- - - - - >Iteration:  46 ----->Partial loss: 0.729049\n",
      "- - - - - >Iteration:  47 ----->Partial loss: 0.687182\n",
      "- - - - - >Iteration:  48 ----->Partial loss: 0.708473\n",
      "- - - - - >Iteration:  49 ----->Partial loss: 0.691551\n",
      "- - - - - >Iteration:  50 ----->Partial loss: 0.690595\n",
      "- - - - - >Iteration:  51 ----->Partial loss: 0.703939\n",
      "- - - - - >Iteration:  52 ----->Partial loss: 0.68342\n",
      "- - - - - >Iteration:  53 ----->Partial loss: 0.696737\n",
      "- - - - - >Iteration:  54 ----->Partial loss: 0.700262\n",
      "- - - - - >Iteration:  55 ----->Partial loss: 0.699203\n",
      "- - - - - >Iteration:  56 ----->Partial loss: 0.700445\n",
      "- - - - - >Iteration:  57 ----->Partial loss: 0.708434\n",
      "- - - - - >Iteration:  58 ----->Partial loss: 0.725002\n",
      "- - - - - >Iteration:  59 ----->Partial loss: 0.717878\n",
      "- - - - - >Iteration:  60 ----->Partial loss: 0.698123\n",
      "- - - - - >Iteration:  61 ----->Partial loss: 0.686448\n",
      "- - - - - >Iteration:  62 ----->Partial loss: 0.696748\n",
      "- - - - - >Iteration:  63 ----->Partial loss: 0.689543\n",
      "- - - - - >Iteration:  64 ----->Partial loss: 0.704211\n",
      "- - - - - >Iteration:  65 ----->Partial loss: 0.694825\n",
      "- - - - - >Iteration:  66 ----->Partial loss: 0.719689\n",
      "- - - - - >Iteration:  67 ----->Partial loss: 0.706151\n",
      "- - - - - >Iteration:  68 ----->Partial loss: 0.694318\n",
      "- - - - - >Iteration:  69 ----->Partial loss: 0.693572\n",
      "- - - - - >Iteration:  70 ----->Partial loss: 0.689261\n",
      "- - - - - >Iteration:  71 ----->Partial loss: 0.688015\n",
      "- - - - - >Iteration:  72 ----->Partial loss: 0.702108\n",
      "- - - - - >Iteration:  73 ----->Partial loss: 0.714264\n",
      "- - - - - >Iteration:  74 ----->Partial loss: 0.696116\n",
      "- - - - - >Iteration:  75 ----->Partial loss: 0.687771\n",
      "- - - - - >Iteration:  76 ----->Partial loss: 0.707186\n",
      "- - - - - >Iteration:  77 ----->Partial loss: 0.721935\n",
      "- - - - - >Iteration:  78 ----->Partial loss: 0.68509\n",
      "- - - - - >Iteration:  79 ----->Partial loss: 0.683095\n",
      "- - - - - >Iteration:  80 ----->Partial loss: 0.701024\n",
      "- - - - - >Iteration:  81 ----->Partial loss: 0.697046\n",
      "- - - - - >Iteration:  82 ----->Partial loss: 0.71024\n",
      "- - - - - >Iteration:  83 ----->Partial loss: 0.697417\n",
      "- - - - - >Iteration:  84 ----->Partial loss: 0.693718\n",
      "- - - - - >Iteration:  85 ----->Partial loss: 0.68401\n",
      "- - - - - >Iteration:  86 ----->Partial loss: 0.711686\n",
      "- - - - - >Iteration:  87 ----->Partial loss: 0.69339\n",
      "- - - - - >Iteration:  88 ----->Partial loss: 0.690361\n",
      "- - - - - >Iteration:  89 ----->Partial loss: 0.703361\n",
      "- - - - - >Iteration:  90 ----->Partial loss: 0.699985\n",
      "- - - - - >Iteration:  91 ----->Partial loss: 0.67199\n",
      "- - - - - >Iteration:  92 ----->Partial loss: 0.693286\n",
      "- - - - - >Iteration:  93 ----->Partial loss: 0.689401\n",
      "- - - - - >Iteration:  94 ----->Partial loss: 0.685556\n",
      "- - - - - >Iteration:  95 ----->Partial loss: 0.705301\n",
      "- - - - - >Iteration:  96 ----->Partial loss: 0.685944\n",
      "- - - - - >Iteration:  97 ----->Partial loss: 0.693931\n",
      "- - - - - >Iteration:  98 ----->Partial loss: 0.685315\n",
      "- - - - - >Iteration:  99 ----->Partial loss: 0.734634\n",
      "- - - - - >Iteration:  100 ----->Partial loss: 0.689689\n",
      "- - - - - >Iteration:  101 ----->Partial loss: 0.671858\n",
      "- - - - - >Iteration:  102 ----->Partial loss: 0.675755\n",
      "- - - - - >Iteration:  103 ----->Partial loss: 0.689756\n",
      "- - - - - >Iteration:  104 ----->Partial loss: 0.688124\n",
      "- - - - - >Iteration:  105 ----->Partial loss: 0.69338\n",
      "- - - - - >Iteration:  106 ----->Partial loss: 0.684265\n",
      "- - - - - >Iteration:  107 ----->Partial loss: 0.687211\n",
      "- - - - - >Iteration:  108 ----->Partial loss: 0.677833\n",
      "- - - - - >Iteration:  109 ----->Partial loss: 0.68829\n",
      "- - - - - >Iteration:  110 ----->Partial loss: 0.679547\n",
      "- - - - - >Iteration:  111 ----->Partial loss: 0.68184\n",
      "- - - - - >Iteration:  112 ----->Partial loss: 0.707124\n",
      "- - - - - >Iteration:  113 ----->Partial loss: 0.689559\n",
      "- - - - - >Iteration:  114 ----->Partial loss: 0.700337\n",
      "- - - - - >Iteration:  115 ----->Partial loss: 0.716979\n",
      "- - - - - >Iteration:  116 ----->Partial loss: 0.690398\n",
      "- - - - - >Iteration:  117 ----->Partial loss: 0.686572\n",
      "- - - - - >Iteration:  118 ----->Partial loss: 0.686749\n",
      "- - - - - >Iteration:  119 ----->Partial loss: 0.67376\n",
      "- - - - - >Iteration:  120 ----->Partial loss: 0.67686\n",
      "- - - - - >Iteration:  121 ----->Partial loss: 0.689795\n",
      "- - - - - >Iteration:  122 ----->Partial loss: 0.700055\n",
      "- - - - - >Iteration:  123 ----->Partial loss: 0.680507\n",
      "- - - - - >Iteration:  124 ----->Partial loss: 0.682278\n",
      "- - - - - >Iteration:  125 ----->Partial loss: 0.69015\n",
      "- - - - - >Iteration:  126 ----->Partial loss: 0.707225\n",
      "- - - - - >Iteration:  127 ----->Partial loss: 0.674593\n",
      "- - - - - >Iteration:  128 ----->Partial loss: 0.696692\n",
      "- - - - - >Iteration:  129 ----->Partial loss: 0.681249\n",
      "- - - - - >Iteration:  130 ----->Partial loss: 0.695601\n",
      "- - - - - >Iteration:  131 ----->Partial loss: 0.705038\n",
      "- - - - - >Iteration:  132 ----->Partial loss: 0.680365\n",
      "- - - - - >Iteration:  133 ----->Partial loss: 0.703644\n",
      "- - - - - >Iteration:  134 ----->Partial loss: 0.699016\n",
      "- - - - - >Iteration:  135 ----->Partial loss: 0.700705\n",
      "- - - - - >Iteration:  136 ----->Partial loss: 0.707348\n",
      "- - - - - >Iteration:  137 ----->Partial loss: 0.68631\n",
      "- - - - - >Iteration:  138 ----->Partial loss: 0.716401\n",
      "- - - - - >Iteration:  139 ----->Partial loss: 0.699826\n",
      "- - - - - >Iteration:  140 ----->Partial loss: 0.689719\n",
      "- - - - - >Iteration:  141 ----->Partial loss: 0.706707\n",
      "- - - - - >Iteration:  142 ----->Partial loss: 0.68483\n",
      "- - - - - >Iteration:  143 ----->Partial loss: 0.692917\n",
      "- - - - - >Iteration:  144 ----->Partial loss: 0.711029\n",
      "- - - - - >Iteration:  145 ----->Partial loss: 0.66797\n",
      "- - - - - >Iteration:  146 ----->Partial loss: 0.684574\n",
      "- - - - - >Iteration:  147 ----->Partial loss: 0.700642\n",
      "- - - - - >Iteration:  148 ----->Partial loss: 0.669931\n",
      "- - - - - >Iteration:  149 ----->Partial loss: 0.693409\n",
      "- - - - - >Iteration:  150 ----->Partial loss: 0.700065\n",
      "- - - - - >Iteration:  151 ----->Partial loss: 0.678126\n",
      "- - - - - >Iteration:  152 ----->Partial loss: 0.670304\n",
      "- - - - - >Iteration:  153 ----->Partial loss: 0.689735\n",
      "- - - - - >Iteration:  154 ----->Partial loss: 0.676367\n",
      "- - - - - >Iteration:  155 ----->Partial loss: 0.67262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- - - - - >Iteration:  156 ----->Partial loss: 0.674355\n",
      "- - - - - >Iteration:  157 ----->Partial loss: 0.682181\n",
      "- - - - - >Iteration:  158 ----->Partial loss: 0.672396\n",
      "- - - - - >Iteration:  159 ----->Partial loss: 0.680557\n",
      "- - - - - >Iteration:  160 ----->Partial loss: 0.682564\n",
      "- - - - - >Iteration:  161 ----->Partial loss: 0.698767\n",
      "- - - - - >Iteration:  162 ----->Partial loss: 0.691726\n",
      "- - - - - >Iteration:  163 ----->Partial loss: 0.673583\n",
      "- - - - - >Iteration:  164 ----->Partial loss: 0.677832\n",
      "- - - - - >Iteration:  165 ----->Partial loss: 0.683648\n",
      "- - - - - >Iteration:  166 ----->Partial loss: 0.674258\n",
      "- - - - - >Iteration:  167 ----->Partial loss: 0.664041\n",
      "- - - - - >Iteration:  168 ----->Partial loss: 0.690572\n",
      "- - - - - >Iteration:  169 ----->Partial loss: 0.668832\n",
      "- - - - - >Iteration:  170 ----->Partial loss: 0.670415\n",
      "- - - - - >Iteration:  171 ----->Partial loss: 0.686139\n",
      "- - - - - >Iteration:  172 ----->Partial loss: 0.677809\n",
      "- - - - - >Iteration:  173 ----->Partial loss: 0.670588\n",
      "- - - - - >Iteration:  174 ----->Partial loss: 0.67669\n",
      "- - - - - >Iteration:  175 ----->Partial loss: 0.678777\n",
      "- - - - - >Iteration:  176 ----->Partial loss: 0.695649\n",
      "- - - - - >Iteration:  177 ----->Partial loss: 0.665709\n",
      "- - - - - >Iteration:  178 ----->Partial loss: 0.666922\n",
      "- - - - - >Iteration:  179 ----->Partial loss: 0.685898\n",
      "- - - - - >Iteration:  180 ----->Partial loss: 0.664288\n",
      "- - - - - >Iteration:  181 ----->Partial loss: 0.671331\n",
      "- - - - - >Iteration:  182 ----->Partial loss: 0.692209\n",
      "- - - - - >Iteration:  183 ----->Partial loss: 0.683187\n",
      "- - - - - >Iteration:  184 ----->Partial loss: 0.676587\n",
      "- - - - - >Iteration:  185 ----->Partial loss: 0.674955\n",
      "- - - - - >Iteration:  186 ----->Partial loss: 0.667346\n",
      "- - - - - >Iteration:  187 ----->Partial loss: 0.658119\n",
      "- - - - - >Iteration:  188 ----->Partial loss: 0.670605\n",
      "- - - - - >Iteration:  189 ----->Partial loss: 0.677031\n",
      "- - - - - >Iteration:  190 ----->Partial loss: 0.662435\n",
      "- - - - - >Iteration:  191 ----->Partial loss: 0.676745\n",
      "- - - - - >Iteration:  192 ----->Partial loss: 0.667484\n",
      "- - - - - >Iteration:  193 ----->Partial loss: 0.66251\n",
      "- - - - - >Iteration:  194 ----->Partial loss: 0.679251\n",
      "- - - - - >Iteration:  195 ----->Partial loss: 0.675185\n",
      "- - - - - >Iteration:  196 ----->Partial loss: 0.674773\n",
      "- - - - - >Iteration:  197 ----->Partial loss: 0.662105\n",
      "- - - - - >Iteration:  198 ----->Partial loss: 0.671437\n",
      "- - - - - >Iteration:  199 ----->Partial loss: 0.674845\n",
      "- - - - - >Iteration:  200 ----->Partial loss: 0.66851\n",
      "- - - - - >Iteration:  201 ----->Partial loss: 0.677863\n",
      "- - - - - >Iteration:  202 ----->Partial loss: 0.6681\n",
      "- - - - - >Iteration:  203 ----->Partial loss: 0.658397\n",
      "- - - - - >Iteration:  204 ----->Partial loss: 0.662787\n",
      "- - - - - >Iteration:  205 ----->Partial loss: 0.661626\n",
      "- - - - - >Iteration:  206 ----->Partial loss: 0.670389\n",
      "- - - - - >Iteration:  207 ----->Partial loss: 0.668066\n",
      "- - - - - >Iteration:  208 ----->Partial loss: 0.675136\n",
      "- - - - - >Iteration:  209 ----->Partial loss: 0.674951\n",
      "- - - - - >Iteration:  210 ----->Partial loss: 0.66474\n",
      "- - - - - >Iteration:  211 ----->Partial loss: 0.661988\n",
      "- - - - - >Iteration:  212 ----->Partial loss: 0.665914\n",
      "- - - - - >Iteration:  213 ----->Partial loss: 0.660362\n",
      "- - - - - >Iteration:  214 ----->Partial loss: 0.677059\n",
      "- - - - - >Iteration:  215 ----->Partial loss: 0.661665\n",
      "- - - - - >Iteration:  216 ----->Partial loss: 0.67024\n",
      "- - - - - >Iteration:  217 ----->Partial loss: 0.656826\n",
      "- - - - - >Iteration:  218 ----->Partial loss: 0.671755\n",
      "- - - - - >Iteration:  219 ----->Partial loss: 0.679708\n",
      "- - - - - >Iteration:  220 ----->Partial loss: 0.674471\n",
      "- - - - - >Iteration:  221 ----->Partial loss: 0.681682\n",
      "- - - - - >Iteration:  222 ----->Partial loss: 0.665173\n",
      "- - - - - >Iteration:  223 ----->Partial loss: 0.661833\n",
      "- - - - - >Iteration:  224 ----->Partial loss: 0.668345\n",
      "- - - - - >Iteration:  225 ----->Partial loss: 0.666893\n",
      "- - - - - >Iteration:  226 ----->Partial loss: 0.660251\n",
      "- - - - - >Iteration:  227 ----->Partial loss: 0.675033\n",
      "- - - - - >Iteration:  228 ----->Partial loss: 0.667595\n",
      "- - - - - >Iteration:  229 ----->Partial loss: 0.683083\n",
      "- - - - - >Iteration:  230 ----->Partial loss: 0.678039\n",
      "- - - - - >Iteration:  231 ----->Partial loss: 0.661249\n",
      "- - - - - >Iteration:  232 ----->Partial loss: 0.663411\n",
      "- - - - - >Iteration:  233 ----->Partial loss: 0.654081\n",
      "- - - - - >Iteration:  234 ----->Partial loss: 0.67499\n",
      "- - - - - >Iteration:  235 ----->Partial loss: 0.664134\n",
      "- - - - - >Iteration:  236 ----->Partial loss: 0.668088\n",
      "- - - - - >Iteration:  237 ----->Partial loss: 0.666084\n",
      "- - - - - >Iteration:  238 ----->Partial loss: 0.668293\n",
      "- - - - - >Iteration:  239 ----->Partial loss: 0.667346\n",
      "- - - - - >Iteration:  240 ----->Partial loss: 0.666382\n",
      "- - - - - >Iteration:  241 ----->Partial loss: 0.674762\n",
      "- - - - - >Iteration:  242 ----->Partial loss: 0.671946\n",
      "- - - - - >Iteration:  243 ----->Partial loss: 0.666108\n",
      "- - - - - >Iteration:  244 ----->Partial loss: 0.668607\n",
      "- - - - - >Iteration:  245 ----->Partial loss: 0.662463\n",
      "- - - - - >Iteration:  246 ----->Partial loss: 0.662955\n",
      "- - - - - >Iteration:  247 ----->Partial loss: 0.647931\n",
      "- - - - - >Iteration:  248 ----->Partial loss: 0.666413\n",
      "- - - - - >Iteration:  249 ----->Partial loss: 0.666254\n",
      "- - - - - >Iteration:  250 ----->Partial loss: 0.654392\n",
      "- - - - - >Iteration:  251 ----->Partial loss: 0.689752\n",
      "- - - - - >Iteration:  252 ----->Partial loss: 0.662238\n",
      "- - - - - >Iteration:  253 ----->Partial loss: 0.652931\n",
      "- - - - - >Iteration:  254 ----->Partial loss: 0.659467\n",
      "- - - - - >Iteration:  255 ----->Partial loss: 0.696236\n",
      "- - - - - >Iteration:  256 ----->Partial loss: 0.667261\n",
      "- - - - - >Iteration:  257 ----->Partial loss: 0.683289\n",
      "- - - - - >Iteration:  258 ----->Partial loss: 0.676971\n",
      "- - - - - >Iteration:  259 ----->Partial loss: 0.668257\n",
      "- - - - - >Iteration:  260 ----->Partial loss: 0.668803\n",
      "- - - - - >Iteration:  261 ----->Partial loss: 0.659129\n",
      "- - - - - >Iteration:  262 ----->Partial loss: 0.662572\n",
      "- - - - - >Iteration:  263 ----->Partial loss: 0.668752\n",
      "- - - - - >Iteration:  264 ----->Partial loss: 0.670696\n",
      "- - - - - >Iteration:  265 ----->Partial loss: 0.658503\n",
      "- - - - - >Iteration:  266 ----->Partial loss: 0.654423\n",
      "- - - - - >Iteration:  267 ----->Partial loss: 0.665966\n",
      "- - - - - >Iteration:  268 ----->Partial loss: 0.663085\n",
      "- - - - - >Iteration:  269 ----->Partial loss: 0.653385\n",
      "- - - - - >Iteration:  270 ----->Partial loss: 0.649005\n",
      "- - - - - >Iteration:  271 ----->Partial loss: 0.679621\n",
      "- - - - - >Iteration:  272 ----->Partial loss: 0.664977\n",
      "- - - - - >Iteration:  273 ----->Partial loss: 0.654011\n",
      "- - - - - >Iteration:  274 ----->Partial loss: 0.673962\n",
      "- - - - - >Iteration:  275 ----->Partial loss: 0.656149\n",
      "- - - - - >Iteration:  276 ----->Partial loss: 0.652887\n",
      "- - - - - >Iteration:  277 ----->Partial loss: 0.660551\n",
      "- - - - - >Iteration:  278 ----->Partial loss: 0.64958\n",
      "- - - - - >Iteration:  279 ----->Partial loss: 0.660789\n",
      "- - - - - >Iteration:  280 ----->Partial loss: 0.652524\n",
      "- - - - - >Iteration:  281 ----->Partial loss: 0.67122\n",
      "- - - - - >Iteration:  282 ----->Partial loss: 0.654901\n",
      "- - - - - >Iteration:  283 ----->Partial loss: 0.651838\n",
      "- - - - - >Iteration:  284 ----->Partial loss: 0.650141\n",
      "- - - - - >Iteration:  285 ----->Partial loss: 0.661587\n",
      "- - - - - >Iteration:  286 ----->Partial loss: 0.663607\n",
      "- - - - - >Iteration:  287 ----->Partial loss: 0.653322\n",
      "- - - - - >Iteration:  288 ----->Partial loss: 0.660627\n",
      "- - - - - >Iteration:  289 ----->Partial loss: 0.670916\n",
      "***************\n",
      "Epoch:  2  of  20 training loss:  0.685223511346\n",
      "***************\n",
      "- - - - - >Iteration:  1 ----->Partial loss: 0.65062\n",
      "- - - - - >Iteration:  2 ----->Partial loss: 0.685603\n",
      "- - - - - >Iteration:  3 ----->Partial loss: 0.648324\n",
      "- - - - - >Iteration:  4 ----->Partial loss: 0.663447\n",
      "- - - - - >Iteration:  5 ----->Partial loss: 0.651343\n",
      "- - - - - >Iteration:  6 ----->Partial loss: 0.657883\n",
      "- - - - - >Iteration:  7 ----->Partial loss: 0.643894\n",
      "- - - - - >Iteration:  8 ----->Partial loss: 0.659865\n",
      "- - - - - >Iteration:  9 ----->Partial loss: 0.670412\n",
      "- - - - - >Iteration:  10 ----->Partial loss: 0.657543\n",
      "- - - - - >Iteration:  11 ----->Partial loss: 0.663945\n",
      "- - - - - >Iteration:  12 ----->Partial loss: 0.663812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- - - - - >Iteration:  13 ----->Partial loss: 0.658896\n",
      "- - - - - >Iteration:  14 ----->Partial loss: 0.659216\n",
      "- - - - - >Iteration:  15 ----->Partial loss: 0.648426\n",
      "- - - - - >Iteration:  16 ----->Partial loss: 0.646717\n",
      "- - - - - >Iteration:  17 ----->Partial loss: 0.658481\n",
      "- - - - - >Iteration:  18 ----->Partial loss: 0.665759\n",
      "- - - - - >Iteration:  19 ----->Partial loss: 0.654323\n",
      "- - - - - >Iteration:  20 ----->Partial loss: 0.651052\n",
      "- - - - - >Iteration:  21 ----->Partial loss: 0.657405\n",
      "- - - - - >Iteration:  22 ----->Partial loss: 0.64796\n",
      "- - - - - >Iteration:  23 ----->Partial loss: 0.646855\n",
      "- - - - - >Iteration:  24 ----->Partial loss: 0.654116\n",
      "- - - - - >Iteration:  25 ----->Partial loss: 0.662102\n",
      "- - - - - >Iteration:  26 ----->Partial loss: 0.647327\n",
      "- - - - - >Iteration:  27 ----->Partial loss: 0.658146\n",
      "- - - - - >Iteration:  28 ----->Partial loss: 0.646403\n",
      "- - - - - >Iteration:  29 ----->Partial loss: 0.660627\n",
      "- - - - - >Iteration:  30 ----->Partial loss: 0.655001\n",
      "- - - - - >Iteration:  31 ----->Partial loss: 0.662409\n",
      "- - - - - >Iteration:  32 ----->Partial loss: 0.64301\n",
      "- - - - - >Iteration:  33 ----->Partial loss: 0.657202\n",
      "- - - - - >Iteration:  34 ----->Partial loss: 0.667083\n",
      "- - - - - >Iteration:  35 ----->Partial loss: 0.659284\n",
      "- - - - - >Iteration:  36 ----->Partial loss: 0.661472\n",
      "- - - - - >Iteration:  37 ----->Partial loss: 0.660774\n",
      "- - - - - >Iteration:  38 ----->Partial loss: 0.662454\n",
      "- - - - - >Iteration:  39 ----->Partial loss: 0.668013\n",
      "- - - - - >Iteration:  40 ----->Partial loss: 0.655576\n",
      "- - - - - >Iteration:  41 ----->Partial loss: 0.641359\n",
      "- - - - - >Iteration:  42 ----->Partial loss: 0.650227\n",
      "- - - - - >Iteration:  43 ----->Partial loss: 0.661695\n",
      "- - - - - >Iteration:  44 ----->Partial loss: 0.653783\n",
      "- - - - - >Iteration:  45 ----->Partial loss: 0.647178\n",
      "- - - - - >Iteration:  46 ----->Partial loss: 0.644194\n",
      "- - - - - >Iteration:  47 ----->Partial loss: 0.643102\n",
      "- - - - - >Iteration:  48 ----->Partial loss: 0.661445\n",
      "- - - - - >Iteration:  49 ----->Partial loss: 0.639822\n",
      "- - - - - >Iteration:  50 ----->Partial loss: 0.650923\n",
      "- - - - - >Iteration:  51 ----->Partial loss: 0.638112\n",
      "- - - - - >Iteration:  52 ----->Partial loss: 0.645434\n",
      "- - - - - >Iteration:  53 ----->Partial loss: 0.680801\n",
      "- - - - - >Iteration:  54 ----->Partial loss: 0.650352\n",
      "- - - - - >Iteration:  55 ----->Partial loss: 0.662965\n",
      "- - - - - >Iteration:  56 ----->Partial loss: 0.658526\n",
      "- - - - - >Iteration:  57 ----->Partial loss: 0.678204\n",
      "- - - - - >Iteration:  58 ----->Partial loss: 0.667676\n",
      "- - - - - >Iteration:  59 ----->Partial loss: 0.649297\n",
      "- - - - - >Iteration:  60 ----->Partial loss: 0.646049\n",
      "- - - - - >Iteration:  61 ----->Partial loss: 0.658121\n",
      "- - - - - >Iteration:  62 ----->Partial loss: 0.641168\n",
      "- - - - - >Iteration:  63 ----->Partial loss: 0.654146\n",
      "- - - - - >Iteration:  64 ----->Partial loss: 0.67213\n",
      "- - - - - >Iteration:  65 ----->Partial loss: 0.658333\n",
      "- - - - - >Iteration:  66 ----->Partial loss: 0.669247\n",
      "- - - - - >Iteration:  67 ----->Partial loss: 0.687532\n",
      "- - - - - >Iteration:  68 ----->Partial loss: 0.633211\n",
      "- - - - - >Iteration:  69 ----->Partial loss: 0.668844\n",
      "- - - - - >Iteration:  70 ----->Partial loss: 0.74132\n",
      "- - - - - >Iteration:  71 ----->Partial loss: 0.654975\n",
      "- - - - - >Iteration:  72 ----->Partial loss: 0.672856\n",
      "- - - - - >Iteration:  73 ----->Partial loss: 0.684819\n",
      "- - - - - >Iteration:  74 ----->Partial loss: 0.659052\n",
      "- - - - - >Iteration:  75 ----->Partial loss: 0.663621\n",
      "- - - - - >Iteration:  76 ----->Partial loss: 0.679739\n",
      "- - - - - >Iteration:  77 ----->Partial loss: 0.690631\n",
      "- - - - - >Iteration:  78 ----->Partial loss: 0.644965\n",
      "- - - - - >Iteration:  79 ----->Partial loss: 0.674304\n",
      "- - - - - >Iteration:  80 ----->Partial loss: 0.651214\n",
      "- - - - - >Iteration:  81 ----->Partial loss: 0.64945\n",
      "- - - - - >Iteration:  82 ----->Partial loss: 0.650824\n",
      "- - - - - >Iteration:  83 ----->Partial loss: 0.666342\n",
      "- - - - - >Iteration:  84 ----->Partial loss: 0.635247\n",
      "- - - - - >Iteration:  85 ----->Partial loss: 0.65729\n",
      "- - - - - >Iteration:  86 ----->Partial loss: 0.646782\n",
      "- - - - - >Iteration:  87 ----->Partial loss: 0.643694\n",
      "- - - - - >Iteration:  88 ----->Partial loss: 0.630896\n",
      "- - - - - >Iteration:  89 ----->Partial loss: 0.658561\n",
      "- - - - - >Iteration:  90 ----->Partial loss: 0.657562\n",
      "- - - - - >Iteration:  91 ----->Partial loss: 0.643732\n",
      "- - - - - >Iteration:  92 ----->Partial loss: 0.650949\n",
      "- - - - - >Iteration:  93 ----->Partial loss: 0.638508\n",
      "- - - - - >Iteration:  94 ----->Partial loss: 0.636909\n",
      "- - - - - >Iteration:  95 ----->Partial loss: 0.641508\n",
      "- - - - - >Iteration:  96 ----->Partial loss: 0.63688\n",
      "- - - - - >Iteration:  97 ----->Partial loss: 0.680429\n",
      "- - - - - >Iteration:  98 ----->Partial loss: 0.643658\n",
      "- - - - - >Iteration:  99 ----->Partial loss: 0.636861\n",
      "- - - - - >Iteration:  100 ----->Partial loss: 0.651704\n",
      "- - - - - >Iteration:  101 ----->Partial loss: 0.650302\n",
      "- - - - - >Iteration:  102 ----->Partial loss: 0.637964\n",
      "- - - - - >Iteration:  103 ----->Partial loss: 0.629179\n",
      "- - - - - >Iteration:  104 ----->Partial loss: 0.657997\n",
      "- - - - - >Iteration:  105 ----->Partial loss: 0.649708\n",
      "- - - - - >Iteration:  106 ----->Partial loss: 0.641675\n",
      "- - - - - >Iteration:  107 ----->Partial loss: 0.637158\n",
      "- - - - - >Iteration:  108 ----->Partial loss: 0.646628\n",
      "- - - - - >Iteration:  109 ----->Partial loss: 0.634793\n",
      "- - - - - >Iteration:  110 ----->Partial loss: 0.670606\n",
      "- - - - - >Iteration:  111 ----->Partial loss: 0.632455\n",
      "- - - - - >Iteration:  112 ----->Partial loss: 0.626152\n",
      "- - - - - >Iteration:  113 ----->Partial loss: 0.631687\n",
      "- - - - - >Iteration:  114 ----->Partial loss: 0.630933\n",
      "- - - - - >Iteration:  115 ----->Partial loss: 0.634262\n",
      "- - - - - >Iteration:  116 ----->Partial loss: 0.674094\n",
      "- - - - - >Iteration:  117 ----->Partial loss: 0.619783\n",
      "- - - - - >Iteration:  118 ----->Partial loss: 0.631746\n",
      "- - - - - >Iteration:  119 ----->Partial loss: 0.630507\n",
      "- - - - - >Iteration:  120 ----->Partial loss: 0.636051\n",
      "- - - - - >Iteration:  121 ----->Partial loss: 0.669222\n",
      "- - - - - >Iteration:  122 ----->Partial loss: 0.629914\n",
      "- - - - - >Iteration:  123 ----->Partial loss: 0.643844\n",
      "- - - - - >Iteration:  124 ----->Partial loss: 0.638746\n",
      "- - - - - >Iteration:  125 ----->Partial loss: 0.634354\n",
      "- - - - - >Iteration:  126 ----->Partial loss: 0.63924\n",
      "- - - - - >Iteration:  127 ----->Partial loss: 0.631302\n",
      "- - - - - >Iteration:  128 ----->Partial loss: 0.640186\n",
      "- - - - - >Iteration:  129 ----->Partial loss: 0.635345\n",
      "- - - - - >Iteration:  130 ----->Partial loss: 0.633032\n",
      "- - - - - >Iteration:  131 ----->Partial loss: 0.638185\n",
      "- - - - - >Iteration:  132 ----->Partial loss: 0.627685\n",
      "- - - - - >Iteration:  133 ----->Partial loss: 0.650188\n",
      "- - - - - >Iteration:  134 ----->Partial loss: 0.631869\n",
      "- - - - - >Iteration:  135 ----->Partial loss: 0.623282\n",
      "- - - - - >Iteration:  136 ----->Partial loss: 0.640446\n",
      "- - - - - >Iteration:  137 ----->Partial loss: 0.634459\n",
      "- - - - - >Iteration:  138 ----->Partial loss: 0.625912\n",
      "- - - - - >Iteration:  139 ----->Partial loss: 0.642774\n",
      "- - - - - >Iteration:  140 ----->Partial loss: 0.643115\n",
      "- - - - - >Iteration:  141 ----->Partial loss: 0.636712\n",
      "- - - - - >Iteration:  142 ----->Partial loss: 0.624134\n",
      "- - - - - >Iteration:  143 ----->Partial loss: 0.630237\n",
      "- - - - - >Iteration:  144 ----->Partial loss: 0.629692\n",
      "- - - - - >Iteration:  145 ----->Partial loss: 0.639931\n",
      "- - - - - >Iteration:  146 ----->Partial loss: 0.623722\n",
      "- - - - - >Iteration:  147 ----->Partial loss: 0.620321\n",
      "- - - - - >Iteration:  148 ----->Partial loss: 0.64784\n",
      "- - - - - >Iteration:  149 ----->Partial loss: 0.634004\n",
      "- - - - - >Iteration:  150 ----->Partial loss: 0.638926\n",
      "- - - - - >Iteration:  151 ----->Partial loss: 0.649944\n",
      "- - - - - >Iteration:  152 ----->Partial loss: 0.624492\n",
      "- - - - - >Iteration:  153 ----->Partial loss: 0.646248\n",
      "- - - - - >Iteration:  154 ----->Partial loss: 0.653166\n",
      "- - - - - >Iteration:  155 ----->Partial loss: 0.657661\n",
      "- - - - - >Iteration:  156 ----->Partial loss: 0.617606\n",
      "- - - - - >Iteration:  157 ----->Partial loss: 0.62314\n",
      "- - - - - >Iteration:  158 ----->Partial loss: 0.631252\n",
      "- - - - - >Iteration:  159 ----->Partial loss: 0.614864\n",
      "- - - - - >Iteration:  160 ----->Partial loss: 0.630392\n",
      "- - - - - >Iteration:  161 ----->Partial loss: 0.6465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- - - - - >Iteration:  162 ----->Partial loss: 0.631492\n",
      "- - - - - >Iteration:  163 ----->Partial loss: 0.626376\n",
      "- - - - - >Iteration:  164 ----->Partial loss: 0.635086\n",
      "- - - - - >Iteration:  165 ----->Partial loss: 0.631256\n",
      "- - - - - >Iteration:  166 ----->Partial loss: 0.625457\n",
      "- - - - - >Iteration:  167 ----->Partial loss: 0.645849\n",
      "- - - - - >Iteration:  168 ----->Partial loss: 0.648856\n",
      "- - - - - >Iteration:  169 ----->Partial loss: 0.663096\n",
      "- - - - - >Iteration:  170 ----->Partial loss: 0.633809\n",
      "- - - - - >Iteration:  171 ----->Partial loss: 0.628044\n",
      "- - - - - >Iteration:  172 ----->Partial loss: 0.630323\n",
      "- - - - - >Iteration:  173 ----->Partial loss: 0.624979\n",
      "- - - - - >Iteration:  174 ----->Partial loss: 0.647365\n",
      "- - - - - >Iteration:  175 ----->Partial loss: 0.624296\n",
      "- - - - - >Iteration:  176 ----->Partial loss: 0.619438\n",
      "- - - - - >Iteration:  177 ----->Partial loss: 0.62501\n",
      "- - - - - >Iteration:  178 ----->Partial loss: 0.628602\n",
      "- - - - - >Iteration:  179 ----->Partial loss: 0.660514\n",
      "- - - - - >Iteration:  180 ----->Partial loss: 0.66124\n",
      "- - - - - >Iteration:  181 ----->Partial loss: 0.629676\n",
      "- - - - - >Iteration:  182 ----->Partial loss: 0.621903\n",
      "- - - - - >Iteration:  183 ----->Partial loss: 0.624839\n",
      "- - - - - >Iteration:  184 ----->Partial loss: 0.635819\n",
      "- - - - - >Iteration:  185 ----->Partial loss: 0.661819\n",
      "- - - - - >Iteration:  186 ----->Partial loss: 0.639525\n",
      "- - - - - >Iteration:  187 ----->Partial loss: 0.621886\n",
      "- - - - - >Iteration:  188 ----->Partial loss: 0.65318\n",
      "- - - - - >Iteration:  189 ----->Partial loss: 0.65534\n",
      "- - - - - >Iteration:  190 ----->Partial loss: 0.631531\n",
      "- - - - - >Iteration:  191 ----->Partial loss: 0.623076\n",
      "- - - - - >Iteration:  192 ----->Partial loss: 0.618636\n",
      "- - - - - >Iteration:  193 ----->Partial loss: 0.631734\n",
      "- - - - - >Iteration:  194 ----->Partial loss: 0.630606\n",
      "- - - - - >Iteration:  195 ----->Partial loss: 0.618909\n",
      "- - - - - >Iteration:  196 ----->Partial loss: 0.637691\n",
      "- - - - - >Iteration:  197 ----->Partial loss: 0.626007\n",
      "- - - - - >Iteration:  198 ----->Partial loss: 0.649917\n",
      "- - - - - >Iteration:  199 ----->Partial loss: 0.628375\n",
      "- - - - - >Iteration:  200 ----->Partial loss: 0.609728\n",
      "- - - - - >Iteration:  201 ----->Partial loss: 0.609757\n",
      "- - - - - >Iteration:  202 ----->Partial loss: 0.622332\n",
      "- - - - - >Iteration:  203 ----->Partial loss: 0.636029\n",
      "- - - - - >Iteration:  204 ----->Partial loss: 0.616512\n",
      "- - - - - >Iteration:  205 ----->Partial loss: 0.645546\n",
      "- - - - - >Iteration:  206 ----->Partial loss: 0.616979\n",
      "- - - - - >Iteration:  207 ----->Partial loss: 0.630874\n",
      "- - - - - >Iteration:  208 ----->Partial loss: 0.647979\n",
      "- - - - - >Iteration:  209 ----->Partial loss: 0.6424\n",
      "- - - - - >Iteration:  210 ----->Partial loss: 0.624593\n",
      "- - - - - >Iteration:  211 ----->Partial loss: 0.64098\n",
      "- - - - - >Iteration:  212 ----->Partial loss: 0.609643\n",
      "- - - - - >Iteration:  213 ----->Partial loss: 0.64678\n",
      "- - - - - >Iteration:  214 ----->Partial loss: 0.602881\n",
      "- - - - - >Iteration:  215 ----->Partial loss: 0.634715\n",
      "- - - - - >Iteration:  216 ----->Partial loss: 0.61187\n",
      "- - - - - >Iteration:  217 ----->Partial loss: 0.616038\n",
      "- - - - - >Iteration:  218 ----->Partial loss: 0.612408\n",
      "- - - - - >Iteration:  219 ----->Partial loss: 0.617977\n",
      "- - - - - >Iteration:  220 ----->Partial loss: 0.618235\n",
      "- - - - - >Iteration:  221 ----->Partial loss: 0.62791\n",
      "- - - - - >Iteration:  222 ----->Partial loss: 0.598085\n",
      "- - - - - >Iteration:  223 ----->Partial loss: 0.632941\n",
      "- - - - - >Iteration:  224 ----->Partial loss: 0.632281\n",
      "- - - - - >Iteration:  225 ----->Partial loss: 0.619601\n",
      "- - - - - >Iteration:  226 ----->Partial loss: 0.603118\n",
      "- - - - - >Iteration:  227 ----->Partial loss: 0.604142\n",
      "- - - - - >Iteration:  228 ----->Partial loss: 0.599323\n",
      "- - - - - >Iteration:  229 ----->Partial loss: 0.599974\n",
      "- - - - - >Iteration:  230 ----->Partial loss: 0.622287\n",
      "- - - - - >Iteration:  231 ----->Partial loss: 0.637648\n",
      "- - - - - >Iteration:  232 ----->Partial loss: 0.600292\n",
      "- - - - - >Iteration:  233 ----->Partial loss: 0.604781\n",
      "- - - - - >Iteration:  234 ----->Partial loss: 0.639575\n",
      "- - - - - >Iteration:  235 ----->Partial loss: 0.614308\n",
      "- - - - - >Iteration:  236 ----->Partial loss: 0.608133\n",
      "- - - - - >Iteration:  237 ----->Partial loss: 0.611471\n",
      "- - - - - >Iteration:  238 ----->Partial loss: 0.609338\n",
      "- - - - - >Iteration:  239 ----->Partial loss: 0.650239\n",
      "- - - - - >Iteration:  240 ----->Partial loss: 0.599679\n",
      "- - - - - >Iteration:  241 ----->Partial loss: 0.595948\n",
      "- - - - - >Iteration:  242 ----->Partial loss: 0.60928\n",
      "- - - - - >Iteration:  243 ----->Partial loss: 0.595613\n",
      "- - - - - >Iteration:  244 ----->Partial loss: 0.624988\n",
      "- - - - - >Iteration:  245 ----->Partial loss: 0.62187\n",
      "- - - - - >Iteration:  246 ----->Partial loss: 0.598556\n",
      "- - - - - >Iteration:  247 ----->Partial loss: 0.628798\n",
      "- - - - - >Iteration:  248 ----->Partial loss: 0.602318\n",
      "- - - - - >Iteration:  249 ----->Partial loss: 0.594241\n",
      "- - - - - >Iteration:  250 ----->Partial loss: 0.616609\n",
      "- - - - - >Iteration:  251 ----->Partial loss: 0.585475\n",
      "- - - - - >Iteration:  252 ----->Partial loss: 0.595728\n",
      "- - - - - >Iteration:  253 ----->Partial loss: 0.594164\n",
      "- - - - - >Iteration:  254 ----->Partial loss: 0.603324\n",
      "- - - - - >Iteration:  255 ----->Partial loss: 0.61951\n",
      "- - - - - >Iteration:  256 ----->Partial loss: 0.592996\n",
      "- - - - - >Iteration:  257 ----->Partial loss: 0.609908\n",
      "- - - - - >Iteration:  258 ----->Partial loss: 0.596157\n",
      "- - - - - >Iteration:  259 ----->Partial loss: 0.589647\n",
      "- - - - - >Iteration:  260 ----->Partial loss: 0.588482\n",
      "- - - - - >Iteration:  261 ----->Partial loss: 0.635066\n",
      "- - - - - >Iteration:  262 ----->Partial loss: 0.64034\n",
      "- - - - - >Iteration:  263 ----->Partial loss: 0.583007\n",
      "- - - - - >Iteration:  264 ----->Partial loss: 0.611423\n",
      "- - - - - >Iteration:  265 ----->Partial loss: 0.61857\n",
      "- - - - - >Iteration:  266 ----->Partial loss: 0.587801\n",
      "- - - - - >Iteration:  267 ----->Partial loss: 0.578719\n",
      "- - - - - >Iteration:  268 ----->Partial loss: 0.623603\n",
      "- - - - - >Iteration:  269 ----->Partial loss: 0.594482\n",
      "- - - - - >Iteration:  270 ----->Partial loss: 0.621557\n",
      "- - - - - >Iteration:  271 ----->Partial loss: 0.58418\n",
      "- - - - - >Iteration:  272 ----->Partial loss: 0.63424\n",
      "- - - - - >Iteration:  273 ----->Partial loss: 0.60637\n",
      "- - - - - >Iteration:  274 ----->Partial loss: 0.631446\n",
      "- - - - - >Iteration:  275 ----->Partial loss: 0.631434\n",
      "- - - - - >Iteration:  276 ----->Partial loss: 0.595695\n",
      "- - - - - >Iteration:  277 ----->Partial loss: 0.59797\n",
      "- - - - - >Iteration:  278 ----->Partial loss: 0.629544\n",
      "- - - - - >Iteration:  279 ----->Partial loss: 0.586667\n",
      "- - - - - >Iteration:  280 ----->Partial loss: 0.588598\n",
      "- - - - - >Iteration:  281 ----->Partial loss: 0.627784\n",
      "- - - - - >Iteration:  282 ----->Partial loss: 0.578894\n",
      "- - - - - >Iteration:  283 ----->Partial loss: 0.592587\n",
      "- - - - - >Iteration:  284 ----->Partial loss: 0.608424\n",
      "- - - - - >Iteration:  285 ----->Partial loss: 0.597746\n",
      "- - - - - >Iteration:  286 ----->Partial loss: 0.588811\n",
      "- - - - - >Iteration:  287 ----->Partial loss: 0.581885\n",
      "- - - - - >Iteration:  288 ----->Partial loss: 0.602274\n",
      "- - - - - >Iteration:  289 ----->Partial loss: 0.612254\n",
      "***************\n",
      "Epoch:  3  of  20 training loss:  0.635831904246\n",
      "***************\n",
      "- - - - - >Iteration:  1 ----->Partial loss: 0.60261\n",
      "- - - - - >Iteration:  2 ----->Partial loss: 0.58791\n",
      "- - - - - >Iteration:  3 ----->Partial loss: 0.601817\n",
      "- - - - - >Iteration:  4 ----->Partial loss: 0.58852\n",
      "- - - - - >Iteration:  5 ----->Partial loss: 0.580619\n",
      "- - - - - >Iteration:  6 ----->Partial loss: 0.579691\n",
      "- - - - - >Iteration:  7 ----->Partial loss: 0.577873\n",
      "- - - - - >Iteration:  8 ----->Partial loss: 0.586933\n",
      "- - - - - >Iteration:  9 ----->Partial loss: 0.577423\n",
      "- - - - - >Iteration:  10 ----->Partial loss: 0.573437\n",
      "- - - - - >Iteration:  11 ----->Partial loss: 0.622466\n",
      "- - - - - >Iteration:  12 ----->Partial loss: 0.577578\n",
      "- - - - - >Iteration:  13 ----->Partial loss: 0.569209\n",
      "- - - - - >Iteration:  14 ----->Partial loss: 0.571205\n",
      "- - - - - >Iteration:  15 ----->Partial loss: 0.604609\n",
      "- - - - - >Iteration:  16 ----->Partial loss: 0.592312\n",
      "- - - - - >Iteration:  17 ----->Partial loss: 0.588576\n",
      "- - - - - >Iteration:  18 ----->Partial loss: 0.592423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- - - - - >Iteration:  19 ----->Partial loss: 0.561909\n",
      "- - - - - >Iteration:  20 ----->Partial loss: 0.575068\n",
      "- - - - - >Iteration:  21 ----->Partial loss: 0.582457\n",
      "- - - - - >Iteration:  22 ----->Partial loss: 0.565777\n",
      "- - - - - >Iteration:  23 ----->Partial loss: 0.583481\n",
      "- - - - - >Iteration:  24 ----->Partial loss: 0.64631\n",
      "- - - - - >Iteration:  25 ----->Partial loss: 0.596431\n",
      "- - - - - >Iteration:  26 ----->Partial loss: 0.579411\n",
      "- - - - - >Iteration:  27 ----->Partial loss: 0.561202\n",
      "- - - - - >Iteration:  28 ----->Partial loss: 0.56372\n",
      "- - - - - >Iteration:  29 ----->Partial loss: 0.569406\n",
      "- - - - - >Iteration:  30 ----->Partial loss: 0.56235\n",
      "- - - - - >Iteration:  31 ----->Partial loss: 0.583057\n",
      "- - - - - >Iteration:  32 ----->Partial loss: 0.616025\n",
      "- - - - - >Iteration:  33 ----->Partial loss: 0.619682\n",
      "- - - - - >Iteration:  34 ----->Partial loss: 0.59098\n",
      "- - - - - >Iteration:  35 ----->Partial loss: 0.587676\n",
      "- - - - - >Iteration:  36 ----->Partial loss: 0.577936\n",
      "- - - - - >Iteration:  37 ----->Partial loss: 0.566553\n",
      "- - - - - >Iteration:  38 ----->Partial loss: 0.572985\n",
      "- - - - - >Iteration:  39 ----->Partial loss: 0.565597\n",
      "- - - - - >Iteration:  40 ----->Partial loss: 0.613992\n",
      "- - - - - >Iteration:  41 ----->Partial loss: 0.602556\n",
      "- - - - - >Iteration:  42 ----->Partial loss: 0.565028\n",
      "- - - - - >Iteration:  43 ----->Partial loss: 0.558601\n",
      "- - - - - >Iteration:  44 ----->Partial loss: 0.601693\n",
      "- - - - - >Iteration:  45 ----->Partial loss: 0.611554\n",
      "- - - - - >Iteration:  46 ----->Partial loss: 0.564928\n",
      "- - - - - >Iteration:  47 ----->Partial loss: 0.566322\n",
      "- - - - - >Iteration:  48 ----->Partial loss: 0.56671\n",
      "- - - - - >Iteration:  49 ----->Partial loss: 0.558269\n",
      "- - - - - >Iteration:  50 ----->Partial loss: 0.557183\n",
      "- - - - - >Iteration:  51 ----->Partial loss: 0.596012\n",
      "- - - - - >Iteration:  52 ----->Partial loss: 0.579302\n",
      "- - - - - >Iteration:  53 ----->Partial loss: 0.566777\n",
      "- - - - - >Iteration:  54 ----->Partial loss: 0.599096\n",
      "- - - - - >Iteration:  55 ----->Partial loss: 0.559691\n",
      "- - - - - >Iteration:  56 ----->Partial loss: 0.602985\n",
      "- - - - - >Iteration:  57 ----->Partial loss: 0.578732\n",
      "- - - - - >Iteration:  58 ----->Partial loss: 0.54532\n",
      "- - - - - >Iteration:  59 ----->Partial loss: 0.542543\n",
      "- - - - - >Iteration:  60 ----->Partial loss: 0.57603\n",
      "- - - - - >Iteration:  61 ----->Partial loss: 0.570935\n",
      "- - - - - >Iteration:  62 ----->Partial loss: 0.65063\n",
      "- - - - - >Iteration:  63 ----->Partial loss: 0.556001\n",
      "- - - - - >Iteration:  64 ----->Partial loss: 0.565913\n",
      "- - - - - >Iteration:  65 ----->Partial loss: 0.58507\n",
      "- - - - - >Iteration:  66 ----->Partial loss: 0.550643\n",
      "- - - - - >Iteration:  67 ----->Partial loss: 0.551648\n",
      "- - - - - >Iteration:  68 ----->Partial loss: 0.557102\n",
      "- - - - - >Iteration:  69 ----->Partial loss: 0.580753\n",
      "- - - - - >Iteration:  70 ----->Partial loss: 0.554376\n",
      "- - - - - >Iteration:  71 ----->Partial loss: 0.562543\n",
      "- - - - - >Iteration:  72 ----->Partial loss: 0.557023\n",
      "- - - - - >Iteration:  73 ----->Partial loss: 0.547767\n",
      "- - - - - >Iteration:  74 ----->Partial loss: 0.550252\n",
      "- - - - - >Iteration:  75 ----->Partial loss: 0.565699\n",
      "- - - - - >Iteration:  76 ----->Partial loss: 0.569681\n",
      "- - - - - >Iteration:  77 ----->Partial loss: 0.567237\n",
      "- - - - - >Iteration:  78 ----->Partial loss: 0.56196\n",
      "- - - - - >Iteration:  79 ----->Partial loss: 0.552095\n",
      "- - - - - >Iteration:  80 ----->Partial loss: 0.571968\n",
      "- - - - - >Iteration:  81 ----->Partial loss: 0.624513\n",
      "- - - - - >Iteration:  82 ----->Partial loss: 0.563395\n",
      "- - - - - >Iteration:  83 ----->Partial loss: 0.563807\n",
      "- - - - - >Iteration:  84 ----->Partial loss: 0.547372\n",
      "- - - - - >Iteration:  85 ----->Partial loss: 0.568884\n",
      "- - - - - >Iteration:  86 ----->Partial loss: 0.567921\n",
      "- - - - - >Iteration:  87 ----->Partial loss: 0.573071\n",
      "- - - - - >Iteration:  88 ----->Partial loss: 0.56619\n",
      "- - - - - >Iteration:  89 ----->Partial loss: 0.538051\n",
      "- - - - - >Iteration:  90 ----->Partial loss: 0.544106\n",
      "- - - - - >Iteration:  91 ----->Partial loss: 0.523794\n",
      "- - - - - >Iteration:  92 ----->Partial loss: 0.546356\n",
      "- - - - - >Iteration:  93 ----->Partial loss: 0.518548\n",
      "- - - - - >Iteration:  94 ----->Partial loss: 0.589627\n",
      "- - - - - >Iteration:  95 ----->Partial loss: 0.52212\n",
      "- - - - - >Iteration:  96 ----->Partial loss: 0.549262\n",
      "- - - - - >Iteration:  97 ----->Partial loss: 0.533661\n",
      "- - - - - >Iteration:  98 ----->Partial loss: 0.550127\n",
      "- - - - - >Iteration:  99 ----->Partial loss: 0.564352\n",
      "- - - - - >Iteration:  100 ----->Partial loss: 0.523702\n",
      "- - - - - >Iteration:  101 ----->Partial loss: 0.522234\n",
      "- - - - - >Iteration:  102 ----->Partial loss: 0.512224\n",
      "- - - - - >Iteration:  103 ----->Partial loss: 0.599218\n",
      "- - - - - >Iteration:  104 ----->Partial loss: 0.53123\n",
      "- - - - - >Iteration:  105 ----->Partial loss: 0.590266\n",
      "- - - - - >Iteration:  106 ----->Partial loss: 0.512269\n",
      "- - - - - >Iteration:  107 ----->Partial loss: 0.526695\n",
      "- - - - - >Iteration:  108 ----->Partial loss: 0.573439\n",
      "- - - - - >Iteration:  109 ----->Partial loss: 0.5561\n",
      "- - - - - >Iteration:  110 ----->Partial loss: 0.636736\n",
      "- - - - - >Iteration:  111 ----->Partial loss: 0.524184\n",
      "- - - - - >Iteration:  112 ----->Partial loss: 0.580469\n",
      "- - - - - >Iteration:  113 ----->Partial loss: 0.528621\n",
      "- - - - - >Iteration:  114 ----->Partial loss: 0.512853\n",
      "- - - - - >Iteration:  115 ----->Partial loss: 0.513875\n",
      "- - - - - >Iteration:  116 ----->Partial loss: 0.533207\n",
      "- - - - - >Iteration:  117 ----->Partial loss: 0.529988\n",
      "- - - - - >Iteration:  118 ----->Partial loss: 0.504498\n",
      "- - - - - >Iteration:  119 ----->Partial loss: 0.561712\n",
      "- - - - - >Iteration:  120 ----->Partial loss: 0.538147\n",
      "- - - - - >Iteration:  121 ----->Partial loss: 0.533667\n",
      "- - - - - >Iteration:  122 ----->Partial loss: 0.542445\n",
      "- - - - - >Iteration:  123 ----->Partial loss: 0.53379\n",
      "- - - - - >Iteration:  124 ----->Partial loss: 0.541966\n",
      "- - - - - >Iteration:  125 ----->Partial loss: 0.507172\n",
      "- - - - - >Iteration:  126 ----->Partial loss: 0.507067\n",
      "- - - - - >Iteration:  127 ----->Partial loss: 0.616976\n",
      "- - - - - >Iteration:  128 ----->Partial loss: 0.55209\n",
      "- - - - - >Iteration:  129 ----->Partial loss: 0.537245\n",
      "- - - - - >Iteration:  130 ----->Partial loss: 0.533115\n",
      "- - - - - >Iteration:  131 ----->Partial loss: 0.524362\n",
      "- - - - - >Iteration:  132 ----->Partial loss: 0.526967\n",
      "- - - - - >Iteration:  133 ----->Partial loss: 0.495417\n",
      "- - - - - >Iteration:  134 ----->Partial loss: 0.500069\n",
      "- - - - - >Iteration:  135 ----->Partial loss: 0.545906\n",
      "- - - - - >Iteration:  136 ----->Partial loss: 0.503199\n",
      "- - - - - >Iteration:  137 ----->Partial loss: 0.516247\n",
      "- - - - - >Iteration:  138 ----->Partial loss: 0.568542\n",
      "- - - - - >Iteration:  139 ----->Partial loss: 0.500988\n",
      "- - - - - >Iteration:  140 ----->Partial loss: 0.511701\n",
      "- - - - - >Iteration:  141 ----->Partial loss: 0.48485\n",
      "- - - - - >Iteration:  142 ----->Partial loss: 0.522344\n",
      "- - - - - >Iteration:  143 ----->Partial loss: 0.509554\n",
      "- - - - - >Iteration:  144 ----->Partial loss: 0.474615\n",
      "- - - - - >Iteration:  145 ----->Partial loss: 0.472426\n",
      "- - - - - >Iteration:  146 ----->Partial loss: 0.471657\n",
      "- - - - - >Iteration:  147 ----->Partial loss: 0.516507\n",
      "- - - - - >Iteration:  148 ----->Partial loss: 0.556159\n",
      "- - - - - >Iteration:  149 ----->Partial loss: 0.502429\n",
      "- - - - - >Iteration:  150 ----->Partial loss: 0.483517\n",
      "- - - - - >Iteration:  151 ----->Partial loss: 0.489625\n",
      "- - - - - >Iteration:  152 ----->Partial loss: 0.467672\n",
      "- - - - - >Iteration:  153 ----->Partial loss: 0.487892\n",
      "- - - - - >Iteration:  154 ----->Partial loss: 0.483347\n",
      "- - - - - >Iteration:  155 ----->Partial loss: 0.478714\n",
      "- - - - - >Iteration:  156 ----->Partial loss: 0.478713\n",
      "- - - - - >Iteration:  157 ----->Partial loss: 0.485441\n",
      "- - - - - >Iteration:  158 ----->Partial loss: 0.526662\n",
      "- - - - - >Iteration:  159 ----->Partial loss: 0.466925\n",
      "- - - - - >Iteration:  160 ----->Partial loss: 0.532781\n",
      "- - - - - >Iteration:  161 ----->Partial loss: 0.467964\n",
      "- - - - - >Iteration:  162 ----->Partial loss: 0.473094\n",
      "- - - - - >Iteration:  163 ----->Partial loss: 0.492165\n",
      "- - - - - >Iteration:  164 ----->Partial loss: 0.466929\n",
      "- - - - - >Iteration:  165 ----->Partial loss: 0.479398\n",
      "- - - - - >Iteration:  166 ----->Partial loss: 0.483711\n",
      "- - - - - >Iteration:  167 ----->Partial loss: 0.430673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- - - - - >Iteration:  168 ----->Partial loss: 0.461002\n",
      "- - - - - >Iteration:  169 ----->Partial loss: 0.443019\n",
      "- - - - - >Iteration:  170 ----->Partial loss: 0.464373\n",
      "- - - - - >Iteration:  171 ----->Partial loss: 0.558601\n",
      "- - - - - >Iteration:  172 ----->Partial loss: 0.439002\n",
      "- - - - - >Iteration:  173 ----->Partial loss: 0.474933\n",
      "- - - - - >Iteration:  174 ----->Partial loss: 0.485438\n",
      "- - - - - >Iteration:  175 ----->Partial loss: 0.553213\n",
      "- - - - - >Iteration:  176 ----->Partial loss: 0.463952\n",
      "- - - - - >Iteration:  177 ----->Partial loss: 0.507362\n",
      "- - - - - >Iteration:  178 ----->Partial loss: 0.453157\n",
      "- - - - - >Iteration:  179 ----->Partial loss: 0.469215\n",
      "- - - - - >Iteration:  180 ----->Partial loss: 0.452154\n",
      "- - - - - >Iteration:  181 ----->Partial loss: 0.444103\n",
      "- - - - - >Iteration:  182 ----->Partial loss: 0.429041\n",
      "- - - - - >Iteration:  183 ----->Partial loss: 0.486034\n",
      "- - - - - >Iteration:  184 ----->Partial loss: 0.524027\n",
      "- - - - - >Iteration:  185 ----->Partial loss: 0.46038\n",
      "- - - - - >Iteration:  186 ----->Partial loss: 0.472503\n",
      "- - - - - >Iteration:  187 ----->Partial loss: 0.444409\n",
      "- - - - - >Iteration:  188 ----->Partial loss: 0.416277\n",
      "- - - - - >Iteration:  189 ----->Partial loss: 0.413136\n",
      "- - - - - >Iteration:  190 ----->Partial loss: 0.518294\n",
      "- - - - - >Iteration:  191 ----->Partial loss: 0.495909\n",
      "- - - - - >Iteration:  192 ----->Partial loss: 0.472112\n",
      "- - - - - >Iteration:  193 ----->Partial loss: 0.525138\n",
      "- - - - - >Iteration:  194 ----->Partial loss: 0.439965\n",
      "- - - - - >Iteration:  195 ----->Partial loss: 0.468603\n",
      "- - - - - >Iteration:  196 ----->Partial loss: 0.462966\n",
      "- - - - - >Iteration:  197 ----->Partial loss: 0.41941\n",
      "- - - - - >Iteration:  198 ----->Partial loss: 0.463969\n",
      "- - - - - >Iteration:  199 ----->Partial loss: 0.513175\n",
      "- - - - - >Iteration:  200 ----->Partial loss: 0.409469\n",
      "- - - - - >Iteration:  201 ----->Partial loss: 0.399189\n",
      "- - - - - >Iteration:  202 ----->Partial loss: 0.40167\n",
      "- - - - - >Iteration:  203 ----->Partial loss: 0.372441\n",
      "- - - - - >Iteration:  204 ----->Partial loss: 0.421399\n",
      "- - - - - >Iteration:  205 ----->Partial loss: 0.40414\n",
      "- - - - - >Iteration:  206 ----->Partial loss: 0.544669\n",
      "- - - - - >Iteration:  207 ----->Partial loss: 0.472189\n",
      "- - - - - >Iteration:  208 ----->Partial loss: 0.3757\n",
      "- - - - - >Iteration:  209 ----->Partial loss: 0.410244\n",
      "- - - - - >Iteration:  210 ----->Partial loss: 0.416518\n",
      "- - - - - >Iteration:  211 ----->Partial loss: 0.493605\n",
      "- - - - - >Iteration:  212 ----->Partial loss: 0.465804\n",
      "- - - - - >Iteration:  213 ----->Partial loss: 0.413227\n",
      "- - - - - >Iteration:  214 ----->Partial loss: 0.409645\n",
      "- - - - - >Iteration:  215 ----->Partial loss: 0.421288\n",
      "- - - - - >Iteration:  216 ----->Partial loss: 0.427029\n",
      "- - - - - >Iteration:  217 ----->Partial loss: 0.504731\n",
      "- - - - - >Iteration:  218 ----->Partial loss: 0.484013\n",
      "- - - - - >Iteration:  219 ----->Partial loss: 0.45117\n",
      "- - - - - >Iteration:  220 ----->Partial loss: 0.450487\n",
      "- - - - - >Iteration:  221 ----->Partial loss: 0.380928\n",
      "- - - - - >Iteration:  222 ----->Partial loss: 0.426021\n",
      "- - - - - >Iteration:  223 ----->Partial loss: 0.415349\n",
      "- - - - - >Iteration:  224 ----->Partial loss: 0.451839\n",
      "- - - - - >Iteration:  225 ----->Partial loss: 0.500951\n",
      "- - - - - >Iteration:  226 ----->Partial loss: 0.37431\n",
      "- - - - - >Iteration:  227 ----->Partial loss: 0.387717\n",
      "- - - - - >Iteration:  228 ----->Partial loss: 0.365216\n",
      "- - - - - >Iteration:  229 ----->Partial loss: 0.458411\n",
      "- - - - - >Iteration:  230 ----->Partial loss: 0.371263\n",
      "- - - - - >Iteration:  231 ----->Partial loss: 0.38906\n",
      "- - - - - >Iteration:  232 ----->Partial loss: 0.38808\n",
      "- - - - - >Iteration:  233 ----->Partial loss: 0.404381\n",
      "- - - - - >Iteration:  234 ----->Partial loss: 0.363438\n",
      "- - - - - >Iteration:  235 ----->Partial loss: 0.365282\n",
      "- - - - - >Iteration:  236 ----->Partial loss: 0.414662\n",
      "- - - - - >Iteration:  237 ----->Partial loss: 0.363801\n",
      "- - - - - >Iteration:  238 ----->Partial loss: 0.408616\n",
      "- - - - - >Iteration:  239 ----->Partial loss: 0.416152\n",
      "- - - - - >Iteration:  240 ----->Partial loss: 0.394558\n",
      "- - - - - >Iteration:  241 ----->Partial loss: 0.363801\n",
      "- - - - - >Iteration:  242 ----->Partial loss: 0.422656\n",
      "- - - - - >Iteration:  243 ----->Partial loss: 0.358822\n",
      "- - - - - >Iteration:  244 ----->Partial loss: 0.360148\n",
      "- - - - - >Iteration:  245 ----->Partial loss: 0.357161\n",
      "- - - - - >Iteration:  246 ----->Partial loss: 0.343867\n",
      "- - - - - >Iteration:  247 ----->Partial loss: 0.352238\n",
      "- - - - - >Iteration:  248 ----->Partial loss: 0.411118\n",
      "- - - - - >Iteration:  249 ----->Partial loss: 0.440544\n",
      "- - - - - >Iteration:  250 ----->Partial loss: 0.412496\n",
      "- - - - - >Iteration:  251 ----->Partial loss: 0.529781\n",
      "- - - - - >Iteration:  252 ----->Partial loss: 0.318067\n",
      "- - - - - >Iteration:  253 ----->Partial loss: 0.343853\n",
      "- - - - - >Iteration:  254 ----->Partial loss: 0.372269\n",
      "- - - - - >Iteration:  255 ----->Partial loss: 0.32541\n",
      "- - - - - >Iteration:  256 ----->Partial loss: 0.415949\n",
      "- - - - - >Iteration:  257 ----->Partial loss: 0.398006\n",
      "- - - - - >Iteration:  258 ----->Partial loss: 0.38726\n",
      "- - - - - >Iteration:  259 ----->Partial loss: 0.394942\n",
      "- - - - - >Iteration:  260 ----->Partial loss: 0.405273\n",
      "- - - - - >Iteration:  261 ----->Partial loss: 0.412012\n",
      "- - - - - >Iteration:  262 ----->Partial loss: 0.309548\n",
      "- - - - - >Iteration:  263 ----->Partial loss: 0.389788\n",
      "- - - - - >Iteration:  264 ----->Partial loss: 0.385309\n",
      "- - - - - >Iteration:  265 ----->Partial loss: 0.352224\n",
      "- - - - - >Iteration:  266 ----->Partial loss: 0.351912\n",
      "- - - - - >Iteration:  267 ----->Partial loss: 0.43181\n",
      "- - - - - >Iteration:  268 ----->Partial loss: 0.310419\n",
      "- - - - - >Iteration:  269 ----->Partial loss: 0.323123\n",
      "- - - - - >Iteration:  270 ----->Partial loss: 0.375085\n",
      "- - - - - >Iteration:  271 ----->Partial loss: 0.419992\n",
      "- - - - - >Iteration:  272 ----->Partial loss: 0.261556\n",
      "- - - - - >Iteration:  273 ----->Partial loss: 0.286021\n",
      "- - - - - >Iteration:  274 ----->Partial loss: 0.388926\n",
      "- - - - - >Iteration:  275 ----->Partial loss: 0.455454\n",
      "- - - - - >Iteration:  276 ----->Partial loss: 0.364419\n",
      "- - - - - >Iteration:  277 ----->Partial loss: 0.454264\n",
      "- - - - - >Iteration:  278 ----->Partial loss: 0.313263\n",
      "- - - - - >Iteration:  279 ----->Partial loss: 0.302256\n",
      "- - - - - >Iteration:  280 ----->Partial loss: 0.303413\n",
      "- - - - - >Iteration:  281 ----->Partial loss: 0.580126\n",
      "- - - - - >Iteration:  282 ----->Partial loss: 0.305132\n",
      "- - - - - >Iteration:  283 ----->Partial loss: 0.294227\n",
      "- - - - - >Iteration:  284 ----->Partial loss: 0.381156\n",
      "- - - - - >Iteration:  285 ----->Partial loss: 0.329795\n",
      "- - - - - >Iteration:  286 ----->Partial loss: 0.478355\n",
      "- - - - - >Iteration:  287 ----->Partial loss: 0.25912\n",
      "- - - - - >Iteration:  288 ----->Partial loss: 0.300245\n",
      "- - - - - >Iteration:  289 ----->Partial loss: 0.510132\n",
      "***************\n",
      "Epoch:  4  of  20 training loss:  0.4935074033\n",
      "***************\n",
      "- - - - - >Iteration:  1 ----->Partial loss: 0.282972\n",
      "- - - - - >Iteration:  2 ----->Partial loss: 0.293994\n",
      "- - - - - >Iteration:  3 ----->Partial loss: 0.321274\n",
      "- - - - - >Iteration:  4 ----->Partial loss: 0.268839\n",
      "- - - - - >Iteration:  5 ----->Partial loss: 0.407174\n",
      "- - - - - >Iteration:  6 ----->Partial loss: 0.278682\n",
      "- - - - - >Iteration:  7 ----->Partial loss: 0.368512\n",
      "- - - - - >Iteration:  8 ----->Partial loss: 0.341126\n",
      "- - - - - >Iteration:  9 ----->Partial loss: 0.240154\n",
      "- - - - - >Iteration:  10 ----->Partial loss: 0.228084\n",
      "- - - - - >Iteration:  11 ----->Partial loss: 0.380563\n",
      "- - - - - >Iteration:  12 ----->Partial loss: 0.295098\n",
      "- - - - - >Iteration:  13 ----->Partial loss: 0.251131\n",
      "- - - - - >Iteration:  14 ----->Partial loss: 0.310858\n",
      "- - - - - >Iteration:  15 ----->Partial loss: 0.377281\n",
      "- - - - - >Iteration:  16 ----->Partial loss: 0.485781\n",
      "- - - - - >Iteration:  17 ----->Partial loss: 0.218673\n",
      "- - - - - >Iteration:  18 ----->Partial loss: 0.337796\n",
      "- - - - - >Iteration:  19 ----->Partial loss: 0.27505\n",
      "- - - - - >Iteration:  20 ----->Partial loss: 0.362737\n",
      "- - - - - >Iteration:  21 ----->Partial loss: 0.209824\n",
      "- - - - - >Iteration:  22 ----->Partial loss: 0.334092\n",
      "- - - - - >Iteration:  23 ----->Partial loss: 0.286902\n",
      "- - - - - >Iteration:  24 ----->Partial loss: 0.379495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- - - - - >Iteration:  25 ----->Partial loss: 0.297408\n",
      "- - - - - >Iteration:  26 ----->Partial loss: 0.276105\n",
      "- - - - - >Iteration:  27 ----->Partial loss: 0.247512\n",
      "- - - - - >Iteration:  28 ----->Partial loss: 0.365383\n",
      "- - - - - >Iteration:  29 ----->Partial loss: 0.365468\n",
      "- - - - - >Iteration:  30 ----->Partial loss: 0.368259\n",
      "- - - - - >Iteration:  31 ----->Partial loss: 0.28677\n",
      "- - - - - >Iteration:  32 ----->Partial loss: 0.286648\n",
      "- - - - - >Iteration:  33 ----->Partial loss: 0.330411\n",
      "- - - - - >Iteration:  34 ----->Partial loss: 0.283954\n",
      "- - - - - >Iteration:  35 ----->Partial loss: 0.319292\n",
      "- - - - - >Iteration:  36 ----->Partial loss: 0.204543\n",
      "- - - - - >Iteration:  37 ----->Partial loss: 0.300081\n",
      "- - - - - >Iteration:  38 ----->Partial loss: 0.406092\n",
      "- - - - - >Iteration:  39 ----->Partial loss: 0.314213\n",
      "- - - - - >Iteration:  40 ----->Partial loss: 0.31268\n",
      "- - - - - >Iteration:  41 ----->Partial loss: 0.322003\n",
      "- - - - - >Iteration:  42 ----->Partial loss: 0.264875\n",
      "- - - - - >Iteration:  43 ----->Partial loss: 0.423128\n",
      "- - - - - >Iteration:  44 ----->Partial loss: 0.254608\n",
      "- - - - - >Iteration:  45 ----->Partial loss: 0.283001\n",
      "- - - - - >Iteration:  46 ----->Partial loss: 0.396939\n",
      "- - - - - >Iteration:  47 ----->Partial loss: 0.254484\n",
      "- - - - - >Iteration:  48 ----->Partial loss: 0.244373\n",
      "- - - - - >Iteration:  49 ----->Partial loss: 0.28123\n",
      "- - - - - >Iteration:  50 ----->Partial loss: 0.338689\n",
      "- - - - - >Iteration:  51 ----->Partial loss: 0.352261\n",
      "- - - - - >Iteration:  52 ----->Partial loss: 0.237324\n",
      "- - - - - >Iteration:  53 ----->Partial loss: 0.29268\n",
      "- - - - - >Iteration:  54 ----->Partial loss: 0.209265\n",
      "- - - - - >Iteration:  55 ----->Partial loss: 0.259243\n",
      "- - - - - >Iteration:  56 ----->Partial loss: 0.350594\n",
      "- - - - - >Iteration:  57 ----->Partial loss: 0.424697\n",
      "- - - - - >Iteration:  58 ----->Partial loss: 0.417177\n",
      "- - - - - >Iteration:  59 ----->Partial loss: 0.31813\n",
      "- - - - - >Iteration:  60 ----->Partial loss: 0.207048\n",
      "- - - - - >Iteration:  61 ----->Partial loss: 0.249353\n",
      "- - - - - >Iteration:  62 ----->Partial loss: 0.230377\n",
      "- - - - - >Iteration:  63 ----->Partial loss: 0.324705\n",
      "- - - - - >Iteration:  64 ----->Partial loss: 0.232761\n",
      "- - - - - >Iteration:  65 ----->Partial loss: 0.25829\n",
      "- - - - - >Iteration:  66 ----->Partial loss: 0.263471\n",
      "- - - - - >Iteration:  67 ----->Partial loss: 0.288889\n",
      "- - - - - >Iteration:  68 ----->Partial loss: 0.226468\n",
      "- - - - - >Iteration:  69 ----->Partial loss: 0.211516\n",
      "- - - - - >Iteration:  70 ----->Partial loss: 0.250563\n",
      "- - - - - >Iteration:  71 ----->Partial loss: 0.202457\n",
      "- - - - - >Iteration:  72 ----->Partial loss: 0.303578\n",
      "- - - - - >Iteration:  73 ----->Partial loss: 0.161403\n",
      "- - - - - >Iteration:  74 ----->Partial loss: 0.268321\n",
      "- - - - - >Iteration:  75 ----->Partial loss: 0.335233\n",
      "- - - - - >Iteration:  76 ----->Partial loss: 0.377749\n",
      "- - - - - >Iteration:  77 ----->Partial loss: 0.239928\n",
      "- - - - - >Iteration:  78 ----->Partial loss: 0.252811\n",
      "- - - - - >Iteration:  79 ----->Partial loss: 0.249203\n",
      "- - - - - >Iteration:  80 ----->Partial loss: 0.246453\n",
      "- - - - - >Iteration:  81 ----->Partial loss: 0.36697\n",
      "- - - - - >Iteration:  82 ----->Partial loss: 0.284701\n",
      "- - - - - >Iteration:  83 ----->Partial loss: 0.170547\n",
      "- - - - - >Iteration:  84 ----->Partial loss: 0.261182\n",
      "- - - - - >Iteration:  85 ----->Partial loss: 0.285334\n",
      "- - - - - >Iteration:  86 ----->Partial loss: 0.263956\n",
      "- - - - - >Iteration:  87 ----->Partial loss: 0.275269\n",
      "- - - - - >Iteration:  88 ----->Partial loss: 0.231621\n",
      "- - - - - >Iteration:  89 ----->Partial loss: 0.132315\n",
      "- - - - - >Iteration:  90 ----->Partial loss: 0.282736\n",
      "- - - - - >Iteration:  91 ----->Partial loss: 0.193811\n",
      "- - - - - >Iteration:  92 ----->Partial loss: 0.35253\n",
      "- - - - - >Iteration:  93 ----->Partial loss: 0.363557\n",
      "- - - - - >Iteration:  94 ----->Partial loss: 0.23805\n",
      "- - - - - >Iteration:  95 ----->Partial loss: 0.181718\n",
      "- - - - - >Iteration:  96 ----->Partial loss: 0.243938\n",
      "- - - - - >Iteration:  97 ----->Partial loss: 0.480589\n",
      "- - - - - >Iteration:  98 ----->Partial loss: 0.202792\n",
      "- - - - - >Iteration:  99 ----->Partial loss: 0.29588\n",
      "- - - - - >Iteration:  100 ----->Partial loss: 0.2493\n",
      "- - - - - >Iteration:  101 ----->Partial loss: 0.245149\n",
      "- - - - - >Iteration:  102 ----->Partial loss: 0.404765\n",
      "- - - - - >Iteration:  103 ----->Partial loss: 0.276975\n",
      "- - - - - >Iteration:  104 ----->Partial loss: 0.300412\n",
      "- - - - - >Iteration:  105 ----->Partial loss: 0.262765\n",
      "- - - - - >Iteration:  106 ----->Partial loss: 0.220346\n",
      "- - - - - >Iteration:  107 ----->Partial loss: 0.310285\n",
      "- - - - - >Iteration:  108 ----->Partial loss: 0.231484\n",
      "- - - - - >Iteration:  109 ----->Partial loss: 0.292134\n",
      "- - - - - >Iteration:  110 ----->Partial loss: 0.187567\n",
      "- - - - - >Iteration:  111 ----->Partial loss: 0.408846\n",
      "- - - - - >Iteration:  112 ----->Partial loss: 0.204617\n",
      "- - - - - >Iteration:  113 ----->Partial loss: 0.267857\n",
      "- - - - - >Iteration:  114 ----->Partial loss: 0.226954\n",
      "- - - - - >Iteration:  115 ----->Partial loss: 0.379117\n",
      "- - - - - >Iteration:  116 ----->Partial loss: 0.291172\n",
      "- - - - - >Iteration:  117 ----->Partial loss: 0.324913\n",
      "- - - - - >Iteration:  118 ----->Partial loss: 0.413652\n",
      "- - - - - >Iteration:  119 ----->Partial loss: 0.338214\n",
      "- - - - - >Iteration:  120 ----->Partial loss: 0.224346\n",
      "- - - - - >Iteration:  121 ----->Partial loss: 0.31348\n",
      "- - - - - >Iteration:  122 ----->Partial loss: 0.169182\n",
      "- - - - - >Iteration:  123 ----->Partial loss: 0.155424\n",
      "- - - - - >Iteration:  124 ----->Partial loss: 0.227648\n",
      "- - - - - >Iteration:  125 ----->Partial loss: 0.223487\n",
      "- - - - - >Iteration:  126 ----->Partial loss: 0.306589\n",
      "- - - - - >Iteration:  127 ----->Partial loss: 0.279338\n",
      "- - - - - >Iteration:  128 ----->Partial loss: 0.212716\n",
      "- - - - - >Iteration:  129 ----->Partial loss: 0.187233\n",
      "- - - - - >Iteration:  130 ----->Partial loss: 0.273485\n",
      "- - - - - >Iteration:  131 ----->Partial loss: 0.225214\n",
      "- - - - - >Iteration:  132 ----->Partial loss: 0.229418\n",
      "- - - - - >Iteration:  133 ----->Partial loss: 0.359155\n",
      "- - - - - >Iteration:  134 ----->Partial loss: 0.195172\n",
      "- - - - - >Iteration:  135 ----->Partial loss: 0.356155\n",
      "- - - - - >Iteration:  136 ----->Partial loss: 0.245546\n",
      "- - - - - >Iteration:  137 ----->Partial loss: 0.155772\n",
      "- - - - - >Iteration:  138 ----->Partial loss: 0.268303\n",
      "- - - - - >Iteration:  139 ----->Partial loss: 0.21317\n",
      "- - - - - >Iteration:  140 ----->Partial loss: 0.300223\n",
      "- - - - - >Iteration:  141 ----->Partial loss: 0.175967\n",
      "- - - - - >Iteration:  142 ----->Partial loss: 0.275966\n",
      "- - - - - >Iteration:  143 ----->Partial loss: 0.221216\n",
      "- - - - - >Iteration:  144 ----->Partial loss: 0.154969\n",
      "- - - - - >Iteration:  145 ----->Partial loss: 0.404872\n",
      "- - - - - >Iteration:  146 ----->Partial loss: 0.345798\n",
      "- - - - - >Iteration:  147 ----->Partial loss: 0.152795\n",
      "- - - - - >Iteration:  148 ----->Partial loss: 0.390769\n",
      "- - - - - >Iteration:  149 ----->Partial loss: 0.226439\n",
      "- - - - - >Iteration:  150 ----->Partial loss: 0.524191\n",
      "- - - - - >Iteration:  151 ----->Partial loss: 0.270466\n",
      "- - - - - >Iteration:  152 ----->Partial loss: 0.303092\n",
      "- - - - - >Iteration:  153 ----->Partial loss: 0.209533\n",
      "- - - - - >Iteration:  154 ----->Partial loss: 0.203289\n",
      "- - - - - >Iteration:  155 ----->Partial loss: 0.294658\n",
      "- - - - - >Iteration:  156 ----->Partial loss: 0.348735\n",
      "- - - - - >Iteration:  157 ----->Partial loss: 0.174331\n",
      "- - - - - >Iteration:  158 ----->Partial loss: 0.197434\n",
      "- - - - - >Iteration:  159 ----->Partial loss: 0.216427\n",
      "- - - - - >Iteration:  160 ----->Partial loss: 0.224236\n",
      "- - - - - >Iteration:  161 ----->Partial loss: 0.201652\n",
      "- - - - - >Iteration:  162 ----->Partial loss: 0.309718\n",
      "- - - - - >Iteration:  163 ----->Partial loss: 0.212372\n",
      "- - - - - >Iteration:  164 ----->Partial loss: 0.227552\n",
      "- - - - - >Iteration:  165 ----->Partial loss: 0.172104\n",
      "- - - - - >Iteration:  166 ----->Partial loss: 0.237463\n",
      "- - - - - >Iteration:  167 ----->Partial loss: 0.221953\n",
      "- - - - - >Iteration:  168 ----->Partial loss: 0.260221\n",
      "- - - - - >Iteration:  169 ----->Partial loss: 0.155384\n",
      "- - - - - >Iteration:  170 ----->Partial loss: 0.173628\n",
      "- - - - - >Iteration:  171 ----->Partial loss: 0.243375\n",
      "- - - - - >Iteration:  172 ----->Partial loss: 0.292679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- - - - - >Iteration:  173 ----->Partial loss: 0.18439\n",
      "- - - - - >Iteration:  174 ----->Partial loss: 0.107457\n",
      "- - - - - >Iteration:  175 ----->Partial loss: 0.178327\n",
      "- - - - - >Iteration:  176 ----->Partial loss: 0.214457\n",
      "- - - - - >Iteration:  177 ----->Partial loss: 0.152863\n",
      "- - - - - >Iteration:  178 ----->Partial loss: 0.120036\n",
      "- - - - - >Iteration:  179 ----->Partial loss: 0.218966\n",
      "- - - - - >Iteration:  180 ----->Partial loss: 0.219814\n",
      "- - - - - >Iteration:  181 ----->Partial loss: 0.219432\n",
      "- - - - - >Iteration:  182 ----->Partial loss: 0.158723\n",
      "- - - - - >Iteration:  183 ----->Partial loss: 0.191161\n",
      "- - - - - >Iteration:  184 ----->Partial loss: 0.16001\n",
      "- - - - - >Iteration:  185 ----->Partial loss: 0.187254\n",
      "- - - - - >Iteration:  186 ----->Partial loss: 0.344076\n",
      "- - - - - >Iteration:  187 ----->Partial loss: 0.196185\n",
      "- - - - - >Iteration:  188 ----->Partial loss: 0.220914\n",
      "- - - - - >Iteration:  189 ----->Partial loss: 0.275835\n",
      "- - - - - >Iteration:  190 ----->Partial loss: 0.414751\n",
      "- - - - - >Iteration:  191 ----->Partial loss: 0.217045\n",
      "- - - - - >Iteration:  192 ----->Partial loss: 0.173885\n",
      "- - - - - >Iteration:  193 ----->Partial loss: 0.174667\n",
      "- - - - - >Iteration:  194 ----->Partial loss: 0.288297\n",
      "- - - - - >Iteration:  195 ----->Partial loss: 0.387391\n",
      "- - - - - >Iteration:  196 ----->Partial loss: 0.350149\n",
      "- - - - - >Iteration:  197 ----->Partial loss: 0.196372\n",
      "- - - - - >Iteration:  198 ----->Partial loss: 0.104183\n",
      "- - - - - >Iteration:  199 ----->Partial loss: 0.121454\n",
      "- - - - - >Iteration:  200 ----->Partial loss: 0.22195\n",
      "- - - - - >Iteration:  201 ----->Partial loss: 0.20657\n",
      "- - - - - >Iteration:  202 ----->Partial loss: 0.151565\n",
      "- - - - - >Iteration:  203 ----->Partial loss: 0.22593\n",
      "- - - - - >Iteration:  204 ----->Partial loss: 0.327357\n",
      "- - - - - >Iteration:  205 ----->Partial loss: 0.282946\n",
      "- - - - - >Iteration:  206 ----->Partial loss: 0.208126\n",
      "- - - - - >Iteration:  207 ----->Partial loss: 0.212649\n",
      "- - - - - >Iteration:  208 ----->Partial loss: 0.203467\n",
      "- - - - - >Iteration:  209 ----->Partial loss: 0.189269\n",
      "- - - - - >Iteration:  210 ----->Partial loss: 0.251304\n",
      "- - - - - >Iteration:  211 ----->Partial loss: 0.209468\n",
      "- - - - - >Iteration:  212 ----->Partial loss: 0.109801\n",
      "- - - - - >Iteration:  213 ----->Partial loss: 0.162471\n",
      "- - - - - >Iteration:  214 ----->Partial loss: 0.232435\n",
      "- - - - - >Iteration:  215 ----->Partial loss: 0.205356\n",
      "- - - - - >Iteration:  216 ----->Partial loss: 0.230415\n",
      "- - - - - >Iteration:  217 ----->Partial loss: 0.242726\n",
      "- - - - - >Iteration:  218 ----->Partial loss: 0.297016\n",
      "- - - - - >Iteration:  219 ----->Partial loss: 0.233742\n",
      "- - - - - >Iteration:  220 ----->Partial loss: 0.240722\n",
      "- - - - - >Iteration:  221 ----->Partial loss: 0.199449\n",
      "- - - - - >Iteration:  222 ----->Partial loss: 0.236087\n",
      "- - - - - >Iteration:  223 ----->Partial loss: 0.166998\n",
      "- - - - - >Iteration:  224 ----->Partial loss: 0.204158\n",
      "- - - - - >Iteration:  225 ----->Partial loss: 0.0998628\n",
      "- - - - - >Iteration:  226 ----->Partial loss: 0.149442\n",
      "- - - - - >Iteration:  227 ----->Partial loss: 0.221666\n",
      "- - - - - >Iteration:  228 ----->Partial loss: 0.186395\n",
      "- - - - - >Iteration:  229 ----->Partial loss: 0.15496\n",
      "- - - - - >Iteration:  230 ----->Partial loss: 0.159275\n",
      "- - - - - >Iteration:  231 ----->Partial loss: 0.196857\n",
      "- - - - - >Iteration:  232 ----->Partial loss: 0.228551\n",
      "- - - - - >Iteration:  233 ----->Partial loss: 0.259244\n",
      "- - - - - >Iteration:  234 ----->Partial loss: 0.40119\n",
      "- - - - - >Iteration:  235 ----->Partial loss: 0.148109\n",
      "- - - - - >Iteration:  236 ----->Partial loss: 0.192364\n",
      "- - - - - >Iteration:  237 ----->Partial loss: 0.1452\n",
      "- - - - - >Iteration:  238 ----->Partial loss: 0.150424\n",
      "- - - - - >Iteration:  239 ----->Partial loss: 0.214656\n",
      "- - - - - >Iteration:  240 ----->Partial loss: 0.201731\n",
      "- - - - - >Iteration:  241 ----->Partial loss: 0.157667\n",
      "- - - - - >Iteration:  242 ----->Partial loss: 0.184477\n",
      "- - - - - >Iteration:  243 ----->Partial loss: 0.205282\n",
      "- - - - - >Iteration:  244 ----->Partial loss: 0.208121\n",
      "- - - - - >Iteration:  245 ----->Partial loss: 0.190215\n",
      "- - - - - >Iteration:  246 ----->Partial loss: 0.24767\n",
      "- - - - - >Iteration:  247 ----->Partial loss: 0.283765\n",
      "- - - - - >Iteration:  248 ----->Partial loss: 0.263601\n",
      "- - - - - >Iteration:  249 ----->Partial loss: 0.278048\n",
      "- - - - - >Iteration:  250 ----->Partial loss: 0.0991488\n",
      "- - - - - >Iteration:  251 ----->Partial loss: 0.198273\n",
      "- - - - - >Iteration:  252 ----->Partial loss: 0.196561\n",
      "- - - - - >Iteration:  253 ----->Partial loss: 0.234871\n",
      "- - - - - >Iteration:  254 ----->Partial loss: 0.155912\n",
      "- - - - - >Iteration:  255 ----->Partial loss: 0.18786\n",
      "- - - - - >Iteration:  256 ----->Partial loss: 0.156355\n",
      "- - - - - >Iteration:  257 ----->Partial loss: 0.206781\n",
      "- - - - - >Iteration:  258 ----->Partial loss: 0.0900585\n",
      "- - - - - >Iteration:  259 ----->Partial loss: 0.157825\n",
      "- - - - - >Iteration:  260 ----->Partial loss: 0.0830093\n",
      "- - - - - >Iteration:  261 ----->Partial loss: 0.0800426\n",
      "- - - - - >Iteration:  262 ----->Partial loss: 0.249944\n",
      "- - - - - >Iteration:  263 ----->Partial loss: 0.365542\n",
      "- - - - - >Iteration:  264 ----->Partial loss: 0.274803\n",
      "- - - - - >Iteration:  265 ----->Partial loss: 0.243856\n",
      "- - - - - >Iteration:  266 ----->Partial loss: 0.16908\n",
      "- - - - - >Iteration:  267 ----->Partial loss: 0.224331\n",
      "- - - - - >Iteration:  268 ----->Partial loss: 0.25499\n",
      "- - - - - >Iteration:  269 ----->Partial loss: 0.235144\n",
      "- - - - - >Iteration:  270 ----->Partial loss: 0.445928\n",
      "- - - - - >Iteration:  271 ----->Partial loss: 0.176066\n",
      "- - - - - >Iteration:  272 ----->Partial loss: 0.133972\n",
      "- - - - - >Iteration:  273 ----->Partial loss: 0.150774\n",
      "- - - - - >Iteration:  274 ----->Partial loss: 0.271553\n",
      "- - - - - >Iteration:  275 ----->Partial loss: 0.279414\n",
      "- - - - - >Iteration:  276 ----->Partial loss: 0.644758\n",
      "- - - - - >Iteration:  277 ----->Partial loss: 0.284942\n",
      "- - - - - >Iteration:  278 ----->Partial loss: 0.1745\n",
      "- - - - - >Iteration:  279 ----->Partial loss: 0.182707\n",
      "- - - - - >Iteration:  280 ----->Partial loss: 0.177415\n",
      "- - - - - >Iteration:  281 ----->Partial loss: 0.159062\n",
      "- - - - - >Iteration:  282 ----->Partial loss: 0.325746\n",
      "- - - - - >Iteration:  283 ----->Partial loss: 0.189021\n",
      "- - - - - >Iteration:  284 ----->Partial loss: 0.214177\n",
      "- - - - - >Iteration:  285 ----->Partial loss: 0.133963\n",
      "- - - - - >Iteration:  286 ----->Partial loss: 0.242956\n",
      "- - - - - >Iteration:  287 ----->Partial loss: 0.242584\n",
      "- - - - - >Iteration:  288 ----->Partial loss: 0.118863\n",
      "- - - - - >Iteration:  289 ----->Partial loss: 0.204225\n",
      "***************\n",
      "Epoch:  5  of  20 training loss:  0.252146710239\n",
      "***************\n",
      "- - - - - >Iteration:  1 ----->Partial loss: 0.243688\n",
      "- - - - - >Iteration:  2 ----->Partial loss: 0.212612\n",
      "- - - - - >Iteration:  3 ----->Partial loss: 0.173639\n",
      "- - - - - >Iteration:  4 ----->Partial loss: 0.142699\n",
      "- - - - - >Iteration:  5 ----->Partial loss: 0.179301\n",
      "- - - - - >Iteration:  6 ----->Partial loss: 0.226326\n",
      "- - - - - >Iteration:  7 ----->Partial loss: 0.141774\n",
      "- - - - - >Iteration:  8 ----->Partial loss: 0.147659\n",
      "- - - - - >Iteration:  9 ----->Partial loss: 0.388803\n",
      "- - - - - >Iteration:  10 ----->Partial loss: 0.130177\n",
      "- - - - - >Iteration:  11 ----->Partial loss: 0.13943\n",
      "- - - - - >Iteration:  12 ----->Partial loss: 0.22865\n",
      "- - - - - >Iteration:  13 ----->Partial loss: 0.143332\n",
      "- - - - - >Iteration:  14 ----->Partial loss: 0.222214\n",
      "- - - - - >Iteration:  15 ----->Partial loss: 0.245249\n",
      "- - - - - >Iteration:  16 ----->Partial loss: 0.199443\n",
      "- - - - - >Iteration:  17 ----->Partial loss: 0.313709\n",
      "- - - - - >Iteration:  18 ----->Partial loss: 0.161057\n",
      "- - - - - >Iteration:  19 ----->Partial loss: 0.173696\n",
      "- - - - - >Iteration:  20 ----->Partial loss: 0.211814\n",
      "- - - - - >Iteration:  21 ----->Partial loss: 0.376849\n",
      "- - - - - >Iteration:  22 ----->Partial loss: 0.198742\n",
      "- - - - - >Iteration:  23 ----->Partial loss: 0.156394\n",
      "- - - - - >Iteration:  24 ----->Partial loss: 0.171847\n",
      "- - - - - >Iteration:  25 ----->Partial loss: 0.175055\n",
      "- - - - - >Iteration:  26 ----->Partial loss: 0.211621\n",
      "- - - - - >Iteration:  27 ----->Partial loss: 0.137984\n",
      "- - - - - >Iteration:  28 ----->Partial loss: 0.160377\n",
      "- - - - - >Iteration:  29 ----->Partial loss: 0.227431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- - - - - >Iteration:  30 ----->Partial loss: 0.180138\n",
      "- - - - - >Iteration:  31 ----->Partial loss: 0.274659\n",
      "- - - - - >Iteration:  32 ----->Partial loss: 0.239159\n",
      "- - - - - >Iteration:  33 ----->Partial loss: 0.151437\n",
      "- - - - - >Iteration:  34 ----->Partial loss: 0.221261\n",
      "- - - - - >Iteration:  35 ----->Partial loss: 0.198756\n",
      "- - - - - >Iteration:  36 ----->Partial loss: 0.185609\n",
      "- - - - - >Iteration:  37 ----->Partial loss: 0.261255\n",
      "- - - - - >Iteration:  38 ----->Partial loss: 0.130335\n",
      "- - - - - >Iteration:  39 ----->Partial loss: 0.189043\n",
      "- - - - - >Iteration:  40 ----->Partial loss: 0.141964\n",
      "- - - - - >Iteration:  41 ----->Partial loss: 0.314605\n",
      "- - - - - >Iteration:  42 ----->Partial loss: 0.163923\n",
      "- - - - - >Iteration:  43 ----->Partial loss: 0.178315\n",
      "- - - - - >Iteration:  44 ----->Partial loss: 0.219975\n",
      "- - - - - >Iteration:  45 ----->Partial loss: 0.145857\n",
      "- - - - - >Iteration:  46 ----->Partial loss: 0.222266\n",
      "- - - - - >Iteration:  47 ----->Partial loss: 0.224521\n",
      "- - - - - >Iteration:  48 ----->Partial loss: 0.20568\n",
      "- - - - - >Iteration:  49 ----->Partial loss: 0.174372\n",
      "- - - - - >Iteration:  50 ----->Partial loss: 0.246565\n",
      "- - - - - >Iteration:  51 ----->Partial loss: 0.192301\n",
      "- - - - - >Iteration:  52 ----->Partial loss: 0.275335\n",
      "- - - - - >Iteration:  53 ----->Partial loss: 0.143975\n",
      "- - - - - >Iteration:  54 ----->Partial loss: 0.249028\n",
      "- - - - - >Iteration:  55 ----->Partial loss: 0.169941\n",
      "- - - - - >Iteration:  56 ----->Partial loss: 0.17528\n",
      "- - - - - >Iteration:  57 ----->Partial loss: 0.12091\n",
      "- - - - - >Iteration:  58 ----->Partial loss: 0.114205\n",
      "- - - - - >Iteration:  59 ----->Partial loss: 0.254748\n",
      "- - - - - >Iteration:  60 ----->Partial loss: 0.206781\n",
      "- - - - - >Iteration:  61 ----->Partial loss: 0.232066\n",
      "- - - - - >Iteration:  62 ----->Partial loss: 0.167189\n",
      "- - - - - >Iteration:  63 ----->Partial loss: 0.175416\n",
      "- - - - - >Iteration:  64 ----->Partial loss: 0.188058\n",
      "- - - - - >Iteration:  65 ----->Partial loss: 0.115887\n",
      "- - - - - >Iteration:  66 ----->Partial loss: 0.185029\n",
      "- - - - - >Iteration:  67 ----->Partial loss: 0.299039\n",
      "- - - - - >Iteration:  68 ----->Partial loss: 0.25185\n",
      "- - - - - >Iteration:  69 ----->Partial loss: 0.222873\n",
      "- - - - - >Iteration:  70 ----->Partial loss: 0.145931\n",
      "- - - - - >Iteration:  71 ----->Partial loss: 0.213357\n",
      "- - - - - >Iteration:  72 ----->Partial loss: 0.173476\n",
      "- - - - - >Iteration:  73 ----->Partial loss: 0.204106\n",
      "- - - - - >Iteration:  74 ----->Partial loss: 0.124426\n",
      "- - - - - >Iteration:  75 ----->Partial loss: 0.200742\n",
      "- - - - - >Iteration:  76 ----->Partial loss: 0.210978\n",
      "- - - - - >Iteration:  77 ----->Partial loss: 0.153193\n",
      "- - - - - >Iteration:  78 ----->Partial loss: 0.366466\n",
      "- - - - - >Iteration:  79 ----->Partial loss: 0.139275\n",
      "- - - - - >Iteration:  80 ----->Partial loss: 0.216658\n",
      "- - - - - >Iteration:  81 ----->Partial loss: 0.162357\n",
      "- - - - - >Iteration:  82 ----->Partial loss: 0.217372\n",
      "- - - - - >Iteration:  83 ----->Partial loss: 0.142565\n",
      "- - - - - >Iteration:  84 ----->Partial loss: 0.171231\n",
      "- - - - - >Iteration:  85 ----->Partial loss: 0.14301\n",
      "- - - - - >Iteration:  86 ----->Partial loss: 0.198682\n",
      "- - - - - >Iteration:  87 ----->Partial loss: 0.13398\n",
      "- - - - - >Iteration:  88 ----->Partial loss: 0.0832437\n",
      "- - - - - >Iteration:  89 ----->Partial loss: 0.223942\n",
      "- - - - - >Iteration:  90 ----->Partial loss: 0.184622\n",
      "- - - - - >Iteration:  91 ----->Partial loss: 0.193935\n",
      "- - - - - >Iteration:  92 ----->Partial loss: 0.154413\n",
      "- - - - - >Iteration:  93 ----->Partial loss: 0.0713822\n",
      "- - - - - >Iteration:  94 ----->Partial loss: 0.0690382\n",
      "- - - - - >Iteration:  95 ----->Partial loss: 0.264034\n",
      "- - - - - >Iteration:  96 ----->Partial loss: 0.140424\n",
      "- - - - - >Iteration:  97 ----->Partial loss: 0.142409\n",
      "- - - - - >Iteration:  98 ----->Partial loss: 0.216769\n",
      "- - - - - >Iteration:  99 ----->Partial loss: 0.268516\n",
      "- - - - - >Iteration:  100 ----->Partial loss: 0.13535\n",
      "- - - - - >Iteration:  101 ----->Partial loss: 0.153781\n",
      "- - - - - >Iteration:  102 ----->Partial loss: 0.117587\n",
      "- - - - - >Iteration:  103 ----->Partial loss: 0.179663\n",
      "- - - - - >Iteration:  104 ----->Partial loss: 0.218455\n",
      "- - - - - >Iteration:  105 ----->Partial loss: 0.187817\n",
      "- - - - - >Iteration:  106 ----->Partial loss: 0.0863926\n",
      "- - - - - >Iteration:  107 ----->Partial loss: 0.185407\n",
      "- - - - - >Iteration:  108 ----->Partial loss: 0.111533\n",
      "- - - - - >Iteration:  109 ----->Partial loss: 0.188388\n",
      "- - - - - >Iteration:  110 ----->Partial loss: 0.111426\n",
      "- - - - - >Iteration:  111 ----->Partial loss: 0.22256\n",
      "- - - - - >Iteration:  112 ----->Partial loss: 0.296029\n",
      "- - - - - >Iteration:  113 ----->Partial loss: 0.197783\n",
      "- - - - - >Iteration:  114 ----->Partial loss: 0.18433\n",
      "- - - - - >Iteration:  115 ----->Partial loss: 0.165758\n",
      "- - - - - >Iteration:  116 ----->Partial loss: 0.155608\n",
      "- - - - - >Iteration:  117 ----->Partial loss: 0.245792\n",
      "- - - - - >Iteration:  118 ----->Partial loss: 0.147587\n",
      "- - - - - >Iteration:  119 ----->Partial loss: 0.152437\n",
      "- - - - - >Iteration:  120 ----->Partial loss: 0.150456\n",
      "- - - - - >Iteration:  121 ----->Partial loss: 0.126007\n",
      "- - - - - >Iteration:  122 ----->Partial loss: 0.129073\n",
      "- - - - - >Iteration:  123 ----->Partial loss: 0.0908461\n",
      "- - - - - >Iteration:  124 ----->Partial loss: 0.151677\n",
      "- - - - - >Iteration:  125 ----->Partial loss: 0.0778837\n",
      "- - - - - >Iteration:  126 ----->Partial loss: 0.1985\n",
      "- - - - - >Iteration:  127 ----->Partial loss: 0.428458\n",
      "- - - - - >Iteration:  128 ----->Partial loss: 0.101568\n",
      "- - - - - >Iteration:  129 ----->Partial loss: 0.163652\n",
      "- - - - - >Iteration:  130 ----->Partial loss: 0.0951052\n",
      "- - - - - >Iteration:  131 ----->Partial loss: 0.168814\n",
      "- - - - - >Iteration:  132 ----->Partial loss: 0.22142\n",
      "- - - - - >Iteration:  133 ----->Partial loss: 0.197556\n",
      "- - - - - >Iteration:  134 ----->Partial loss: 0.188626\n",
      "- - - - - >Iteration:  135 ----->Partial loss: 0.199945\n",
      "- - - - - >Iteration:  136 ----->Partial loss: 0.173986\n",
      "- - - - - >Iteration:  137 ----->Partial loss: 0.150406\n",
      "- - - - - >Iteration:  138 ----->Partial loss: 0.0903536\n",
      "- - - - - >Iteration:  139 ----->Partial loss: 0.173387\n",
      "- - - - - >Iteration:  140 ----->Partial loss: 0.196133\n",
      "- - - - - >Iteration:  141 ----->Partial loss: 0.246753\n",
      "- - - - - >Iteration:  142 ----->Partial loss: 0.133828\n",
      "- - - - - >Iteration:  143 ----->Partial loss: 0.173618\n",
      "- - - - - >Iteration:  144 ----->Partial loss: 0.200372\n",
      "- - - - - >Iteration:  145 ----->Partial loss: 0.100388\n",
      "- - - - - >Iteration:  146 ----->Partial loss: 0.160249\n",
      "- - - - - >Iteration:  147 ----->Partial loss: 0.14637\n",
      "- - - - - >Iteration:  148 ----->Partial loss: 0.17111\n",
      "- - - - - >Iteration:  149 ----->Partial loss: 0.145383\n",
      "- - - - - >Iteration:  150 ----->Partial loss: 0.383378\n",
      "- - - - - >Iteration:  151 ----->Partial loss: 0.134704\n",
      "- - - - - >Iteration:  152 ----->Partial loss: 0.152477\n",
      "- - - - - >Iteration:  153 ----->Partial loss: 0.107166\n",
      "- - - - - >Iteration:  154 ----->Partial loss: 0.132091\n",
      "- - - - - >Iteration:  155 ----->Partial loss: 0.0955407\n",
      "- - - - - >Iteration:  156 ----->Partial loss: 0.132264\n",
      "- - - - - >Iteration:  157 ----->Partial loss: 0.178737\n",
      "- - - - - >Iteration:  158 ----->Partial loss: 0.222629\n",
      "- - - - - >Iteration:  159 ----->Partial loss: 0.184677\n",
      "- - - - - >Iteration:  160 ----->Partial loss: 0.11424\n",
      "- - - - - >Iteration:  161 ----->Partial loss: 0.0642557\n",
      "- - - - - >Iteration:  162 ----->Partial loss: 0.136277\n",
      "- - - - - >Iteration:  163 ----->Partial loss: 0.197305\n",
      "- - - - - >Iteration:  164 ----->Partial loss: 0.205466\n",
      "- - - - - >Iteration:  165 ----->Partial loss: 0.175633\n",
      "- - - - - >Iteration:  166 ----->Partial loss: 0.133352\n",
      "- - - - - >Iteration:  167 ----->Partial loss: 0.209114\n",
      "- - - - - >Iteration:  168 ----->Partial loss: 0.205131\n",
      "- - - - - >Iteration:  169 ----->Partial loss: 0.22509\n",
      "- - - - - >Iteration:  170 ----->Partial loss: 0.10753\n",
      "- - - - - >Iteration:  171 ----->Partial loss: 0.19567\n",
      "- - - - - >Iteration:  172 ----->Partial loss: 0.151053\n",
      "- - - - - >Iteration:  173 ----->Partial loss: 0.187621\n",
      "- - - - - >Iteration:  174 ----->Partial loss: 0.149463\n",
      "- - - - - >Iteration:  175 ----->Partial loss: 0.224891\n",
      "- - - - - >Iteration:  176 ----->Partial loss: 0.104248\n",
      "- - - - - >Iteration:  177 ----->Partial loss: 0.125056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- - - - - >Iteration:  178 ----->Partial loss: 0.17851\n",
      "- - - - - >Iteration:  179 ----->Partial loss: 0.121701\n",
      "- - - - - >Iteration:  180 ----->Partial loss: 0.167591\n",
      "- - - - - >Iteration:  181 ----->Partial loss: 0.0752265\n",
      "- - - - - >Iteration:  182 ----->Partial loss: 0.120638\n",
      "- - - - - >Iteration:  183 ----->Partial loss: 0.230165\n",
      "- - - - - >Iteration:  184 ----->Partial loss: 0.122733\n",
      "- - - - - >Iteration:  185 ----->Partial loss: 0.100022\n",
      "- - - - - >Iteration:  186 ----->Partial loss: 0.164019\n",
      "- - - - - >Iteration:  187 ----->Partial loss: 0.257158\n",
      "- - - - - >Iteration:  188 ----->Partial loss: 0.211437\n",
      "- - - - - >Iteration:  189 ----->Partial loss: 0.152877\n",
      "- - - - - >Iteration:  190 ----->Partial loss: 0.168722\n",
      "- - - - - >Iteration:  191 ----->Partial loss: 0.150276\n",
      "- - - - - >Iteration:  192 ----->Partial loss: 0.100821\n",
      "- - - - - >Iteration:  193 ----->Partial loss: 0.108871\n",
      "- - - - - >Iteration:  194 ----->Partial loss: 0.160117\n",
      "- - - - - >Iteration:  195 ----->Partial loss: 0.149529\n",
      "- - - - - >Iteration:  196 ----->Partial loss: 0.249549\n",
      "- - - - - >Iteration:  197 ----->Partial loss: 0.0872698\n",
      "- - - - - >Iteration:  198 ----->Partial loss: 0.157632\n",
      "- - - - - >Iteration:  199 ----->Partial loss: 0.189326\n",
      "- - - - - >Iteration:  200 ----->Partial loss: 0.127842\n",
      "- - - - - >Iteration:  201 ----->Partial loss: 0.167677\n",
      "- - - - - >Iteration:  202 ----->Partial loss: 0.10791\n",
      "- - - - - >Iteration:  203 ----->Partial loss: 0.139418\n",
      "- - - - - >Iteration:  204 ----->Partial loss: 0.151286\n",
      "- - - - - >Iteration:  205 ----->Partial loss: 0.084132\n",
      "- - - - - >Iteration:  206 ----->Partial loss: 0.169696\n",
      "- - - - - >Iteration:  207 ----->Partial loss: 0.0837812\n",
      "- - - - - >Iteration:  208 ----->Partial loss: 0.106463\n",
      "- - - - - >Iteration:  209 ----->Partial loss: 0.213251\n",
      "- - - - - >Iteration:  210 ----->Partial loss: 0.168622\n",
      "- - - - - >Iteration:  211 ----->Partial loss: 0.140394\n",
      "- - - - - >Iteration:  212 ----->Partial loss: 0.185398\n",
      "- - - - - >Iteration:  213 ----->Partial loss: 0.26982\n",
      "- - - - - >Iteration:  214 ----->Partial loss: 0.147724\n",
      "- - - - - >Iteration:  215 ----->Partial loss: 0.144392\n",
      "- - - - - >Iteration:  216 ----->Partial loss: 0.157968\n",
      "- - - - - >Iteration:  217 ----->Partial loss: 0.141585\n",
      "- - - - - >Iteration:  218 ----->Partial loss: 0.314515\n",
      "- - - - - >Iteration:  219 ----->Partial loss: 0.250748\n",
      "- - - - - >Iteration:  220 ----->Partial loss: 0.131679\n",
      "- - - - - >Iteration:  221 ----->Partial loss: 0.133707\n",
      "- - - - - >Iteration:  222 ----->Partial loss: 0.317154\n",
      "- - - - - >Iteration:  223 ----->Partial loss: 0.0677518\n",
      "- - - - - >Iteration:  224 ----->Partial loss: 0.213756\n",
      "- - - - - >Iteration:  225 ----->Partial loss: 0.13676\n",
      "- - - - - >Iteration:  226 ----->Partial loss: 0.1544\n",
      "- - - - - >Iteration:  227 ----->Partial loss: 0.298677\n",
      "- - - - - >Iteration:  228 ----->Partial loss: 0.164113\n",
      "- - - - - >Iteration:  229 ----->Partial loss: 0.135832\n",
      "- - - - - >Iteration:  230 ----->Partial loss: 0.154646\n",
      "- - - - - >Iteration:  231 ----->Partial loss: 0.131677\n",
      "- - - - - >Iteration:  232 ----->Partial loss: 0.202831\n",
      "- - - - - >Iteration:  233 ----->Partial loss: 0.129999\n",
      "- - - - - >Iteration:  234 ----->Partial loss: 0.143338\n",
      "- - - - - >Iteration:  235 ----->Partial loss: 0.0952785\n",
      "- - - - - >Iteration:  236 ----->Partial loss: 0.180534\n",
      "- - - - - >Iteration:  237 ----->Partial loss: 0.0703954\n",
      "- - - - - >Iteration:  238 ----->Partial loss: 0.323954\n",
      "- - - - - >Iteration:  239 ----->Partial loss: 0.209091\n",
      "- - - - - >Iteration:  240 ----->Partial loss: 0.279247\n",
      "- - - - - >Iteration:  241 ----->Partial loss: 0.268759\n",
      "- - - - - >Iteration:  242 ----->Partial loss: 0.0762966\n",
      "- - - - - >Iteration:  243 ----->Partial loss: 0.110372\n",
      "- - - - - >Iteration:  244 ----->Partial loss: 0.101933\n",
      "- - - - - >Iteration:  245 ----->Partial loss: 0.16503\n",
      "- - - - - >Iteration:  246 ----->Partial loss: 0.0686756\n",
      "- - - - - >Iteration:  247 ----->Partial loss: 0.184395\n",
      "- - - - - >Iteration:  248 ----->Partial loss: 0.304521\n",
      "- - - - - >Iteration:  249 ----->Partial loss: 0.130985\n",
      "- - - - - >Iteration:  250 ----->Partial loss: 0.226029\n",
      "- - - - - >Iteration:  251 ----->Partial loss: 0.153657\n",
      "- - - - - >Iteration:  252 ----->Partial loss: 0.278012\n",
      "- - - - - >Iteration:  253 ----->Partial loss: 0.142301\n",
      "- - - - - >Iteration:  254 ----->Partial loss: 0.120763\n",
      "- - - - - >Iteration:  255 ----->Partial loss: 0.149179\n",
      "- - - - - >Iteration:  256 ----->Partial loss: 0.181106\n",
      "- - - - - >Iteration:  257 ----->Partial loss: 0.198357\n",
      "- - - - - >Iteration:  258 ----->Partial loss: 0.321669\n",
      "- - - - - >Iteration:  259 ----->Partial loss: 0.158211\n",
      "- - - - - >Iteration:  260 ----->Partial loss: 0.128738\n",
      "- - - - - >Iteration:  261 ----->Partial loss: 0.213744\n",
      "- - - - - >Iteration:  262 ----->Partial loss: 0.18713\n",
      "- - - - - >Iteration:  263 ----->Partial loss: 0.329543\n",
      "- - - - - >Iteration:  264 ----->Partial loss: 0.150395\n",
      "- - - - - >Iteration:  265 ----->Partial loss: 0.181377\n",
      "- - - - - >Iteration:  266 ----->Partial loss: 0.190723\n",
      "- - - - - >Iteration:  267 ----->Partial loss: 0.0918886\n",
      "- - - - - >Iteration:  268 ----->Partial loss: 0.207083\n",
      "- - - - - >Iteration:  269 ----->Partial loss: 0.199743\n",
      "- - - - - >Iteration:  270 ----->Partial loss: 0.220457\n",
      "- - - - - >Iteration:  271 ----->Partial loss: 0.156433\n",
      "- - - - - >Iteration:  272 ----->Partial loss: 0.114319\n",
      "- - - - - >Iteration:  273 ----->Partial loss: 0.151806\n",
      "- - - - - >Iteration:  274 ----->Partial loss: 0.194979\n",
      "- - - - - >Iteration:  275 ----->Partial loss: 0.124432\n",
      "- - - - - >Iteration:  276 ----->Partial loss: 0.177821\n",
      "- - - - - >Iteration:  277 ----->Partial loss: 0.150214\n",
      "- - - - - >Iteration:  278 ----->Partial loss: 0.0723586\n",
      "- - - - - >Iteration:  279 ----->Partial loss: 0.128011\n",
      "- - - - - >Iteration:  280 ----->Partial loss: 0.139545\n",
      "- - - - - >Iteration:  281 ----->Partial loss: 0.131599\n",
      "- - - - - >Iteration:  282 ----->Partial loss: 0.0592809\n",
      "- - - - - >Iteration:  283 ----->Partial loss: 0.124328\n",
      "- - - - - >Iteration:  284 ----->Partial loss: 0.104729\n",
      "- - - - - >Iteration:  285 ----->Partial loss: 0.117758\n",
      "- - - - - >Iteration:  286 ----->Partial loss: 0.0617436\n",
      "- - - - - >Iteration:  287 ----->Partial loss: 0.20438\n",
      "- - - - - >Iteration:  288 ----->Partial loss: 0.136537\n",
      "- - - - - >Iteration:  289 ----->Partial loss: 0.282397\n",
      "***************\n",
      "Epoch:  6  of  20 training loss:  0.175286365692\n",
      "***************\n",
      "- - - - - >Iteration:  1 ----->Partial loss: 0.110211\n",
      "- - - - - >Iteration:  2 ----->Partial loss: 0.083799\n",
      "- - - - - >Iteration:  3 ----->Partial loss: 0.160726\n",
      "- - - - - >Iteration:  4 ----->Partial loss: 0.295894\n",
      "- - - - - >Iteration:  5 ----->Partial loss: 0.128708\n",
      "- - - - - >Iteration:  6 ----->Partial loss: 0.130281\n",
      "- - - - - >Iteration:  7 ----->Partial loss: 0.168002\n",
      "- - - - - >Iteration:  8 ----->Partial loss: 0.145786\n",
      "- - - - - >Iteration:  9 ----->Partial loss: 0.19703\n",
      "- - - - - >Iteration:  10 ----->Partial loss: 0.11457\n",
      "- - - - - >Iteration:  11 ----->Partial loss: 0.178415\n",
      "- - - - - >Iteration:  12 ----->Partial loss: 0.10987\n",
      "- - - - - >Iteration:  13 ----->Partial loss: 0.17293\n",
      "- - - - - >Iteration:  14 ----->Partial loss: 0.189409\n",
      "- - - - - >Iteration:  15 ----->Partial loss: 0.137127\n",
      "- - - - - >Iteration:  16 ----->Partial loss: 0.176423\n",
      "- - - - - >Iteration:  17 ----->Partial loss: 0.190739\n",
      "- - - - - >Iteration:  18 ----->Partial loss: 0.0961355\n",
      "- - - - - >Iteration:  19 ----->Partial loss: 0.109755\n",
      "- - - - - >Iteration:  20 ----->Partial loss: 0.16223\n",
      "- - - - - >Iteration:  21 ----->Partial loss: 0.109542\n",
      "- - - - - >Iteration:  22 ----->Partial loss: 0.17074\n",
      "- - - - - >Iteration:  23 ----->Partial loss: 0.107771\n",
      "- - - - - >Iteration:  24 ----->Partial loss: 0.0998596\n",
      "- - - - - >Iteration:  25 ----->Partial loss: 0.071002\n",
      "- - - - - >Iteration:  26 ----->Partial loss: 0.334812\n",
      "- - - - - >Iteration:  27 ----->Partial loss: 0.343158\n",
      "- - - - - >Iteration:  28 ----->Partial loss: 0.0906787\n",
      "- - - - - >Iteration:  29 ----->Partial loss: 0.155152\n",
      "- - - - - >Iteration:  30 ----->Partial loss: 0.13738\n",
      "- - - - - >Iteration:  31 ----->Partial loss: 0.27109\n",
      "- - - - - >Iteration:  32 ----->Partial loss: 0.125873\n",
      "- - - - - >Iteration:  33 ----->Partial loss: 0.194818\n",
      "- - - - - >Iteration:  34 ----->Partial loss: 0.148697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- - - - - >Iteration:  35 ----->Partial loss: 0.170228\n",
      "- - - - - >Iteration:  36 ----->Partial loss: 0.100597\n",
      "- - - - - >Iteration:  37 ----->Partial loss: 0.136808\n",
      "- - - - - >Iteration:  38 ----->Partial loss: 0.0772318\n",
      "- - - - - >Iteration:  39 ----->Partial loss: 0.252188\n",
      "- - - - - >Iteration:  40 ----->Partial loss: 0.241959\n",
      "- - - - - >Iteration:  41 ----->Partial loss: 0.263411\n",
      "- - - - - >Iteration:  42 ----->Partial loss: 0.103483\n",
      "- - - - - >Iteration:  43 ----->Partial loss: 0.136349\n",
      "- - - - - >Iteration:  44 ----->Partial loss: 0.0828929\n",
      "- - - - - >Iteration:  45 ----->Partial loss: 0.101442\n",
      "- - - - - >Iteration:  46 ----->Partial loss: 0.126161\n",
      "- - - - - >Iteration:  47 ----->Partial loss: 0.198334\n",
      "- - - - - >Iteration:  48 ----->Partial loss: 0.247401\n",
      "- - - - - >Iteration:  49 ----->Partial loss: 0.117226\n",
      "- - - - - >Iteration:  50 ----->Partial loss: 0.0796103\n",
      "- - - - - >Iteration:  51 ----->Partial loss: 0.12691\n",
      "- - - - - >Iteration:  52 ----->Partial loss: 0.171918\n",
      "- - - - - >Iteration:  53 ----->Partial loss: 0.0597672\n",
      "- - - - - >Iteration:  54 ----->Partial loss: 0.150247\n",
      "- - - - - >Iteration:  55 ----->Partial loss: 0.122943\n",
      "- - - - - >Iteration:  56 ----->Partial loss: 0.259337\n",
      "- - - - - >Iteration:  57 ----->Partial loss: 0.246191\n",
      "- - - - - >Iteration:  58 ----->Partial loss: 0.311116\n",
      "- - - - - >Iteration:  59 ----->Partial loss: 0.126215\n",
      "- - - - - >Iteration:  60 ----->Partial loss: 0.138053\n",
      "- - - - - >Iteration:  61 ----->Partial loss: 0.294386\n",
      "- - - - - >Iteration:  62 ----->Partial loss: 0.186833\n",
      "- - - - - >Iteration:  63 ----->Partial loss: 0.147043\n",
      "- - - - - >Iteration:  64 ----->Partial loss: 0.207983\n",
      "- - - - - >Iteration:  65 ----->Partial loss: 0.120118\n",
      "- - - - - >Iteration:  66 ----->Partial loss: 0.133433\n",
      "- - - - - >Iteration:  67 ----->Partial loss: 0.320972\n",
      "- - - - - >Iteration:  68 ----->Partial loss: 0.164499\n",
      "- - - - - >Iteration:  69 ----->Partial loss: 0.226307\n",
      "- - - - - >Iteration:  70 ----->Partial loss: 0.0934712\n",
      "- - - - - >Iteration:  71 ----->Partial loss: 0.135543\n",
      "- - - - - >Iteration:  72 ----->Partial loss: 0.161453\n",
      "- - - - - >Iteration:  73 ----->Partial loss: 0.213309\n",
      "- - - - - >Iteration:  74 ----->Partial loss: 0.286383\n",
      "- - - - - >Iteration:  75 ----->Partial loss: 0.158591\n",
      "- - - - - >Iteration:  76 ----->Partial loss: 0.185779\n",
      "- - - - - >Iteration:  77 ----->Partial loss: 0.136558\n",
      "- - - - - >Iteration:  78 ----->Partial loss: 0.0939905\n",
      "- - - - - >Iteration:  79 ----->Partial loss: 0.0899267\n",
      "- - - - - >Iteration:  80 ----->Partial loss: 0.0599945\n",
      "- - - - - >Iteration:  81 ----->Partial loss: 0.252989\n",
      "- - - - - >Iteration:  82 ----->Partial loss: 0.0731955\n",
      "- - - - - >Iteration:  83 ----->Partial loss: 0.155407\n",
      "- - - - - >Iteration:  84 ----->Partial loss: 0.100831\n",
      "- - - - - >Iteration:  85 ----->Partial loss: 0.195718\n",
      "- - - - - >Iteration:  86 ----->Partial loss: 0.0874716\n",
      "- - - - - >Iteration:  87 ----->Partial loss: 0.166305\n",
      "- - - - - >Iteration:  88 ----->Partial loss: 0.103579\n",
      "- - - - - >Iteration:  89 ----->Partial loss: 0.176582\n",
      "- - - - - >Iteration:  90 ----->Partial loss: 0.153317\n",
      "- - - - - >Iteration:  91 ----->Partial loss: 0.157325\n",
      "- - - - - >Iteration:  92 ----->Partial loss: 0.0774276\n",
      "- - - - - >Iteration:  93 ----->Partial loss: 0.14465\n",
      "- - - - - >Iteration:  94 ----->Partial loss: 0.115313\n",
      "- - - - - >Iteration:  95 ----->Partial loss: 0.0657765\n",
      "- - - - - >Iteration:  96 ----->Partial loss: 0.0697941\n",
      "- - - - - >Iteration:  97 ----->Partial loss: 0.1165\n",
      "- - - - - >Iteration:  98 ----->Partial loss: 0.0726243\n",
      "- - - - - >Iteration:  99 ----->Partial loss: 0.0857268\n",
      "- - - - - >Iteration:  100 ----->Partial loss: 0.234364\n",
      "- - - - - >Iteration:  101 ----->Partial loss: 0.0999969\n",
      "- - - - - >Iteration:  102 ----->Partial loss: 0.116794\n",
      "- - - - - >Iteration:  103 ----->Partial loss: 0.136833\n",
      "- - - - - >Iteration:  104 ----->Partial loss: 0.0565207\n",
      "- - - - - >Iteration:  105 ----->Partial loss: 0.0902843\n",
      "- - - - - >Iteration:  106 ----->Partial loss: 0.114081\n",
      "- - - - - >Iteration:  107 ----->Partial loss: 0.200988\n",
      "- - - - - >Iteration:  108 ----->Partial loss: 0.136245\n",
      "- - - - - >Iteration:  109 ----->Partial loss: 0.172888\n",
      "- - - - - >Iteration:  110 ----->Partial loss: 0.081727\n",
      "- - - - - >Iteration:  111 ----->Partial loss: 0.0833157\n",
      "- - - - - >Iteration:  112 ----->Partial loss: 0.0912044\n",
      "- - - - - >Iteration:  113 ----->Partial loss: 0.113415\n",
      "- - - - - >Iteration:  114 ----->Partial loss: 0.17323\n",
      "- - - - - >Iteration:  115 ----->Partial loss: 0.174666\n",
      "- - - - - >Iteration:  116 ----->Partial loss: 0.186105\n",
      "- - - - - >Iteration:  117 ----->Partial loss: 0.130015\n",
      "- - - - - >Iteration:  118 ----->Partial loss: 0.121313\n",
      "- - - - - >Iteration:  119 ----->Partial loss: 0.175662\n",
      "- - - - - >Iteration:  120 ----->Partial loss: 0.156631\n",
      "- - - - - >Iteration:  121 ----->Partial loss: 0.100469\n",
      "- - - - - >Iteration:  122 ----->Partial loss: 0.123925\n",
      "- - - - - >Iteration:  123 ----->Partial loss: 0.136519\n",
      "- - - - - >Iteration:  124 ----->Partial loss: 0.123662\n",
      "- - - - - >Iteration:  125 ----->Partial loss: 0.112501\n",
      "- - - - - >Iteration:  126 ----->Partial loss: 0.120874\n",
      "- - - - - >Iteration:  127 ----->Partial loss: 0.0878797\n",
      "- - - - - >Iteration:  128 ----->Partial loss: 0.0968869\n",
      "- - - - - >Iteration:  129 ----->Partial loss: 0.128343\n",
      "- - - - - >Iteration:  130 ----->Partial loss: 0.0925383\n",
      "- - - - - >Iteration:  131 ----->Partial loss: 0.091744\n",
      "- - - - - >Iteration:  132 ----->Partial loss: 0.12906\n",
      "- - - - - >Iteration:  133 ----->Partial loss: 0.128083\n",
      "- - - - - >Iteration:  134 ----->Partial loss: 0.0955407\n",
      "- - - - - >Iteration:  135 ----->Partial loss: 0.421652\n",
      "- - - - - >Iteration:  136 ----->Partial loss: 0.0519719\n",
      "- - - - - >Iteration:  137 ----->Partial loss: 0.070425\n",
      "- - - - - >Iteration:  138 ----->Partial loss: 0.198603\n",
      "- - - - - >Iteration:  139 ----->Partial loss: 0.209989\n",
      "- - - - - >Iteration:  140 ----->Partial loss: 0.132315\n",
      "- - - - - >Iteration:  141 ----->Partial loss: 0.150948\n",
      "- - - - - >Iteration:  142 ----->Partial loss: 0.0746799\n",
      "- - - - - >Iteration:  143 ----->Partial loss: 0.139657\n",
      "- - - - - >Iteration:  144 ----->Partial loss: 0.14711\n",
      "- - - - - >Iteration:  145 ----->Partial loss: 0.0807885\n",
      "- - - - - >Iteration:  146 ----->Partial loss: 0.185796\n",
      "- - - - - >Iteration:  147 ----->Partial loss: 0.117866\n",
      "- - - - - >Iteration:  148 ----->Partial loss: 0.0793109\n",
      "- - - - - >Iteration:  149 ----->Partial loss: 0.124583\n",
      "- - - - - >Iteration:  150 ----->Partial loss: 0.16531\n",
      "- - - - - >Iteration:  151 ----->Partial loss: 0.136539\n",
      "- - - - - >Iteration:  152 ----->Partial loss: 0.149698\n",
      "- - - - - >Iteration:  153 ----->Partial loss: 0.118284\n",
      "- - - - - >Iteration:  154 ----->Partial loss: 0.235718\n",
      "- - - - - >Iteration:  155 ----->Partial loss: 0.0804029\n",
      "- - - - - >Iteration:  156 ----->Partial loss: 0.0992048\n",
      "- - - - - >Iteration:  157 ----->Partial loss: 0.138873\n",
      "- - - - - >Iteration:  158 ----->Partial loss: 0.140275\n",
      "- - - - - >Iteration:  159 ----->Partial loss: 0.055063\n",
      "- - - - - >Iteration:  160 ----->Partial loss: 0.264843\n",
      "- - - - - >Iteration:  161 ----->Partial loss: 0.221058\n",
      "- - - - - >Iteration:  162 ----->Partial loss: 0.15412\n",
      "- - - - - >Iteration:  163 ----->Partial loss: 0.0568456\n",
      "- - - - - >Iteration:  164 ----->Partial loss: 0.138938\n",
      "- - - - - >Iteration:  165 ----->Partial loss: 0.3321\n",
      "- - - - - >Iteration:  166 ----->Partial loss: 0.0735006\n",
      "- - - - - >Iteration:  167 ----->Partial loss: 0.152256\n",
      "- - - - - >Iteration:  168 ----->Partial loss: 0.191675\n",
      "- - - - - >Iteration:  169 ----->Partial loss: 0.142208\n",
      "- - - - - >Iteration:  170 ----->Partial loss: 0.103491\n",
      "- - - - - >Iteration:  171 ----->Partial loss: 0.07781\n",
      "- - - - - >Iteration:  172 ----->Partial loss: 0.131149\n",
      "- - - - - >Iteration:  173 ----->Partial loss: 0.141975\n",
      "- - - - - >Iteration:  174 ----->Partial loss: 0.135735\n",
      "- - - - - >Iteration:  175 ----->Partial loss: 0.467738\n",
      "- - - - - >Iteration:  176 ----->Partial loss: 0.123515\n",
      "- - - - - >Iteration:  177 ----->Partial loss: 0.0944746\n",
      "- - - - - >Iteration:  178 ----->Partial loss: 0.178158\n",
      "- - - - - >Iteration:  179 ----->Partial loss: 0.132276\n",
      "- - - - - >Iteration:  180 ----->Partial loss: 0.0935439\n",
      "- - - - - >Iteration:  181 ----->Partial loss: 0.130361\n",
      "- - - - - >Iteration:  182 ----->Partial loss: 0.154161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- - - - - >Iteration:  183 ----->Partial loss: 0.146674\n",
      "- - - - - >Iteration:  184 ----->Partial loss: 0.114983\n",
      "- - - - - >Iteration:  185 ----->Partial loss: 0.13475\n",
      "- - - - - >Iteration:  186 ----->Partial loss: 0.278223\n",
      "- - - - - >Iteration:  187 ----->Partial loss: 0.124637\n",
      "- - - - - >Iteration:  188 ----->Partial loss: 0.112383\n",
      "- - - - - >Iteration:  189 ----->Partial loss: 0.0996103\n",
      "- - - - - >Iteration:  190 ----->Partial loss: 0.119338\n",
      "- - - - - >Iteration:  191 ----->Partial loss: 0.114113\n",
      "- - - - - >Iteration:  192 ----->Partial loss: 0.173136\n",
      "- - - - - >Iteration:  193 ----->Partial loss: 0.187283\n",
      "- - - - - >Iteration:  194 ----->Partial loss: 0.164417\n",
      "- - - - - >Iteration:  195 ----->Partial loss: 0.147737\n",
      "- - - - - >Iteration:  196 ----->Partial loss: 0.105574\n",
      "- - - - - >Iteration:  197 ----->Partial loss: 0.110618\n",
      "- - - - - >Iteration:  198 ----->Partial loss: 0.142757\n",
      "- - - - - >Iteration:  199 ----->Partial loss: 0.244117\n",
      "- - - - - >Iteration:  200 ----->Partial loss: 0.128433\n",
      "- - - - - >Iteration:  201 ----->Partial loss: 0.0613716\n",
      "- - - - - >Iteration:  202 ----->Partial loss: 0.192118\n",
      "- - - - - >Iteration:  203 ----->Partial loss: 0.193782\n",
      "- - - - - >Iteration:  204 ----->Partial loss: 0.146277\n",
      "- - - - - >Iteration:  205 ----->Partial loss: 0.190047\n",
      "- - - - - >Iteration:  206 ----->Partial loss: 0.0978632\n",
      "- - - - - >Iteration:  207 ----->Partial loss: 0.20777\n",
      "- - - - - >Iteration:  208 ----->Partial loss: 0.146665\n",
      "- - - - - >Iteration:  209 ----->Partial loss: 0.129974\n",
      "- - - - - >Iteration:  210 ----->Partial loss: 0.10387\n",
      "- - - - - >Iteration:  211 ----->Partial loss: 0.107017\n",
      "- - - - - >Iteration:  212 ----->Partial loss: 0.136979\n",
      "- - - - - >Iteration:  213 ----->Partial loss: 0.0806599\n",
      "- - - - - >Iteration:  214 ----->Partial loss: 0.075187\n",
      "- - - - - >Iteration:  215 ----->Partial loss: 0.0700132\n",
      "- - - - - >Iteration:  216 ----->Partial loss: 0.31614\n",
      "- - - - - >Iteration:  217 ----->Partial loss: 0.355787\n",
      "- - - - - >Iteration:  218 ----->Partial loss: 0.0564777\n",
      "- - - - - >Iteration:  219 ----->Partial loss: 0.105634\n",
      "- - - - - >Iteration:  220 ----->Partial loss: 0.113686\n",
      "- - - - - >Iteration:  221 ----->Partial loss: 0.115558\n",
      "- - - - - >Iteration:  222 ----->Partial loss: 0.190157\n",
      "- - - - - >Iteration:  223 ----->Partial loss: 0.0676784\n",
      "- - - - - >Iteration:  224 ----->Partial loss: 0.158077\n",
      "- - - - - >Iteration:  225 ----->Partial loss: 0.138855\n",
      "- - - - - >Iteration:  226 ----->Partial loss: 0.11804\n",
      "- - - - - >Iteration:  227 ----->Partial loss: 0.0990429\n",
      "- - - - - >Iteration:  228 ----->Partial loss: 0.237836\n",
      "- - - - - >Iteration:  229 ----->Partial loss: 0.237355\n",
      "- - - - - >Iteration:  230 ----->Partial loss: 0.138186\n",
      "- - - - - >Iteration:  231 ----->Partial loss: 0.158653\n",
      "- - - - - >Iteration:  232 ----->Partial loss: 0.11657\n",
      "- - - - - >Iteration:  233 ----->Partial loss: 0.0838064\n",
      "- - - - - >Iteration:  234 ----->Partial loss: 0.108555\n",
      "- - - - - >Iteration:  235 ----->Partial loss: 0.135934\n",
      "- - - - - >Iteration:  236 ----->Partial loss: 0.0646564\n",
      "- - - - - >Iteration:  237 ----->Partial loss: 0.173255\n",
      "- - - - - >Iteration:  238 ----->Partial loss: 0.14293\n",
      "- - - - - >Iteration:  239 ----->Partial loss: 0.110792\n",
      "- - - - - >Iteration:  240 ----->Partial loss: 0.072663\n",
      "- - - - - >Iteration:  241 ----->Partial loss: 0.0509008\n",
      "- - - - - >Iteration:  242 ----->Partial loss: 0.108117\n",
      "- - - - - >Iteration:  243 ----->Partial loss: 0.0963246\n",
      "- - - - - >Iteration:  244 ----->Partial loss: 0.184151\n",
      "- - - - - >Iteration:  245 ----->Partial loss: 0.15737\n",
      "- - - - - >Iteration:  246 ----->Partial loss: 0.179491\n",
      "- - - - - >Iteration:  247 ----->Partial loss: 0.195037\n",
      "- - - - - >Iteration:  248 ----->Partial loss: 0.131931\n",
      "- - - - - >Iteration:  249 ----->Partial loss: 0.111631\n",
      "- - - - - >Iteration:  250 ----->Partial loss: 0.058002\n",
      "- - - - - >Iteration:  251 ----->Partial loss: 0.142002\n",
      "- - - - - >Iteration:  252 ----->Partial loss: 0.158824\n",
      "- - - - - >Iteration:  253 ----->Partial loss: 0.176778\n",
      "- - - - - >Iteration:  254 ----->Partial loss: 0.113661\n",
      "- - - - - >Iteration:  255 ----->Partial loss: 0.138935\n",
      "- - - - - >Iteration:  256 ----->Partial loss: 0.131632\n",
      "- - - - - >Iteration:  257 ----->Partial loss: 0.137863\n",
      "- - - - - >Iteration:  258 ----->Partial loss: 0.23554\n",
      "- - - - - >Iteration:  259 ----->Partial loss: 0.0908746\n",
      "- - - - - >Iteration:  260 ----->Partial loss: 0.0818026\n",
      "- - - - - >Iteration:  261 ----->Partial loss: 0.138259\n",
      "- - - - - >Iteration:  262 ----->Partial loss: 0.0844423\n",
      "- - - - - >Iteration:  263 ----->Partial loss: 0.161468\n",
      "- - - - - >Iteration:  264 ----->Partial loss: 0.116802\n",
      "- - - - - >Iteration:  265 ----->Partial loss: 0.082178\n",
      "- - - - - >Iteration:  266 ----->Partial loss: 0.111301\n",
      "- - - - - >Iteration:  267 ----->Partial loss: 0.142395\n",
      "- - - - - >Iteration:  268 ----->Partial loss: 0.121839\n",
      "- - - - - >Iteration:  269 ----->Partial loss: 0.134367\n",
      "- - - - - >Iteration:  270 ----->Partial loss: 0.179535\n",
      "- - - - - >Iteration:  271 ----->Partial loss: 0.0854324\n",
      "- - - - - >Iteration:  272 ----->Partial loss: 0.0643462\n",
      "- - - - - >Iteration:  273 ----->Partial loss: 0.14302\n",
      "- - - - - >Iteration:  274 ----->Partial loss: 0.146156\n",
      "- - - - - >Iteration:  275 ----->Partial loss: 0.168619\n",
      "- - - - - >Iteration:  276 ----->Partial loss: 0.143033\n",
      "- - - - - >Iteration:  277 ----->Partial loss: 0.20877\n",
      "- - - - - >Iteration:  278 ----->Partial loss: 0.154782\n",
      "- - - - - >Iteration:  279 ----->Partial loss: 0.133693\n",
      "- - - - - >Iteration:  280 ----->Partial loss: 0.127568\n",
      "- - - - - >Iteration:  281 ----->Partial loss: 0.129018\n",
      "- - - - - >Iteration:  282 ----->Partial loss: 0.156617\n",
      "- - - - - >Iteration:  283 ----->Partial loss: 0.238033\n",
      "- - - - - >Iteration:  284 ----->Partial loss: 0.0803481\n",
      "- - - - - >Iteration:  285 ----->Partial loss: 0.0982431\n",
      "- - - - - >Iteration:  286 ----->Partial loss: 0.0835581\n",
      "- - - - - >Iteration:  287 ----->Partial loss: 0.114091\n",
      "- - - - - >Iteration:  288 ----->Partial loss: 0.058079\n",
      "- - - - - >Iteration:  289 ----->Partial loss: 0.0957233\n",
      "***************\n",
      "Epoch:  7  of  20 training loss:  0.143779653154\n",
      "***************\n",
      "- - - - - >Iteration:  1 ----->Partial loss: 0.121823\n",
      "- - - - - >Iteration:  2 ----->Partial loss: 0.133558\n",
      "- - - - - >Iteration:  3 ----->Partial loss: 0.153965\n",
      "- - - - - >Iteration:  4 ----->Partial loss: 0.112837\n",
      "- - - - - >Iteration:  5 ----->Partial loss: 0.0935575\n",
      "- - - - - >Iteration:  6 ----->Partial loss: 0.175586\n",
      "- - - - - >Iteration:  7 ----->Partial loss: 0.262327\n",
      "- - - - - >Iteration:  8 ----->Partial loss: 0.165879\n",
      "- - - - - >Iteration:  9 ----->Partial loss: 0.0731039\n",
      "- - - - - >Iteration:  10 ----->Partial loss: 0.118167\n",
      "- - - - - >Iteration:  11 ----->Partial loss: 0.124944\n",
      "- - - - - >Iteration:  12 ----->Partial loss: 0.163062\n",
      "- - - - - >Iteration:  13 ----->Partial loss: 0.059603\n",
      "- - - - - >Iteration:  14 ----->Partial loss: 0.0752757\n",
      "- - - - - >Iteration:  15 ----->Partial loss: 0.113313\n",
      "- - - - - >Iteration:  16 ----->Partial loss: 0.0468357\n",
      "- - - - - >Iteration:  17 ----->Partial loss: 0.128708\n",
      "- - - - - >Iteration:  18 ----->Partial loss: 0.176308\n",
      "- - - - - >Iteration:  19 ----->Partial loss: 0.100886\n",
      "- - - - - >Iteration:  20 ----->Partial loss: 0.0478271\n",
      "- - - - - >Iteration:  21 ----->Partial loss: 0.0813187\n",
      "- - - - - >Iteration:  22 ----->Partial loss: 0.110854\n",
      "- - - - - >Iteration:  23 ----->Partial loss: 0.209816\n",
      "- - - - - >Iteration:  24 ----->Partial loss: 0.0810161\n",
      "- - - - - >Iteration:  25 ----->Partial loss: 0.105886\n",
      "- - - - - >Iteration:  26 ----->Partial loss: 0.0654299\n",
      "- - - - - >Iteration:  27 ----->Partial loss: 0.15971\n",
      "- - - - - >Iteration:  28 ----->Partial loss: 0.0649457\n",
      "- - - - - >Iteration:  29 ----->Partial loss: 0.131636\n",
      "- - - - - >Iteration:  30 ----->Partial loss: 0.17536\n",
      "- - - - - >Iteration:  31 ----->Partial loss: 0.112367\n",
      "- - - - - >Iteration:  32 ----->Partial loss: 0.269305\n",
      "- - - - - >Iteration:  33 ----->Partial loss: 0.0946693\n",
      "- - - - - >Iteration:  34 ----->Partial loss: 0.213803\n",
      "- - - - - >Iteration:  35 ----->Partial loss: 0.173544\n",
      "- - - - - >Iteration:  36 ----->Partial loss: 0.112456\n",
      "- - - - - >Iteration:  37 ----->Partial loss: 0.16086\n",
      "- - - - - >Iteration:  38 ----->Partial loss: 0.137969\n",
      "- - - - - >Iteration:  39 ----->Partial loss: 0.130779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- - - - - >Iteration:  40 ----->Partial loss: 0.129708\n",
      "- - - - - >Iteration:  41 ----->Partial loss: 0.124839\n",
      "- - - - - >Iteration:  42 ----->Partial loss: 0.172882\n",
      "- - - - - >Iteration:  43 ----->Partial loss: 0.0741989\n",
      "- - - - - >Iteration:  44 ----->Partial loss: 0.127892\n",
      "- - - - - >Iteration:  45 ----->Partial loss: 0.199446\n",
      "- - - - - >Iteration:  46 ----->Partial loss: 0.138636\n",
      "- - - - - >Iteration:  47 ----->Partial loss: 0.123702\n",
      "- - - - - >Iteration:  48 ----->Partial loss: 0.0955807\n",
      "- - - - - >Iteration:  49 ----->Partial loss: 0.273792\n",
      "- - - - - >Iteration:  50 ----->Partial loss: 0.085175\n",
      "- - - - - >Iteration:  51 ----->Partial loss: 0.147158\n",
      "- - - - - >Iteration:  52 ----->Partial loss: 0.0858899\n",
      "- - - - - >Iteration:  53 ----->Partial loss: 0.109733\n",
      "- - - - - >Iteration:  54 ----->Partial loss: 0.149059\n",
      "- - - - - >Iteration:  55 ----->Partial loss: 0.254305\n",
      "- - - - - >Iteration:  56 ----->Partial loss: 0.0731273\n",
      "- - - - - >Iteration:  57 ----->Partial loss: 0.160721\n",
      "- - - - - >Iteration:  58 ----->Partial loss: 0.0659125\n",
      "- - - - - >Iteration:  59 ----->Partial loss: 0.0789064\n",
      "- - - - - >Iteration:  60 ----->Partial loss: 0.137933\n",
      "- - - - - >Iteration:  61 ----->Partial loss: 0.108992\n",
      "- - - - - >Iteration:  62 ----->Partial loss: 0.145924\n",
      "- - - - - >Iteration:  63 ----->Partial loss: 0.0962674\n",
      "- - - - - >Iteration:  64 ----->Partial loss: 0.095216\n",
      "- - - - - >Iteration:  65 ----->Partial loss: 0.109827\n",
      "- - - - - >Iteration:  66 ----->Partial loss: 0.116908\n",
      "- - - - - >Iteration:  67 ----->Partial loss: 0.127857\n",
      "- - - - - >Iteration:  68 ----->Partial loss: 0.058338\n",
      "- - - - - >Iteration:  69 ----->Partial loss: 0.210272\n",
      "- - - - - >Iteration:  70 ----->Partial loss: 0.145358\n",
      "- - - - - >Iteration:  71 ----->Partial loss: 0.135784\n",
      "- - - - - >Iteration:  72 ----->Partial loss: 0.0836635\n",
      "- - - - - >Iteration:  73 ----->Partial loss: 0.0505941\n",
      "- - - - - >Iteration:  74 ----->Partial loss: 0.1614\n",
      "- - - - - >Iteration:  75 ----->Partial loss: 0.0593503\n",
      "- - - - - >Iteration:  76 ----->Partial loss: 0.19509\n",
      "- - - - - >Iteration:  77 ----->Partial loss: 0.1676\n",
      "- - - - - >Iteration:  78 ----->Partial loss: 0.0846251\n",
      "- - - - - >Iteration:  79 ----->Partial loss: 0.138227\n",
      "- - - - - >Iteration:  80 ----->Partial loss: 0.144828\n",
      "- - - - - >Iteration:  81 ----->Partial loss: 0.0607259\n",
      "- - - - - >Iteration:  82 ----->Partial loss: 0.108472\n",
      "- - - - - >Iteration:  83 ----->Partial loss: 0.0877685\n",
      "- - - - - >Iteration:  84 ----->Partial loss: 0.159195\n",
      "- - - - - >Iteration:  85 ----->Partial loss: 0.153288\n",
      "- - - - - >Iteration:  86 ----->Partial loss: 0.240979\n",
      "- - - - - >Iteration:  87 ----->Partial loss: 0.0785579\n",
      "- - - - - >Iteration:  88 ----->Partial loss: 0.148461\n",
      "- - - - - >Iteration:  89 ----->Partial loss: 0.0573579\n",
      "- - - - - >Iteration:  90 ----->Partial loss: 0.143171\n",
      "- - - - - >Iteration:  91 ----->Partial loss: 0.129002\n",
      "- - - - - >Iteration:  92 ----->Partial loss: 0.0616565\n",
      "- - - - - >Iteration:  93 ----->Partial loss: 0.194339\n",
      "- - - - - >Iteration:  94 ----->Partial loss: 0.0552212\n",
      "- - - - - >Iteration:  95 ----->Partial loss: 0.172689\n",
      "- - - - - >Iteration:  96 ----->Partial loss: 0.162222\n",
      "- - - - - >Iteration:  97 ----->Partial loss: 0.0708246\n",
      "- - - - - >Iteration:  98 ----->Partial loss: 0.125272\n",
      "- - - - - >Iteration:  99 ----->Partial loss: 0.0756139\n",
      "- - - - - >Iteration:  100 ----->Partial loss: 0.24057\n",
      "- - - - - >Iteration:  101 ----->Partial loss: 0.170097\n",
      "- - - - - >Iteration:  102 ----->Partial loss: 0.0787649\n",
      "- - - - - >Iteration:  103 ----->Partial loss: 0.0924391\n",
      "- - - - - >Iteration:  104 ----->Partial loss: 0.155058\n",
      "- - - - - >Iteration:  105 ----->Partial loss: 0.0608469\n",
      "- - - - - >Iteration:  106 ----->Partial loss: 0.189705\n",
      "- - - - - >Iteration:  107 ----->Partial loss: 0.0983323\n",
      "- - - - - >Iteration:  108 ----->Partial loss: 0.0777484\n",
      "- - - - - >Iteration:  109 ----->Partial loss: 0.225522\n",
      "- - - - - >Iteration:  110 ----->Partial loss: 0.0679877\n",
      "- - - - - >Iteration:  111 ----->Partial loss: 0.180441\n",
      "- - - - - >Iteration:  112 ----->Partial loss: 0.177556\n",
      "- - - - - >Iteration:  113 ----->Partial loss: 0.0638419\n",
      "- - - - - >Iteration:  114 ----->Partial loss: 0.238568\n",
      "- - - - - >Iteration:  115 ----->Partial loss: 0.115415\n",
      "- - - - - >Iteration:  116 ----->Partial loss: 0.0955599\n",
      "- - - - - >Iteration:  117 ----->Partial loss: 0.268273\n",
      "- - - - - >Iteration:  118 ----->Partial loss: 0.260262\n",
      "- - - - - >Iteration:  119 ----->Partial loss: 0.0774844\n",
      "- - - - - >Iteration:  120 ----->Partial loss: 0.134308\n",
      "- - - - - >Iteration:  121 ----->Partial loss: 0.134095\n",
      "- - - - - >Iteration:  122 ----->Partial loss: 0.0771799\n",
      "- - - - - >Iteration:  123 ----->Partial loss: 0.0971108\n",
      "- - - - - >Iteration:  124 ----->Partial loss: 0.10657\n",
      "- - - - - >Iteration:  125 ----->Partial loss: 0.128209\n",
      "- - - - - >Iteration:  126 ----->Partial loss: 0.0610276\n",
      "- - - - - >Iteration:  127 ----->Partial loss: 0.0476499\n",
      "- - - - - >Iteration:  128 ----->Partial loss: 0.508223\n",
      "- - - - - >Iteration:  129 ----->Partial loss: 0.0739081\n",
      "- - - - - >Iteration:  130 ----->Partial loss: 0.0712462\n",
      "- - - - - >Iteration:  131 ----->Partial loss: 0.113429\n",
      "- - - - - >Iteration:  132 ----->Partial loss: 0.0589107\n",
      "- - - - - >Iteration:  133 ----->Partial loss: 0.123685\n",
      "- - - - - >Iteration:  134 ----->Partial loss: 0.115758\n",
      "- - - - - >Iteration:  135 ----->Partial loss: 0.121817\n",
      "- - - - - >Iteration:  136 ----->Partial loss: 0.0648373\n",
      "- - - - - >Iteration:  137 ----->Partial loss: 0.0669258\n",
      "- - - - - >Iteration:  138 ----->Partial loss: 0.149873\n",
      "- - - - - >Iteration:  139 ----->Partial loss: 0.134867\n",
      "- - - - - >Iteration:  140 ----->Partial loss: 0.0817334\n",
      "- - - - - >Iteration:  141 ----->Partial loss: 0.0495349\n",
      "- - - - - >Iteration:  142 ----->Partial loss: 0.117682\n",
      "- - - - - >Iteration:  143 ----->Partial loss: 0.213787\n",
      "- - - - - >Iteration:  144 ----->Partial loss: 0.153166\n",
      "- - - - - >Iteration:  145 ----->Partial loss: 0.106903\n",
      "- - - - - >Iteration:  146 ----->Partial loss: 0.0993789\n",
      "- - - - - >Iteration:  147 ----->Partial loss: 0.0594839\n",
      "- - - - - >Iteration:  148 ----->Partial loss: 0.10463\n",
      "- - - - - >Iteration:  149 ----->Partial loss: 0.0794681\n",
      "- - - - - >Iteration:  150 ----->Partial loss: 0.226381\n",
      "- - - - - >Iteration:  151 ----->Partial loss: 0.159308\n",
      "- - - - - >Iteration:  152 ----->Partial loss: 0.114075\n",
      "- - - - - >Iteration:  153 ----->Partial loss: 0.17712\n",
      "- - - - - >Iteration:  154 ----->Partial loss: 0.124346\n",
      "- - - - - >Iteration:  155 ----->Partial loss: 0.120173\n",
      "- - - - - >Iteration:  156 ----->Partial loss: 0.110902\n",
      "- - - - - >Iteration:  157 ----->Partial loss: 0.0934559\n",
      "- - - - - >Iteration:  158 ----->Partial loss: 0.122732\n",
      "- - - - - >Iteration:  159 ----->Partial loss: 0.0878531\n",
      "- - - - - >Iteration:  160 ----->Partial loss: 0.149624\n",
      "- - - - - >Iteration:  161 ----->Partial loss: 0.0516331\n",
      "- - - - - >Iteration:  162 ----->Partial loss: 0.10862\n",
      "- - - - - >Iteration:  163 ----->Partial loss: 0.110034\n",
      "- - - - - >Iteration:  164 ----->Partial loss: 0.101795\n",
      "- - - - - >Iteration:  165 ----->Partial loss: 0.116188\n",
      "- - - - - >Iteration:  166 ----->Partial loss: 0.140722\n",
      "- - - - - >Iteration:  167 ----->Partial loss: 0.170254\n",
      "- - - - - >Iteration:  168 ----->Partial loss: 0.198908\n",
      "- - - - - >Iteration:  169 ----->Partial loss: 0.124279\n",
      "- - - - - >Iteration:  170 ----->Partial loss: 0.187536\n",
      "- - - - - >Iteration:  171 ----->Partial loss: 0.171802\n",
      "- - - - - >Iteration:  172 ----->Partial loss: 0.133429\n",
      "- - - - - >Iteration:  173 ----->Partial loss: 0.307498\n",
      "- - - - - >Iteration:  174 ----->Partial loss: 0.183566\n",
      "- - - - - >Iteration:  175 ----->Partial loss: 0.0849566\n",
      "- - - - - >Iteration:  176 ----->Partial loss: 0.119771\n",
      "- - - - - >Iteration:  177 ----->Partial loss: 0.138373\n",
      "- - - - - >Iteration:  178 ----->Partial loss: 0.103954\n",
      "- - - - - >Iteration:  179 ----->Partial loss: 0.171296\n",
      "- - - - - >Iteration:  180 ----->Partial loss: 0.142435\n",
      "- - - - - >Iteration:  181 ----->Partial loss: 0.14076\n",
      "- - - - - >Iteration:  182 ----->Partial loss: 0.181724\n",
      "- - - - - >Iteration:  183 ----->Partial loss: 0.147787\n",
      "- - - - - >Iteration:  184 ----->Partial loss: 0.0823536\n",
      "- - - - - >Iteration:  185 ----->Partial loss: 0.188456\n",
      "- - - - - >Iteration:  186 ----->Partial loss: 0.14205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- - - - - >Iteration:  187 ----->Partial loss: 0.0835698\n",
      "- - - - - >Iteration:  188 ----->Partial loss: 0.0780936\n",
      "- - - - - >Iteration:  189 ----->Partial loss: 0.076994\n",
      "- - - - - >Iteration:  190 ----->Partial loss: 0.200451\n",
      "- - - - - >Iteration:  191 ----->Partial loss: 0.0704643\n",
      "- - - - - >Iteration:  192 ----->Partial loss: 0.0685126\n",
      "- - - - - >Iteration:  193 ----->Partial loss: 0.119267\n",
      "- - - - - >Iteration:  194 ----->Partial loss: 0.148414\n",
      "- - - - - >Iteration:  195 ----->Partial loss: 0.0575143\n",
      "- - - - - >Iteration:  196 ----->Partial loss: 0.0669272\n",
      "- - - - - >Iteration:  197 ----->Partial loss: 0.0738939\n",
      "- - - - - >Iteration:  198 ----->Partial loss: 0.215883\n",
      "- - - - - >Iteration:  199 ----->Partial loss: 0.148884\n",
      "- - - - - >Iteration:  200 ----->Partial loss: 0.123659\n",
      "- - - - - >Iteration:  201 ----->Partial loss: 0.111542\n",
      "- - - - - >Iteration:  202 ----->Partial loss: 0.0786821\n",
      "- - - - - >Iteration:  203 ----->Partial loss: 0.117866\n",
      "- - - - - >Iteration:  204 ----->Partial loss: 0.0674488\n",
      "- - - - - >Iteration:  205 ----->Partial loss: 0.152682\n",
      "- - - - - >Iteration:  206 ----->Partial loss: 0.129846\n",
      "- - - - - >Iteration:  207 ----->Partial loss: 0.0741904\n",
      "- - - - - >Iteration:  208 ----->Partial loss: 0.081207\n",
      "- - - - - >Iteration:  209 ----->Partial loss: 0.168013\n",
      "- - - - - >Iteration:  210 ----->Partial loss: 0.276475\n",
      "- - - - - >Iteration:  211 ----->Partial loss: 0.148465\n",
      "- - - - - >Iteration:  212 ----->Partial loss: 0.0955073\n",
      "- - - - - >Iteration:  213 ----->Partial loss: 0.0957938\n",
      "- - - - - >Iteration:  214 ----->Partial loss: 0.11095\n",
      "- - - - - >Iteration:  215 ----->Partial loss: 0.297028\n",
      "- - - - - >Iteration:  216 ----->Partial loss: 0.131334\n",
      "- - - - - >Iteration:  217 ----->Partial loss: 0.107132\n",
      "- - - - - >Iteration:  218 ----->Partial loss: 0.118064\n",
      "- - - - - >Iteration:  219 ----->Partial loss: 0.080817\n",
      "- - - - - >Iteration:  220 ----->Partial loss: 0.188667\n",
      "- - - - - >Iteration:  221 ----->Partial loss: 0.142208\n",
      "- - - - - >Iteration:  222 ----->Partial loss: 0.0715428\n",
      "- - - - - >Iteration:  223 ----->Partial loss: 0.0949448\n",
      "- - - - - >Iteration:  224 ----->Partial loss: 0.102703\n",
      "- - - - - >Iteration:  225 ----->Partial loss: 0.118947\n",
      "- - - - - >Iteration:  226 ----->Partial loss: 0.0775651\n",
      "- - - - - >Iteration:  227 ----->Partial loss: 0.0928379\n",
      "- - - - - >Iteration:  228 ----->Partial loss: 0.121746\n",
      "- - - - - >Iteration:  229 ----->Partial loss: 0.0724189\n",
      "- - - - - >Iteration:  230 ----->Partial loss: 0.121915\n",
      "- - - - - >Iteration:  231 ----->Partial loss: 0.073469\n",
      "- - - - - >Iteration:  232 ----->Partial loss: 0.10422\n",
      "- - - - - >Iteration:  233 ----->Partial loss: 0.0698348\n",
      "- - - - - >Iteration:  234 ----->Partial loss: 0.113727\n",
      "- - - - - >Iteration:  235 ----->Partial loss: 0.0689438\n",
      "- - - - - >Iteration:  236 ----->Partial loss: 0.12374\n",
      "- - - - - >Iteration:  237 ----->Partial loss: 0.0737431\n",
      "- - - - - >Iteration:  238 ----->Partial loss: 0.0752329\n",
      "- - - - - >Iteration:  239 ----->Partial loss: 0.1494\n",
      "- - - - - >Iteration:  240 ----->Partial loss: 0.0504752\n",
      "- - - - - >Iteration:  241 ----->Partial loss: 0.0845725\n",
      "- - - - - >Iteration:  242 ----->Partial loss: 0.04895\n",
      "- - - - - >Iteration:  243 ----->Partial loss: 0.110082\n",
      "- - - - - >Iteration:  244 ----->Partial loss: 0.0885984\n",
      "- - - - - >Iteration:  245 ----->Partial loss: 0.0863541\n",
      "- - - - - >Iteration:  246 ----->Partial loss: 0.142017\n",
      "- - - - - >Iteration:  247 ----->Partial loss: 0.10516\n",
      "- - - - - >Iteration:  248 ----->Partial loss: 0.0931235\n",
      "- - - - - >Iteration:  249 ----->Partial loss: 0.0951465\n",
      "- - - - - >Iteration:  250 ----->Partial loss: 0.0463634\n",
      "- - - - - >Iteration:  251 ----->Partial loss: 0.0959755\n",
      "- - - - - >Iteration:  252 ----->Partial loss: 0.123384\n",
      "- - - - - >Iteration:  253 ----->Partial loss: 0.0794966\n",
      "- - - - - >Iteration:  254 ----->Partial loss: 0.105329\n",
      "- - - - - >Iteration:  255 ----->Partial loss: 0.0933485\n",
      "- - - - - >Iteration:  256 ----->Partial loss: 0.115697\n",
      "- - - - - >Iteration:  257 ----->Partial loss: 0.0692146\n",
      "- - - - - >Iteration:  258 ----->Partial loss: 0.0542556\n",
      "- - - - - >Iteration:  259 ----->Partial loss: 0.0513281\n",
      "- - - - - >Iteration:  260 ----->Partial loss: 0.184896\n",
      "- - - - - >Iteration:  261 ----->Partial loss: 0.0569689\n",
      "- - - - - >Iteration:  262 ----->Partial loss: 0.112365\n",
      "- - - - - >Iteration:  263 ----->Partial loss: 0.146777\n",
      "- - - - - >Iteration:  264 ----->Partial loss: 0.159526\n",
      "- - - - - >Iteration:  265 ----->Partial loss: 0.252891\n",
      "- - - - - >Iteration:  266 ----->Partial loss: 0.148796\n",
      "- - - - - >Iteration:  267 ----->Partial loss: 0.147534\n",
      "- - - - - >Iteration:  268 ----->Partial loss: 0.0964053\n",
      "- - - - - >Iteration:  269 ----->Partial loss: 0.0906017\n",
      "- - - - - >Iteration:  270 ----->Partial loss: 0.0617084\n",
      "- - - - - >Iteration:  271 ----->Partial loss: 0.13525\n",
      "- - - - - >Iteration:  272 ----->Partial loss: 0.104975\n",
      "- - - - - >Iteration:  273 ----->Partial loss: 0.120113\n",
      "- - - - - >Iteration:  274 ----->Partial loss: 0.0766597\n",
      "- - - - - >Iteration:  275 ----->Partial loss: 0.0879616\n",
      "- - - - - >Iteration:  276 ----->Partial loss: 0.120433\n",
      "- - - - - >Iteration:  277 ----->Partial loss: 0.0992554\n",
      "- - - - - >Iteration:  278 ----->Partial loss: 0.136638\n",
      "- - - - - >Iteration:  279 ----->Partial loss: 0.0895132\n",
      "- - - - - >Iteration:  280 ----->Partial loss: 0.113675\n",
      "- - - - - >Iteration:  281 ----->Partial loss: 0.0892589\n",
      "- - - - - >Iteration:  282 ----->Partial loss: 0.0667702\n",
      "- - - - - >Iteration:  283 ----->Partial loss: 0.159251\n",
      "- - - - - >Iteration:  284 ----->Partial loss: 0.188753\n",
      "- - - - - >Iteration:  285 ----->Partial loss: 0.10754\n",
      "- - - - - >Iteration:  286 ----->Partial loss: 0.0684099\n",
      "- - - - - >Iteration:  287 ----->Partial loss: 0.127585\n",
      "- - - - - >Iteration:  288 ----->Partial loss: 0.0653308\n",
      "- - - - - >Iteration:  289 ----->Partial loss: 0.293664\n",
      "***************\n",
      "Epoch:  8  of  20 training loss:  0.123448474017\n",
      "***************\n",
      "- - - - - >Iteration:  1 ----->Partial loss: 0.0917663\n",
      "- - - - - >Iteration:  2 ----->Partial loss: 0.113923\n",
      "- - - - - >Iteration:  3 ----->Partial loss: 0.0790956\n",
      "- - - - - >Iteration:  4 ----->Partial loss: 0.115536\n",
      "- - - - - >Iteration:  5 ----->Partial loss: 0.096597\n",
      "- - - - - >Iteration:  6 ----->Partial loss: 0.0769795\n",
      "- - - - - >Iteration:  7 ----->Partial loss: 0.205238\n",
      "- - - - - >Iteration:  8 ----->Partial loss: 0.166796\n",
      "- - - - - >Iteration:  9 ----->Partial loss: 0.1312\n",
      "- - - - - >Iteration:  10 ----->Partial loss: 0.0889285\n",
      "- - - - - >Iteration:  11 ----->Partial loss: 0.106194\n",
      "- - - - - >Iteration:  12 ----->Partial loss: 0.0704662\n",
      "- - - - - >Iteration:  13 ----->Partial loss: 0.0445129\n",
      "- - - - - >Iteration:  14 ----->Partial loss: 0.100608\n",
      "- - - - - >Iteration:  15 ----->Partial loss: 0.0909192\n",
      "- - - - - >Iteration:  16 ----->Partial loss: 0.0395031\n",
      "- - - - - >Iteration:  17 ----->Partial loss: 0.0677577\n",
      "- - - - - >Iteration:  18 ----->Partial loss: 0.11147\n",
      "- - - - - >Iteration:  19 ----->Partial loss: 0.077965\n",
      "- - - - - >Iteration:  20 ----->Partial loss: 0.163823\n",
      "- - - - - >Iteration:  21 ----->Partial loss: 0.12874\n",
      "- - - - - >Iteration:  22 ----->Partial loss: 0.0614389\n",
      "- - - - - >Iteration:  23 ----->Partial loss: 0.142193\n",
      "- - - - - >Iteration:  24 ----->Partial loss: 0.133236\n",
      "- - - - - >Iteration:  25 ----->Partial loss: 0.0533296\n",
      "- - - - - >Iteration:  26 ----->Partial loss: 0.0630848\n",
      "- - - - - >Iteration:  27 ----->Partial loss: 0.169968\n",
      "- - - - - >Iteration:  28 ----->Partial loss: 0.220795\n",
      "- - - - - >Iteration:  29 ----->Partial loss: 0.0772491\n",
      "- - - - - >Iteration:  30 ----->Partial loss: 0.0682093\n",
      "- - - - - >Iteration:  31 ----->Partial loss: 0.106334\n",
      "- - - - - >Iteration:  32 ----->Partial loss: 0.080333\n",
      "- - - - - >Iteration:  33 ----->Partial loss: 0.0564898\n",
      "- - - - - >Iteration:  34 ----->Partial loss: 0.0727088\n",
      "- - - - - >Iteration:  35 ----->Partial loss: 0.118087\n",
      "- - - - - >Iteration:  36 ----->Partial loss: 0.302808\n",
      "- - - - - >Iteration:  37 ----->Partial loss: 0.0879192\n",
      "- - - - - >Iteration:  38 ----->Partial loss: 0.249521\n",
      "- - - - - >Iteration:  39 ----->Partial loss: 0.110474\n",
      "- - - - - >Iteration:  40 ----->Partial loss: 0.0587384\n",
      "- - - - - >Iteration:  41 ----->Partial loss: 0.167597\n",
      "- - - - - >Iteration:  42 ----->Partial loss: 0.0406979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- - - - - >Iteration:  43 ----->Partial loss: 0.11213\n",
      "- - - - - >Iteration:  44 ----->Partial loss: 0.16164\n",
      "- - - - - >Iteration:  45 ----->Partial loss: 0.0750413\n",
      "- - - - - >Iteration:  46 ----->Partial loss: 0.1019\n",
      "- - - - - >Iteration:  47 ----->Partial loss: 0.145267\n",
      "- - - - - >Iteration:  48 ----->Partial loss: 0.320865\n",
      "- - - - - >Iteration:  49 ----->Partial loss: 0.076885\n",
      "- - - - - >Iteration:  50 ----->Partial loss: 0.0593104\n",
      "- - - - - >Iteration:  51 ----->Partial loss: 0.0623571\n",
      "- - - - - >Iteration:  52 ----->Partial loss: 0.146966\n",
      "- - - - - >Iteration:  53 ----->Partial loss: 0.139461\n",
      "- - - - - >Iteration:  54 ----->Partial loss: 0.0615602\n",
      "- - - - - >Iteration:  55 ----->Partial loss: 0.0997679\n",
      "- - - - - >Iteration:  56 ----->Partial loss: 0.135932\n",
      "- - - - - >Iteration:  57 ----->Partial loss: 0.145936\n",
      "- - - - - >Iteration:  58 ----->Partial loss: 0.106257\n",
      "- - - - - >Iteration:  59 ----->Partial loss: 0.232015\n",
      "- - - - - >Iteration:  60 ----->Partial loss: 0.123237\n",
      "- - - - - >Iteration:  61 ----->Partial loss: 0.0616631\n",
      "- - - - - >Iteration:  62 ----->Partial loss: 0.107579\n",
      "- - - - - >Iteration:  63 ----->Partial loss: 0.0869719\n",
      "- - - - - >Iteration:  64 ----->Partial loss: 0.0653833\n",
      "- - - - - >Iteration:  65 ----->Partial loss: 0.178493\n",
      "- - - - - >Iteration:  66 ----->Partial loss: 0.171023\n",
      "- - - - - >Iteration:  67 ----->Partial loss: 0.11503\n",
      "- - - - - >Iteration:  68 ----->Partial loss: 0.0878331\n",
      "- - - - - >Iteration:  69 ----->Partial loss: 0.088965\n",
      "- - - - - >Iteration:  70 ----->Partial loss: 0.21642\n",
      "- - - - - >Iteration:  71 ----->Partial loss: 0.0696361\n",
      "- - - - - >Iteration:  72 ----->Partial loss: 0.0445009\n",
      "- - - - - >Iteration:  73 ----->Partial loss: 0.067538\n",
      "- - - - - >Iteration:  74 ----->Partial loss: 0.107652\n",
      "- - - - - >Iteration:  75 ----->Partial loss: 0.0711251\n",
      "- - - - - >Iteration:  76 ----->Partial loss: 0.124941\n",
      "- - - - - >Iteration:  77 ----->Partial loss: 0.175147\n",
      "- - - - - >Iteration:  78 ----->Partial loss: 0.135868\n",
      "- - - - - >Iteration:  79 ----->Partial loss: 0.0915447\n",
      "- - - - - >Iteration:  80 ----->Partial loss: 0.101628\n",
      "- - - - - >Iteration:  81 ----->Partial loss: 0.113145\n",
      "- - - - - >Iteration:  82 ----->Partial loss: 0.154897\n",
      "- - - - - >Iteration:  83 ----->Partial loss: 0.0875077\n",
      "- - - - - >Iteration:  84 ----->Partial loss: 0.104629\n",
      "- - - - - >Iteration:  85 ----->Partial loss: 0.110042\n",
      "- - - - - >Iteration:  86 ----->Partial loss: 0.144167\n",
      "- - - - - >Iteration:  87 ----->Partial loss: 0.0770152\n",
      "- - - - - >Iteration:  88 ----->Partial loss: 0.052003\n",
      "- - - - - >Iteration:  89 ----->Partial loss: 0.113956\n",
      "- - - - - >Iteration:  90 ----->Partial loss: 0.0469216\n",
      "- - - - - >Iteration:  91 ----->Partial loss: 0.0947442\n",
      "- - - - - >Iteration:  92 ----->Partial loss: 0.0734449\n",
      "- - - - - >Iteration:  93 ----->Partial loss: 0.112739\n",
      "- - - - - >Iteration:  94 ----->Partial loss: 0.195205\n",
      "- - - - - >Iteration:  95 ----->Partial loss: 0.11228\n",
      "- - - - - >Iteration:  96 ----->Partial loss: 0.181353\n",
      "- - - - - >Iteration:  97 ----->Partial loss: 0.118366\n",
      "- - - - - >Iteration:  98 ----->Partial loss: 0.0637018\n",
      "- - - - - >Iteration:  99 ----->Partial loss: 0.0608906\n",
      "- - - - - >Iteration:  100 ----->Partial loss: 0.151868\n",
      "- - - - - >Iteration:  101 ----->Partial loss: 0.0715085\n",
      "- - - - - >Iteration:  102 ----->Partial loss: 0.237712\n",
      "- - - - - >Iteration:  103 ----->Partial loss: 0.0597935\n",
      "- - - - - >Iteration:  104 ----->Partial loss: 0.0771743\n",
      "- - - - - >Iteration:  105 ----->Partial loss: 0.110668\n",
      "- - - - - >Iteration:  106 ----->Partial loss: 0.0815312\n",
      "- - - - - >Iteration:  107 ----->Partial loss: 0.170964\n",
      "- - - - - >Iteration:  108 ----->Partial loss: 0.115659\n",
      "- - - - - >Iteration:  109 ----->Partial loss: 0.127645\n",
      "- - - - - >Iteration:  110 ----->Partial loss: 0.140265\n",
      "- - - - - >Iteration:  111 ----->Partial loss: 0.188467\n",
      "- - - - - >Iteration:  112 ----->Partial loss: 0.0768515\n",
      "- - - - - >Iteration:  113 ----->Partial loss: 0.0891208\n",
      "- - - - - >Iteration:  114 ----->Partial loss: 0.116242\n",
      "- - - - - >Iteration:  115 ----->Partial loss: 0.109745\n",
      "- - - - - >Iteration:  116 ----->Partial loss: 0.0738679\n",
      "- - - - - >Iteration:  117 ----->Partial loss: 0.0974635\n",
      "- - - - - >Iteration:  118 ----->Partial loss: 0.099995\n",
      "- - - - - >Iteration:  119 ----->Partial loss: 0.0719568\n",
      "- - - - - >Iteration:  120 ----->Partial loss: 0.116058\n",
      "- - - - - >Iteration:  121 ----->Partial loss: 0.125538\n",
      "- - - - - >Iteration:  122 ----->Partial loss: 0.0593505\n",
      "- - - - - >Iteration:  123 ----->Partial loss: 0.0821247\n",
      "- - - - - >Iteration:  124 ----->Partial loss: 0.136203\n",
      "- - - - - >Iteration:  125 ----->Partial loss: 0.0907208\n",
      "- - - - - >Iteration:  126 ----->Partial loss: 0.237987\n",
      "- - - - - >Iteration:  127 ----->Partial loss: 0.110795\n",
      "- - - - - >Iteration:  128 ----->Partial loss: 0.0551169\n",
      "- - - - - >Iteration:  129 ----->Partial loss: 0.0831832\n",
      "- - - - - >Iteration:  130 ----->Partial loss: 0.0987572\n",
      "- - - - - >Iteration:  131 ----->Partial loss: 0.0823585\n",
      "- - - - - >Iteration:  132 ----->Partial loss: 0.0699642\n",
      "- - - - - >Iteration:  133 ----->Partial loss: 0.133823\n",
      "- - - - - >Iteration:  134 ----->Partial loss: 0.0506428\n",
      "- - - - - >Iteration:  135 ----->Partial loss: 0.0949461\n",
      "- - - - - >Iteration:  136 ----->Partial loss: 0.204156\n",
      "- - - - - >Iteration:  137 ----->Partial loss: 0.0565668\n",
      "- - - - - >Iteration:  138 ----->Partial loss: 0.144048\n",
      "- - - - - >Iteration:  139 ----->Partial loss: 0.119926\n",
      "- - - - - >Iteration:  140 ----->Partial loss: 0.0821067\n",
      "- - - - - >Iteration:  141 ----->Partial loss: 0.145087\n",
      "- - - - - >Iteration:  142 ----->Partial loss: 0.0863659\n",
      "- - - - - >Iteration:  143 ----->Partial loss: 0.160641\n",
      "- - - - - >Iteration:  144 ----->Partial loss: 0.126499\n",
      "- - - - - >Iteration:  145 ----->Partial loss: 0.0846108\n",
      "- - - - - >Iteration:  146 ----->Partial loss: 0.0889416\n",
      "- - - - - >Iteration:  147 ----->Partial loss: 0.13068\n",
      "- - - - - >Iteration:  148 ----->Partial loss: 0.0681569\n",
      "- - - - - >Iteration:  149 ----->Partial loss: 0.0658546\n",
      "- - - - - >Iteration:  150 ----->Partial loss: 0.187629\n",
      "- - - - - >Iteration:  151 ----->Partial loss: 0.0599343\n",
      "- - - - - >Iteration:  152 ----->Partial loss: 0.0931931\n",
      "- - - - - >Iteration:  153 ----->Partial loss: 0.0712318\n",
      "- - - - - >Iteration:  154 ----->Partial loss: 0.0769629\n",
      "- - - - - >Iteration:  155 ----->Partial loss: 0.0614311\n",
      "- - - - - >Iteration:  156 ----->Partial loss: 0.187514\n",
      "- - - - - >Iteration:  157 ----->Partial loss: 0.13337\n",
      "- - - - - >Iteration:  158 ----->Partial loss: 0.0658252\n",
      "- - - - - >Iteration:  159 ----->Partial loss: 0.115855\n",
      "- - - - - >Iteration:  160 ----->Partial loss: 0.100952\n",
      "- - - - - >Iteration:  161 ----->Partial loss: 0.0579866\n",
      "- - - - - >Iteration:  162 ----->Partial loss: 0.104647\n",
      "- - - - - >Iteration:  163 ----->Partial loss: 0.0601764\n",
      "- - - - - >Iteration:  164 ----->Partial loss: 0.140916\n",
      "- - - - - >Iteration:  165 ----->Partial loss: 0.247601\n",
      "- - - - - >Iteration:  166 ----->Partial loss: 0.134228\n",
      "- - - - - >Iteration:  167 ----->Partial loss: 0.0424076\n",
      "- - - - - >Iteration:  168 ----->Partial loss: 0.08268\n",
      "- - - - - >Iteration:  169 ----->Partial loss: 0.112561\n",
      "- - - - - >Iteration:  170 ----->Partial loss: 0.148176\n",
      "- - - - - >Iteration:  171 ----->Partial loss: 0.130053\n",
      "- - - - - >Iteration:  172 ----->Partial loss: 0.0449435\n",
      "- - - - - >Iteration:  173 ----->Partial loss: 0.0435155\n",
      "- - - - - >Iteration:  174 ----->Partial loss: 0.121549\n",
      "- - - - - >Iteration:  175 ----->Partial loss: 0.175931\n",
      "- - - - - >Iteration:  176 ----->Partial loss: 0.0833571\n",
      "- - - - - >Iteration:  177 ----->Partial loss: 0.0927187\n",
      "- - - - - >Iteration:  178 ----->Partial loss: 0.132999\n",
      "- - - - - >Iteration:  179 ----->Partial loss: 0.107525\n",
      "- - - - - >Iteration:  180 ----->Partial loss: 0.074793\n",
      "- - - - - >Iteration:  181 ----->Partial loss: 0.120279\n",
      "- - - - - >Iteration:  182 ----->Partial loss: 0.0686404\n",
      "- - - - - >Iteration:  183 ----->Partial loss: 0.109094\n",
      "- - - - - >Iteration:  184 ----->Partial loss: 0.178863\n",
      "- - - - - >Iteration:  185 ----->Partial loss: 0.103519\n",
      "- - - - - >Iteration:  186 ----->Partial loss: 0.0410395\n",
      "- - - - - >Iteration:  187 ----->Partial loss: 0.127045\n",
      "- - - - - >Iteration:  188 ----->Partial loss: 0.0710745\n",
      "- - - - - >Iteration:  189 ----->Partial loss: 0.139981\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- - - - - >Iteration:  190 ----->Partial loss: 0.0708563\n",
      "- - - - - >Iteration:  191 ----->Partial loss: 0.077698\n",
      "- - - - - >Iteration:  192 ----->Partial loss: 0.0757581\n",
      "- - - - - >Iteration:  193 ----->Partial loss: 0.0787652\n",
      "- - - - - >Iteration:  194 ----->Partial loss: 0.130261\n",
      "- - - - - >Iteration:  195 ----->Partial loss: 0.061696\n",
      "- - - - - >Iteration:  196 ----->Partial loss: 0.175487\n",
      "- - - - - >Iteration:  197 ----->Partial loss: 0.0549942\n",
      "- - - - - >Iteration:  198 ----->Partial loss: 0.101836\n",
      "- - - - - >Iteration:  199 ----->Partial loss: 0.111974\n",
      "- - - - - >Iteration:  200 ----->Partial loss: 0.147834\n",
      "- - - - - >Iteration:  201 ----->Partial loss: 0.0959721\n",
      "- - - - - >Iteration:  202 ----->Partial loss: 0.0710778\n",
      "- - - - - >Iteration:  203 ----->Partial loss: 0.0990305\n",
      "- - - - - >Iteration:  204 ----->Partial loss: 0.116747\n",
      "- - - - - >Iteration:  205 ----->Partial loss: 0.114203\n",
      "- - - - - >Iteration:  206 ----->Partial loss: 0.163384\n",
      "- - - - - >Iteration:  207 ----->Partial loss: 0.17049\n",
      "- - - - - >Iteration:  208 ----->Partial loss: 0.144757\n",
      "- - - - - >Iteration:  209 ----->Partial loss: 0.0897511\n",
      "- - - - - >Iteration:  210 ----->Partial loss: 0.0590024\n",
      "- - - - - >Iteration:  211 ----->Partial loss: 0.0940792\n",
      "- - - - - >Iteration:  212 ----->Partial loss: 0.0908933\n",
      "- - - - - >Iteration:  213 ----->Partial loss: 0.123878\n",
      "- - - - - >Iteration:  214 ----->Partial loss: 0.0560705\n",
      "- - - - - >Iteration:  215 ----->Partial loss: 0.0507032\n",
      "- - - - - >Iteration:  216 ----->Partial loss: 0.0710091\n",
      "- - - - - >Iteration:  217 ----->Partial loss: 0.0962546\n",
      "- - - - - >Iteration:  218 ----->Partial loss: 0.110899\n",
      "- - - - - >Iteration:  219 ----->Partial loss: 0.0768483\n",
      "- - - - - >Iteration:  220 ----->Partial loss: 0.225879\n",
      "- - - - - >Iteration:  221 ----->Partial loss: 0.0456892\n",
      "- - - - - >Iteration:  222 ----->Partial loss: 0.0811886\n",
      "- - - - - >Iteration:  223 ----->Partial loss: 0.0616677\n",
      "- - - - - >Iteration:  224 ----->Partial loss: 0.116211\n",
      "- - - - - >Iteration:  225 ----->Partial loss: 0.0637725\n",
      "- - - - - >Iteration:  226 ----->Partial loss: 0.236717\n",
      "- - - - - >Iteration:  227 ----->Partial loss: 0.0806149\n",
      "- - - - - >Iteration:  228 ----->Partial loss: 0.0459829\n",
      "- - - - - >Iteration:  229 ----->Partial loss: 0.106819\n",
      "- - - - - >Iteration:  230 ----->Partial loss: 0.0473772\n",
      "- - - - - >Iteration:  231 ----->Partial loss: 0.0695664\n",
      "- - - - - >Iteration:  232 ----->Partial loss: 0.112455\n",
      "- - - - - >Iteration:  233 ----->Partial loss: 0.11018\n",
      "- - - - - >Iteration:  234 ----->Partial loss: 0.0622968\n",
      "- - - - - >Iteration:  235 ----->Partial loss: 0.0683465\n",
      "- - - - - >Iteration:  236 ----->Partial loss: 0.0461921\n",
      "- - - - - >Iteration:  237 ----->Partial loss: 0.17268\n",
      "- - - - - >Iteration:  238 ----->Partial loss: 0.0556407\n",
      "- - - - - >Iteration:  239 ----->Partial loss: 0.132773\n",
      "- - - - - >Iteration:  240 ----->Partial loss: 0.163902\n",
      "- - - - - >Iteration:  241 ----->Partial loss: 0.0951199\n",
      "- - - - - >Iteration:  242 ----->Partial loss: 0.127021\n",
      "- - - - - >Iteration:  243 ----->Partial loss: 0.084511\n",
      "- - - - - >Iteration:  244 ----->Partial loss: 0.102203\n",
      "- - - - - >Iteration:  245 ----->Partial loss: 0.118758\n",
      "- - - - - >Iteration:  246 ----->Partial loss: 0.0686459\n",
      "- - - - - >Iteration:  247 ----->Partial loss: 0.0502638\n",
      "- - - - - >Iteration:  248 ----->Partial loss: 0.117077\n",
      "- - - - - >Iteration:  249 ----->Partial loss: 0.0510806\n",
      "- - - - - >Iteration:  250 ----->Partial loss: 0.0989285\n",
      "- - - - - >Iteration:  251 ----->Partial loss: 0.0998721\n",
      "- - - - - >Iteration:  252 ----->Partial loss: 0.114563\n",
      "- - - - - >Iteration:  253 ----->Partial loss: 0.0389944\n",
      "- - - - - >Iteration:  254 ----->Partial loss: 0.112833\n",
      "- - - - - >Iteration:  255 ----->Partial loss: 0.0702422\n",
      "- - - - - >Iteration:  256 ----->Partial loss: 0.106088\n",
      "- - - - - >Iteration:  257 ----->Partial loss: 0.0979253\n",
      "- - - - - >Iteration:  258 ----->Partial loss: 0.119557\n",
      "- - - - - >Iteration:  259 ----->Partial loss: 0.128468\n",
      "- - - - - >Iteration:  260 ----->Partial loss: 0.137799\n",
      "- - - - - >Iteration:  261 ----->Partial loss: 0.0906779\n",
      "- - - - - >Iteration:  262 ----->Partial loss: 0.327862\n",
      "- - - - - >Iteration:  263 ----->Partial loss: 0.0864203\n",
      "- - - - - >Iteration:  264 ----->Partial loss: 0.149222\n",
      "- - - - - >Iteration:  265 ----->Partial loss: 0.145237\n",
      "- - - - - >Iteration:  266 ----->Partial loss: 0.089373\n",
      "- - - - - >Iteration:  267 ----->Partial loss: 0.239792\n",
      "- - - - - >Iteration:  268 ----->Partial loss: 0.119815\n",
      "- - - - - >Iteration:  269 ----->Partial loss: 0.140621\n",
      "- - - - - >Iteration:  270 ----->Partial loss: 0.116423\n",
      "- - - - - >Iteration:  271 ----->Partial loss: 0.162999\n",
      "- - - - - >Iteration:  272 ----->Partial loss: 0.109616\n",
      "- - - - - >Iteration:  273 ----->Partial loss: 0.105839\n",
      "- - - - - >Iteration:  274 ----->Partial loss: 0.139211\n",
      "- - - - - >Iteration:  275 ----->Partial loss: 0.171366\n",
      "- - - - - >Iteration:  276 ----->Partial loss: 0.0660701\n",
      "- - - - - >Iteration:  277 ----->Partial loss: 0.0686623\n",
      "- - - - - >Iteration:  278 ----->Partial loss: 0.24619\n",
      "- - - - - >Iteration:  279 ----->Partial loss: 0.167608\n",
      "- - - - - >Iteration:  280 ----->Partial loss: 0.0973424\n",
      "- - - - - >Iteration:  281 ----->Partial loss: 0.0700577\n",
      "- - - - - >Iteration:  282 ----->Partial loss: 0.135262\n",
      "- - - - - >Iteration:  283 ----->Partial loss: 0.138065\n",
      "- - - - - >Iteration:  284 ----->Partial loss: 0.0429019\n",
      "- - - - - >Iteration:  285 ----->Partial loss: 0.0857573\n",
      "- - - - - >Iteration:  286 ----->Partial loss: 0.106827\n",
      "- - - - - >Iteration:  287 ----->Partial loss: 0.0797144\n",
      "- - - - - >Iteration:  288 ----->Partial loss: 0.085209\n",
      "- - - - - >Iteration:  289 ----->Partial loss: 0.129198\n",
      "***************\n",
      "Epoch:  9  of  20 training loss:  0.109187078814\n",
      "***************\n",
      "- - - - - >Iteration:  1 ----->Partial loss: 0.0803888\n",
      "- - - - - >Iteration:  2 ----->Partial loss: 0.0953137\n",
      "- - - - - >Iteration:  3 ----->Partial loss: 0.101164\n",
      "- - - - - >Iteration:  4 ----->Partial loss: 0.0860379\n",
      "- - - - - >Iteration:  5 ----->Partial loss: 0.0676814\n",
      "- - - - - >Iteration:  6 ----->Partial loss: 0.0823733\n",
      "- - - - - >Iteration:  7 ----->Partial loss: 0.100955\n",
      "- - - - - >Iteration:  8 ----->Partial loss: 0.057789\n",
      "- - - - - >Iteration:  9 ----->Partial loss: 0.0828281\n",
      "- - - - - >Iteration:  10 ----->Partial loss: 0.136232\n",
      "- - - - - >Iteration:  11 ----->Partial loss: 0.0765452\n",
      "- - - - - >Iteration:  12 ----->Partial loss: 0.0507294\n",
      "- - - - - >Iteration:  13 ----->Partial loss: 0.0743155\n",
      "- - - - - >Iteration:  14 ----->Partial loss: 0.0828918\n",
      "- - - - - >Iteration:  15 ----->Partial loss: 0.109858\n",
      "- - - - - >Iteration:  16 ----->Partial loss: 0.0449284\n",
      "- - - - - >Iteration:  17 ----->Partial loss: 0.0562727\n",
      "- - - - - >Iteration:  18 ----->Partial loss: 0.0422246\n",
      "- - - - - >Iteration:  19 ----->Partial loss: 0.0517279\n",
      "- - - - - >Iteration:  20 ----->Partial loss: 0.13683\n",
      "- - - - - >Iteration:  21 ----->Partial loss: 0.0773092\n",
      "- - - - - >Iteration:  22 ----->Partial loss: 0.150181\n",
      "- - - - - >Iteration:  23 ----->Partial loss: 0.048783\n",
      "- - - - - >Iteration:  24 ----->Partial loss: 0.0442292\n",
      "- - - - - >Iteration:  25 ----->Partial loss: 0.0417081\n",
      "- - - - - >Iteration:  26 ----->Partial loss: 0.078919\n",
      "- - - - - >Iteration:  27 ----->Partial loss: 0.0904127\n",
      "- - - - - >Iteration:  28 ----->Partial loss: 0.0992546\n",
      "- - - - - >Iteration:  29 ----->Partial loss: 0.125886\n",
      "- - - - - >Iteration:  30 ----->Partial loss: 0.176687\n",
      "- - - - - >Iteration:  31 ----->Partial loss: 0.0797234\n",
      "- - - - - >Iteration:  32 ----->Partial loss: 0.105399\n",
      "- - - - - >Iteration:  33 ----->Partial loss: 0.115818\n",
      "- - - - - >Iteration:  34 ----->Partial loss: 0.123383\n",
      "- - - - - >Iteration:  35 ----->Partial loss: 0.082421\n",
      "- - - - - >Iteration:  36 ----->Partial loss: 0.0451186\n",
      "- - - - - >Iteration:  37 ----->Partial loss: 0.121019\n",
      "- - - - - >Iteration:  38 ----->Partial loss: 0.127398\n",
      "- - - - - >Iteration:  39 ----->Partial loss: 0.0569155\n",
      "- - - - - >Iteration:  40 ----->Partial loss: 0.0655101\n",
      "- - - - - >Iteration:  41 ----->Partial loss: 0.107343\n",
      "- - - - - >Iteration:  42 ----->Partial loss: 0.0689904\n",
      "- - - - - >Iteration:  43 ----->Partial loss: 0.0863949\n",
      "- - - - - >Iteration:  44 ----->Partial loss: 0.0378508\n",
      "- - - - - >Iteration:  45 ----->Partial loss: 0.123503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- - - - - >Iteration:  46 ----->Partial loss: 0.0691263\n",
      "- - - - - >Iteration:  47 ----->Partial loss: 0.11581\n",
      "- - - - - >Iteration:  48 ----->Partial loss: 0.0906397\n",
      "- - - - - >Iteration:  49 ----->Partial loss: 0.0782666\n",
      "- - - - - >Iteration:  50 ----->Partial loss: 0.0770029\n",
      "- - - - - >Iteration:  51 ----->Partial loss: 0.119665\n",
      "- - - - - >Iteration:  52 ----->Partial loss: 0.0814534\n",
      "- - - - - >Iteration:  53 ----->Partial loss: 0.0880536\n",
      "- - - - - >Iteration:  54 ----->Partial loss: 0.156762\n",
      "- - - - - >Iteration:  55 ----->Partial loss: 0.0952857\n",
      "- - - - - >Iteration:  56 ----->Partial loss: 0.105283\n",
      "- - - - - >Iteration:  57 ----->Partial loss: 0.0772578\n",
      "- - - - - >Iteration:  58 ----->Partial loss: 0.0965991\n",
      "- - - - - >Iteration:  59 ----->Partial loss: 0.0577437\n",
      "- - - - - >Iteration:  60 ----->Partial loss: 0.0623217\n",
      "- - - - - >Iteration:  61 ----->Partial loss: 0.0558902\n",
      "- - - - - >Iteration:  62 ----->Partial loss: 0.083011\n",
      "- - - - - >Iteration:  63 ----->Partial loss: 0.162357\n",
      "- - - - - >Iteration:  64 ----->Partial loss: 0.107365\n",
      "- - - - - >Iteration:  65 ----->Partial loss: 0.0475639\n",
      "- - - - - >Iteration:  66 ----->Partial loss: 0.0747288\n",
      "- - - - - >Iteration:  67 ----->Partial loss: 0.0521074\n",
      "- - - - - >Iteration:  68 ----->Partial loss: 0.0735357\n",
      "- - - - - >Iteration:  69 ----->Partial loss: 0.0642058\n",
      "- - - - - >Iteration:  70 ----->Partial loss: 0.193999\n",
      "- - - - - >Iteration:  71 ----->Partial loss: 0.237085\n",
      "- - - - - >Iteration:  72 ----->Partial loss: 0.0878922\n",
      "- - - - - >Iteration:  73 ----->Partial loss: 0.0794272\n",
      "- - - - - >Iteration:  74 ----->Partial loss: 0.0715405\n",
      "- - - - - >Iteration:  75 ----->Partial loss: 0.136512\n",
      "- - - - - >Iteration:  76 ----->Partial loss: 0.0771594\n",
      "- - - - - >Iteration:  77 ----->Partial loss: 0.0929971\n",
      "- - - - - >Iteration:  78 ----->Partial loss: 0.0777671\n",
      "- - - - - >Iteration:  79 ----->Partial loss: 0.108445\n",
      "- - - - - >Iteration:  80 ----->Partial loss: 0.135713\n",
      "- - - - - >Iteration:  81 ----->Partial loss: 0.0430488\n",
      "- - - - - >Iteration:  82 ----->Partial loss: 0.107004\n",
      "- - - - - >Iteration:  83 ----->Partial loss: 0.0443011\n",
      "- - - - - >Iteration:  84 ----->Partial loss: 0.0674744\n",
      "- - - - - >Iteration:  85 ----->Partial loss: 0.0942796\n",
      "- - - - - >Iteration:  86 ----->Partial loss: 0.0562881\n",
      "- - - - - >Iteration:  87 ----->Partial loss: 0.097807\n",
      "- - - - - >Iteration:  88 ----->Partial loss: 0.0681418\n",
      "- - - - - >Iteration:  89 ----->Partial loss: 0.0652678\n",
      "- - - - - >Iteration:  90 ----->Partial loss: 0.200325\n",
      "- - - - - >Iteration:  91 ----->Partial loss: 0.0989743\n",
      "- - - - - >Iteration:  92 ----->Partial loss: 0.0850947\n",
      "- - - - - >Iteration:  93 ----->Partial loss: 0.0691349\n",
      "- - - - - >Iteration:  94 ----->Partial loss: 0.120278\n",
      "- - - - - >Iteration:  95 ----->Partial loss: 0.0875552\n",
      "- - - - - >Iteration:  96 ----->Partial loss: 0.147832\n",
      "- - - - - >Iteration:  97 ----->Partial loss: 0.0969206\n",
      "- - - - - >Iteration:  98 ----->Partial loss: 0.0871546\n",
      "- - - - - >Iteration:  99 ----->Partial loss: 0.0435408\n",
      "- - - - - >Iteration:  100 ----->Partial loss: 0.086096\n",
      "- - - - - >Iteration:  101 ----->Partial loss: 0.154857\n",
      "- - - - - >Iteration:  102 ----->Partial loss: 0.180916\n",
      "- - - - - >Iteration:  103 ----->Partial loss: 0.189164\n",
      "- - - - - >Iteration:  104 ----->Partial loss: 0.11119\n",
      "- - - - - >Iteration:  105 ----->Partial loss: 0.10637\n",
      "- - - - - >Iteration:  106 ----->Partial loss: 0.0805786\n",
      "- - - - - >Iteration:  107 ----->Partial loss: 0.0514322\n",
      "- - - - - >Iteration:  108 ----->Partial loss: 0.0962242\n",
      "- - - - - >Iteration:  109 ----->Partial loss: 0.0479054\n",
      "- - - - - >Iteration:  110 ----->Partial loss: 0.0810369\n",
      "- - - - - >Iteration:  111 ----->Partial loss: 0.0921898\n",
      "- - - - - >Iteration:  112 ----->Partial loss: 0.0938789\n",
      "- - - - - >Iteration:  113 ----->Partial loss: 0.0715555\n",
      "- - - - - >Iteration:  114 ----->Partial loss: 0.135424\n",
      "- - - - - >Iteration:  115 ----->Partial loss: 0.109704\n",
      "- - - - - >Iteration:  116 ----->Partial loss: 0.0607699\n",
      "- - - - - >Iteration:  117 ----->Partial loss: 0.11514\n",
      "- - - - - >Iteration:  118 ----->Partial loss: 0.0496336\n",
      "- - - - - >Iteration:  119 ----->Partial loss: 0.100019\n",
      "- - - - - >Iteration:  120 ----->Partial loss: 0.0923722\n",
      "- - - - - >Iteration:  121 ----->Partial loss: 0.101664\n",
      "- - - - - >Iteration:  122 ----->Partial loss: 0.140735\n",
      "- - - - - >Iteration:  123 ----->Partial loss: 0.107309\n",
      "- - - - - >Iteration:  124 ----->Partial loss: 0.103541\n",
      "- - - - - >Iteration:  125 ----->Partial loss: 0.0600082\n",
      "- - - - - >Iteration:  126 ----->Partial loss: 0.0888728\n",
      "- - - - - >Iteration:  127 ----->Partial loss: 0.0837686\n",
      "- - - - - >Iteration:  128 ----->Partial loss: 0.107832\n",
      "- - - - - >Iteration:  129 ----->Partial loss: 0.0709301\n",
      "- - - - - >Iteration:  130 ----->Partial loss: 0.13958\n",
      "- - - - - >Iteration:  131 ----->Partial loss: 0.0769693\n",
      "- - - - - >Iteration:  132 ----->Partial loss: 0.104809\n",
      "- - - - - >Iteration:  133 ----->Partial loss: 0.0567432\n",
      "- - - - - >Iteration:  134 ----->Partial loss: 0.0816697\n",
      "- - - - - >Iteration:  135 ----->Partial loss: 0.0916913\n",
      "- - - - - >Iteration:  136 ----->Partial loss: 0.0688898\n",
      "- - - - - >Iteration:  137 ----->Partial loss: 0.226136\n",
      "- - - - - >Iteration:  138 ----->Partial loss: 0.175721\n",
      "- - - - - >Iteration:  139 ----->Partial loss: 0.0524562\n",
      "- - - - - >Iteration:  140 ----->Partial loss: 0.0671518\n",
      "- - - - - >Iteration:  141 ----->Partial loss: 0.102503\n",
      "- - - - - >Iteration:  142 ----->Partial loss: 0.167367\n",
      "- - - - - >Iteration:  143 ----->Partial loss: 0.077007\n",
      "- - - - - >Iteration:  144 ----->Partial loss: 0.257703\n",
      "- - - - - >Iteration:  145 ----->Partial loss: 0.0977897\n",
      "- - - - - >Iteration:  146 ----->Partial loss: 0.144324\n",
      "- - - - - >Iteration:  147 ----->Partial loss: 0.116923\n",
      "- - - - - >Iteration:  148 ----->Partial loss: 0.0793514\n",
      "- - - - - >Iteration:  149 ----->Partial loss: 0.233816\n",
      "- - - - - >Iteration:  150 ----->Partial loss: 0.165369\n",
      "- - - - - >Iteration:  151 ----->Partial loss: 0.0567172\n",
      "- - - - - >Iteration:  152 ----->Partial loss: 0.10025\n",
      "- - - - - >Iteration:  153 ----->Partial loss: 0.0960496\n",
      "- - - - - >Iteration:  154 ----->Partial loss: 0.13063\n",
      "- - - - - >Iteration:  155 ----->Partial loss: 0.117091\n",
      "- - - - - >Iteration:  156 ----->Partial loss: 0.10552\n",
      "- - - - - >Iteration:  157 ----->Partial loss: 0.145639\n",
      "- - - - - >Iteration:  158 ----->Partial loss: 0.120372\n",
      "- - - - - >Iteration:  159 ----->Partial loss: 0.0880944\n",
      "- - - - - >Iteration:  160 ----->Partial loss: 0.213114\n",
      "- - - - - >Iteration:  161 ----->Partial loss: 0.0977672\n",
      "- - - - - >Iteration:  162 ----->Partial loss: 0.121986\n",
      "- - - - - >Iteration:  163 ----->Partial loss: 0.123689\n",
      "- - - - - >Iteration:  164 ----->Partial loss: 0.0858241\n",
      "- - - - - >Iteration:  165 ----->Partial loss: 0.134331\n",
      "- - - - - >Iteration:  166 ----->Partial loss: 0.0609846\n",
      "- - - - - >Iteration:  167 ----->Partial loss: 0.0447178\n",
      "- - - - - >Iteration:  168 ----->Partial loss: 0.0660343\n",
      "- - - - - >Iteration:  169 ----->Partial loss: 0.0898763\n",
      "- - - - - >Iteration:  170 ----->Partial loss: 0.109472\n",
      "- - - - - >Iteration:  171 ----->Partial loss: 0.0826819\n",
      "- - - - - >Iteration:  172 ----->Partial loss: 0.139555\n",
      "- - - - - >Iteration:  173 ----->Partial loss: 0.170096\n",
      "- - - - - >Iteration:  174 ----->Partial loss: 0.110054\n",
      "- - - - - >Iteration:  175 ----->Partial loss: 0.197555\n",
      "- - - - - >Iteration:  176 ----->Partial loss: 0.151904\n",
      "- - - - - >Iteration:  177 ----->Partial loss: 0.0921277\n",
      "- - - - - >Iteration:  178 ----->Partial loss: 0.044666\n",
      "- - - - - >Iteration:  179 ----->Partial loss: 0.108063\n",
      "- - - - - >Iteration:  180 ----->Partial loss: 0.115066\n",
      "- - - - - >Iteration:  181 ----->Partial loss: 0.0958943\n",
      "- - - - - >Iteration:  182 ----->Partial loss: 0.049615\n",
      "- - - - - >Iteration:  183 ----->Partial loss: 0.102208\n",
      "- - - - - >Iteration:  184 ----->Partial loss: 0.0656332\n",
      "- - - - - >Iteration:  185 ----->Partial loss: 0.0594082\n",
      "- - - - - >Iteration:  186 ----->Partial loss: 0.0619434\n",
      "- - - - - >Iteration:  187 ----->Partial loss: 0.217425\n",
      "- - - - - >Iteration:  188 ----->Partial loss: 0.0769488\n",
      "- - - - - >Iteration:  189 ----->Partial loss: 0.0458447\n",
      "- - - - - >Iteration:  190 ----->Partial loss: 0.133573\n",
      "- - - - - >Iteration:  191 ----->Partial loss: 0.0814923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- - - - - >Iteration:  192 ----->Partial loss: 0.0657785\n",
      "- - - - - >Iteration:  193 ----->Partial loss: 0.181357\n",
      "- - - - - >Iteration:  194 ----->Partial loss: 0.0756848\n",
      "- - - - - >Iteration:  195 ----->Partial loss: 0.0461209\n",
      "- - - - - >Iteration:  196 ----->Partial loss: 0.0698987\n",
      "- - - - - >Iteration:  197 ----->Partial loss: 0.176306\n",
      "- - - - - >Iteration:  198 ----->Partial loss: 0.180117\n",
      "- - - - - >Iteration:  199 ----->Partial loss: 0.07298\n",
      "- - - - - >Iteration:  200 ----->Partial loss: 0.179657\n",
      "- - - - - >Iteration:  201 ----->Partial loss: 0.192167\n",
      "- - - - - >Iteration:  202 ----->Partial loss: 0.106589\n",
      "- - - - - >Iteration:  203 ----->Partial loss: 0.0380977\n",
      "- - - - - >Iteration:  204 ----->Partial loss: 0.0662137\n",
      "- - - - - >Iteration:  205 ----->Partial loss: 0.0532723\n",
      "- - - - - >Iteration:  206 ----->Partial loss: 0.100117\n",
      "- - - - - >Iteration:  207 ----->Partial loss: 0.132623\n",
      "- - - - - >Iteration:  208 ----->Partial loss: 0.115293\n",
      "- - - - - >Iteration:  209 ----->Partial loss: 0.0406137\n",
      "- - - - - >Iteration:  210 ----->Partial loss: 0.1174\n",
      "- - - - - >Iteration:  211 ----->Partial loss: 0.0511634\n",
      "- - - - - >Iteration:  212 ----->Partial loss: 0.132232\n",
      "- - - - - >Iteration:  213 ----->Partial loss: 0.0982993\n",
      "- - - - - >Iteration:  214 ----->Partial loss: 0.141095\n",
      "- - - - - >Iteration:  215 ----->Partial loss: 0.10962\n",
      "- - - - - >Iteration:  216 ----->Partial loss: 0.0847097\n",
      "- - - - - >Iteration:  217 ----->Partial loss: 0.0501132\n",
      "- - - - - >Iteration:  218 ----->Partial loss: 0.0721082\n",
      "- - - - - >Iteration:  219 ----->Partial loss: 0.135015\n",
      "- - - - - >Iteration:  220 ----->Partial loss: 0.140172\n",
      "- - - - - >Iteration:  221 ----->Partial loss: 0.0384786\n",
      "- - - - - >Iteration:  222 ----->Partial loss: 0.060716\n",
      "- - - - - >Iteration:  223 ----->Partial loss: 0.159675\n",
      "- - - - - >Iteration:  224 ----->Partial loss: 0.158088\n",
      "- - - - - >Iteration:  225 ----->Partial loss: 0.121309\n",
      "- - - - - >Iteration:  226 ----->Partial loss: 0.0891004\n",
      "- - - - - >Iteration:  227 ----->Partial loss: 0.116685\n",
      "- - - - - >Iteration:  228 ----->Partial loss: 0.0528691\n",
      "- - - - - >Iteration:  229 ----->Partial loss: 0.0986379\n",
      "- - - - - >Iteration:  230 ----->Partial loss: 0.112465\n",
      "- - - - - >Iteration:  231 ----->Partial loss: 0.0608377\n",
      "- - - - - >Iteration:  232 ----->Partial loss: 0.0727912\n",
      "- - - - - >Iteration:  233 ----->Partial loss: 0.131701\n",
      "- - - - - >Iteration:  234 ----->Partial loss: 0.121286\n",
      "- - - - - >Iteration:  235 ----->Partial loss: 0.0959426\n",
      "- - - - - >Iteration:  236 ----->Partial loss: 0.0485894\n",
      "- - - - - >Iteration:  237 ----->Partial loss: 0.0908836\n",
      "- - - - - >Iteration:  238 ----->Partial loss: 0.125862\n",
      "- - - - - >Iteration:  239 ----->Partial loss: 0.0645497\n",
      "- - - - - >Iteration:  240 ----->Partial loss: 0.169367\n",
      "- - - - - >Iteration:  241 ----->Partial loss: 0.0832028\n",
      "- - - - - >Iteration:  242 ----->Partial loss: 0.0698093\n",
      "- - - - - >Iteration:  243 ----->Partial loss: 0.0585092\n",
      "- - - - - >Iteration:  244 ----->Partial loss: 0.0666743\n",
      "- - - - - >Iteration:  245 ----->Partial loss: 0.036572\n",
      "- - - - - >Iteration:  246 ----->Partial loss: 0.0767325\n",
      "- - - - - >Iteration:  247 ----->Partial loss: 0.109865\n",
      "- - - - - >Iteration:  248 ----->Partial loss: 0.064387\n",
      "- - - - - >Iteration:  249 ----->Partial loss: 0.053616\n",
      "- - - - - >Iteration:  250 ----->Partial loss: 0.133151\n",
      "- - - - - >Iteration:  251 ----->Partial loss: 0.0491917\n",
      "- - - - - >Iteration:  252 ----->Partial loss: 0.160637\n",
      "- - - - - >Iteration:  253 ----->Partial loss: 0.144293\n",
      "- - - - - >Iteration:  254 ----->Partial loss: 0.171457\n",
      "- - - - - >Iteration:  255 ----->Partial loss: 0.0829997\n",
      "- - - - - >Iteration:  256 ----->Partial loss: 0.0443931\n",
      "- - - - - >Iteration:  257 ----->Partial loss: 0.0714466\n",
      "- - - - - >Iteration:  258 ----->Partial loss: 0.146841\n",
      "- - - - - >Iteration:  259 ----->Partial loss: 0.119996\n",
      "- - - - - >Iteration:  260 ----->Partial loss: 0.0418142\n",
      "- - - - - >Iteration:  261 ----->Partial loss: 0.0641378\n",
      "- - - - - >Iteration:  262 ----->Partial loss: 0.107743\n",
      "- - - - - >Iteration:  263 ----->Partial loss: 0.0794909\n",
      "- - - - - >Iteration:  264 ----->Partial loss: 0.0984668\n",
      "- - - - - >Iteration:  265 ----->Partial loss: 0.0753676\n",
      "- - - - - >Iteration:  266 ----->Partial loss: 0.086569\n",
      "- - - - - >Iteration:  267 ----->Partial loss: 0.0430428\n",
      "- - - - - >Iteration:  268 ----->Partial loss: 0.0473344\n",
      "- - - - - >Iteration:  269 ----->Partial loss: 0.0441113\n",
      "- - - - - >Iteration:  270 ----->Partial loss: 0.0837506\n",
      "- - - - - >Iteration:  271 ----->Partial loss: 0.0881544\n",
      "- - - - - >Iteration:  272 ----->Partial loss: 0.0763828\n",
      "- - - - - >Iteration:  273 ----->Partial loss: 0.110887\n",
      "- - - - - >Iteration:  274 ----->Partial loss: 0.0818789\n",
      "- - - - - >Iteration:  275 ----->Partial loss: 0.24247\n",
      "- - - - - >Iteration:  276 ----->Partial loss: 0.0618465\n",
      "- - - - - >Iteration:  277 ----->Partial loss: 0.0476446\n",
      "- - - - - >Iteration:  278 ----->Partial loss: 0.149541\n",
      "- - - - - >Iteration:  279 ----->Partial loss: 0.0973593\n",
      "- - - - - >Iteration:  280 ----->Partial loss: 0.0930708\n",
      "- - - - - >Iteration:  281 ----->Partial loss: 0.0575916\n",
      "- - - - - >Iteration:  282 ----->Partial loss: 0.135594\n",
      "- - - - - >Iteration:  283 ----->Partial loss: 0.0499773\n",
      "- - - - - >Iteration:  284 ----->Partial loss: 0.0644135\n",
      "- - - - - >Iteration:  285 ----->Partial loss: 0.124789\n",
      "- - - - - >Iteration:  286 ----->Partial loss: 0.0597028\n",
      "- - - - - >Iteration:  287 ----->Partial loss: 0.141596\n",
      "- - - - - >Iteration:  288 ----->Partial loss: 0.0659185\n",
      "- - - - - >Iteration:  289 ----->Partial loss: 0.12096\n",
      "***************\n",
      "Epoch:  10  of  20 training loss:  0.0976929666288\n",
      "***************\n",
      "- - - - - >Iteration:  1 ----->Partial loss: 0.0766113\n",
      "- - - - - >Iteration:  2 ----->Partial loss: 0.041862\n",
      "- - - - - >Iteration:  3 ----->Partial loss: 0.209482\n",
      "- - - - - >Iteration:  4 ----->Partial loss: 0.0604825\n",
      "- - - - - >Iteration:  5 ----->Partial loss: 0.0467255\n",
      "- - - - - >Iteration:  6 ----->Partial loss: 0.0738323\n",
      "- - - - - >Iteration:  7 ----->Partial loss: 0.12354\n",
      "- - - - - >Iteration:  8 ----->Partial loss: 0.0841206\n",
      "- - - - - >Iteration:  9 ----->Partial loss: 0.0791982\n",
      "- - - - - >Iteration:  10 ----->Partial loss: 0.0475517\n",
      "- - - - - >Iteration:  11 ----->Partial loss: 0.215593\n",
      "- - - - - >Iteration:  12 ----->Partial loss: 0.0569581\n",
      "- - - - - >Iteration:  13 ----->Partial loss: 0.114139\n",
      "- - - - - >Iteration:  14 ----->Partial loss: 0.0939301\n",
      "- - - - - >Iteration:  15 ----->Partial loss: 0.0882015\n",
      "- - - - - >Iteration:  16 ----->Partial loss: 0.170703\n",
      "- - - - - >Iteration:  17 ----->Partial loss: 0.0500892\n",
      "- - - - - >Iteration:  18 ----->Partial loss: 0.0775441\n",
      "- - - - - >Iteration:  19 ----->Partial loss: 0.144451\n",
      "- - - - - >Iteration:  20 ----->Partial loss: 0.1418\n",
      "- - - - - >Iteration:  21 ----->Partial loss: 0.0470378\n",
      "- - - - - >Iteration:  22 ----->Partial loss: 0.0390202\n",
      "- - - - - >Iteration:  23 ----->Partial loss: 0.122148\n",
      "- - - - - >Iteration:  24 ----->Partial loss: 0.0693676\n",
      "- - - - - >Iteration:  25 ----->Partial loss: 0.115727\n",
      "- - - - - >Iteration:  26 ----->Partial loss: 0.15595\n",
      "- - - - - >Iteration:  27 ----->Partial loss: 0.073222\n",
      "- - - - - >Iteration:  28 ----->Partial loss: 0.0873718\n",
      "- - - - - >Iteration:  29 ----->Partial loss: 0.0769482\n",
      "- - - - - >Iteration:  30 ----->Partial loss: 0.0365847\n",
      "- - - - - >Iteration:  31 ----->Partial loss: 0.131737\n",
      "- - - - - >Iteration:  32 ----->Partial loss: 0.039196\n",
      "- - - - - >Iteration:  33 ----->Partial loss: 0.108514\n",
      "- - - - - >Iteration:  34 ----->Partial loss: 0.1082\n",
      "- - - - - >Iteration:  35 ----->Partial loss: 0.114406\n",
      "- - - - - >Iteration:  36 ----->Partial loss: 0.075719\n",
      "- - - - - >Iteration:  37 ----->Partial loss: 0.058163\n",
      "- - - - - >Iteration:  38 ----->Partial loss: 0.0374574\n",
      "- - - - - >Iteration:  39 ----->Partial loss: 0.0625502\n",
      "- - - - - >Iteration:  40 ----->Partial loss: 0.073893\n",
      "- - - - - >Iteration:  41 ----->Partial loss: 0.182688\n",
      "- - - - - >Iteration:  42 ----->Partial loss: 0.0899277\n",
      "- - - - - >Iteration:  43 ----->Partial loss: 0.0746406\n",
      "- - - - - >Iteration:  44 ----->Partial loss: 0.0804034\n",
      "- - - - - >Iteration:  45 ----->Partial loss: 0.051126\n",
      "- - - - - >Iteration:  46 ----->Partial loss: 0.116595\n",
      "- - - - - >Iteration:  47 ----->Partial loss: 0.149824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- - - - - >Iteration:  48 ----->Partial loss: 0.131184\n",
      "- - - - - >Iteration:  49 ----->Partial loss: 0.0816184\n",
      "- - - - - >Iteration:  50 ----->Partial loss: 0.0833771\n",
      "- - - - - >Iteration:  51 ----->Partial loss: 0.0598674\n",
      "- - - - - >Iteration:  52 ----->Partial loss: 0.0737261\n",
      "- - - - - >Iteration:  53 ----->Partial loss: 0.080666\n",
      "- - - - - >Iteration:  54 ----->Partial loss: 0.117167\n",
      "- - - - - >Iteration:  55 ----->Partial loss: 0.120724\n",
      "- - - - - >Iteration:  56 ----->Partial loss: 0.107352\n",
      "- - - - - >Iteration:  57 ----->Partial loss: 0.112634\n",
      "- - - - - >Iteration:  58 ----->Partial loss: 0.0518033\n",
      "- - - - - >Iteration:  59 ----->Partial loss: 0.0527988\n",
      "- - - - - >Iteration:  60 ----->Partial loss: 0.153389\n",
      "- - - - - >Iteration:  61 ----->Partial loss: 0.0709779\n",
      "- - - - - >Iteration:  62 ----->Partial loss: 0.064677\n",
      "- - - - - >Iteration:  63 ----->Partial loss: 0.0455302\n",
      "- - - - - >Iteration:  64 ----->Partial loss: 0.0798498\n",
      "- - - - - >Iteration:  65 ----->Partial loss: 0.14607\n",
      "- - - - - >Iteration:  66 ----->Partial loss: 0.0678318\n",
      "- - - - - >Iteration:  67 ----->Partial loss: 0.0779399\n",
      "- - - - - >Iteration:  68 ----->Partial loss: 0.0375062\n",
      "- - - - - >Iteration:  69 ----->Partial loss: 0.10898\n",
      "- - - - - >Iteration:  70 ----->Partial loss: 0.0936125\n",
      "- - - - - >Iteration:  71 ----->Partial loss: 0.0655175\n",
      "- - - - - >Iteration:  72 ----->Partial loss: 0.0389887\n",
      "- - - - - >Iteration:  73 ----->Partial loss: 0.0518956\n",
      "- - - - - >Iteration:  74 ----->Partial loss: 0.0998188\n",
      "- - - - - >Iteration:  75 ----->Partial loss: 0.0487799\n",
      "- - - - - >Iteration:  76 ----->Partial loss: 0.12536\n",
      "- - - - - >Iteration:  77 ----->Partial loss: 0.11562\n",
      "- - - - - >Iteration:  78 ----->Partial loss: 0.066546\n",
      "- - - - - >Iteration:  79 ----->Partial loss: 0.0521254\n",
      "- - - - - >Iteration:  80 ----->Partial loss: 0.0484983\n",
      "- - - - - >Iteration:  81 ----->Partial loss: 0.0725131\n",
      "- - - - - >Iteration:  82 ----->Partial loss: 0.0490358\n",
      "- - - - - >Iteration:  83 ----->Partial loss: 0.0733437\n",
      "- - - - - >Iteration:  84 ----->Partial loss: 0.0523939\n",
      "- - - - - >Iteration:  85 ----->Partial loss: 0.0796133\n",
      "- - - - - >Iteration:  86 ----->Partial loss: 0.047151\n",
      "- - - - - >Iteration:  87 ----->Partial loss: 0.0661702\n",
      "- - - - - >Iteration:  88 ----->Partial loss: 0.102241\n",
      "- - - - - >Iteration:  89 ----->Partial loss: 0.0538849\n",
      "- - - - - >Iteration:  90 ----->Partial loss: 0.10516\n",
      "- - - - - >Iteration:  91 ----->Partial loss: 0.0912197\n",
      "- - - - - >Iteration:  92 ----->Partial loss: 0.0925852\n",
      "- - - - - >Iteration:  93 ----->Partial loss: 0.0913191\n",
      "- - - - - >Iteration:  94 ----->Partial loss: 0.098748\n",
      "- - - - - >Iteration:  95 ----->Partial loss: 0.0831222\n",
      "- - - - - >Iteration:  96 ----->Partial loss: 0.102658\n",
      "- - - - - >Iteration:  97 ----->Partial loss: 0.0795518\n",
      "- - - - - >Iteration:  98 ----->Partial loss: 0.0656399\n",
      "- - - - - >Iteration:  99 ----->Partial loss: 0.223371\n",
      "- - - - - >Iteration:  100 ----->Partial loss: 0.106362\n",
      "- - - - - >Iteration:  101 ----->Partial loss: 0.158838\n",
      "- - - - - >Iteration:  102 ----->Partial loss: 0.0622601\n",
      "- - - - - >Iteration:  103 ----->Partial loss: 0.069281\n",
      "- - - - - >Iteration:  104 ----->Partial loss: 0.0691197\n",
      "- - - - - >Iteration:  105 ----->Partial loss: 0.124942\n",
      "- - - - - >Iteration:  106 ----->Partial loss: 0.112211\n",
      "- - - - - >Iteration:  107 ----->Partial loss: 0.053509\n",
      "- - - - - >Iteration:  108 ----->Partial loss: 0.0668347\n",
      "- - - - - >Iteration:  109 ----->Partial loss: 0.0811234\n",
      "- - - - - >Iteration:  110 ----->Partial loss: 0.0878837\n",
      "- - - - - >Iteration:  111 ----->Partial loss: 0.0437471\n",
      "- - - - - >Iteration:  112 ----->Partial loss: 0.0510764\n",
      "- - - - - >Iteration:  113 ----->Partial loss: 0.0765829\n",
      "- - - - - >Iteration:  114 ----->Partial loss: 0.118394\n",
      "- - - - - >Iteration:  115 ----->Partial loss: 0.0507756\n",
      "- - - - - >Iteration:  116 ----->Partial loss: 0.0781714\n",
      "- - - - - >Iteration:  117 ----->Partial loss: 0.13298\n",
      "- - - - - >Iteration:  118 ----->Partial loss: 0.100112\n",
      "- - - - - >Iteration:  119 ----->Partial loss: 0.0572341\n",
      "- - - - - >Iteration:  120 ----->Partial loss: 0.217824\n",
      "- - - - - >Iteration:  121 ----->Partial loss: 0.073259\n",
      "- - - - - >Iteration:  122 ----->Partial loss: 0.0584103\n",
      "- - - - - >Iteration:  123 ----->Partial loss: 0.0471263\n",
      "- - - - - >Iteration:  124 ----->Partial loss: 0.0677527\n",
      "- - - - - >Iteration:  125 ----->Partial loss: 0.0488561\n",
      "- - - - - >Iteration:  126 ----->Partial loss: 0.0625789\n",
      "- - - - - >Iteration:  127 ----->Partial loss: 0.1036\n",
      "- - - - - >Iteration:  128 ----->Partial loss: 0.14979\n",
      "- - - - - >Iteration:  129 ----->Partial loss: 0.0695426\n",
      "- - - - - >Iteration:  130 ----->Partial loss: 0.0817998\n",
      "- - - - - >Iteration:  131 ----->Partial loss: 0.126187\n",
      "- - - - - >Iteration:  132 ----->Partial loss: 0.0719061\n",
      "- - - - - >Iteration:  133 ----->Partial loss: 0.0752915\n",
      "- - - - - >Iteration:  134 ----->Partial loss: 0.128925\n",
      "- - - - - >Iteration:  135 ----->Partial loss: 0.171863\n",
      "- - - - - >Iteration:  136 ----->Partial loss: 0.0506513\n",
      "- - - - - >Iteration:  137 ----->Partial loss: 0.0366308\n",
      "- - - - - >Iteration:  138 ----->Partial loss: 0.154813\n",
      "- - - - - >Iteration:  139 ----->Partial loss: 0.0742666\n",
      "- - - - - >Iteration:  140 ----->Partial loss: 0.0373759\n",
      "- - - - - >Iteration:  141 ----->Partial loss: 0.135737\n",
      "- - - - - >Iteration:  142 ----->Partial loss: 0.0456189\n",
      "- - - - - >Iteration:  143 ----->Partial loss: 0.179493\n",
      "- - - - - >Iteration:  144 ----->Partial loss: 0.0590225\n",
      "- - - - - >Iteration:  145 ----->Partial loss: 0.0924996\n",
      "- - - - - >Iteration:  146 ----->Partial loss: 0.100858\n",
      "- - - - - >Iteration:  147 ----->Partial loss: 0.0715846\n",
      "- - - - - >Iteration:  148 ----->Partial loss: 0.0419962\n",
      "- - - - - >Iteration:  149 ----->Partial loss: 0.0499209\n",
      "- - - - - >Iteration:  150 ----->Partial loss: 0.109343\n",
      "- - - - - >Iteration:  151 ----->Partial loss: 0.0953505\n",
      "- - - - - >Iteration:  152 ----->Partial loss: 0.0807678\n",
      "- - - - - >Iteration:  153 ----->Partial loss: 0.0967893\n",
      "- - - - - >Iteration:  154 ----->Partial loss: 0.05887\n",
      "- - - - - >Iteration:  155 ----->Partial loss: 0.0997396\n",
      "- - - - - >Iteration:  156 ----->Partial loss: 0.142163\n",
      "- - - - - >Iteration:  157 ----->Partial loss: 0.126123\n",
      "- - - - - >Iteration:  158 ----->Partial loss: 0.0988676\n",
      "- - - - - >Iteration:  159 ----->Partial loss: 0.0871254\n",
      "- - - - - >Iteration:  160 ----->Partial loss: 0.103142\n",
      "- - - - - >Iteration:  161 ----->Partial loss: 0.0976268\n",
      "- - - - - >Iteration:  162 ----->Partial loss: 0.0504753\n",
      "- - - - - >Iteration:  163 ----->Partial loss: 0.110384\n",
      "- - - - - >Iteration:  164 ----->Partial loss: 0.0441771\n",
      "- - - - - >Iteration:  165 ----->Partial loss: 0.0550984\n",
      "- - - - - >Iteration:  166 ----->Partial loss: 0.112823\n",
      "- - - - - >Iteration:  167 ----->Partial loss: 0.0941023\n",
      "- - - - - >Iteration:  168 ----->Partial loss: 0.0722696\n",
      "- - - - - >Iteration:  169 ----->Partial loss: 0.0593317\n",
      "- - - - - >Iteration:  170 ----->Partial loss: 0.0744793\n",
      "- - - - - >Iteration:  171 ----->Partial loss: 0.141088\n",
      "- - - - - >Iteration:  172 ----->Partial loss: 0.061222\n",
      "- - - - - >Iteration:  173 ----->Partial loss: 0.0615298\n",
      "- - - - - >Iteration:  174 ----->Partial loss: 0.105387\n",
      "- - - - - >Iteration:  175 ----->Partial loss: 0.154901\n",
      "- - - - - >Iteration:  176 ----->Partial loss: 0.0948183\n",
      "- - - - - >Iteration:  177 ----->Partial loss: 0.0868529\n",
      "- - - - - >Iteration:  178 ----->Partial loss: 0.0439238\n",
      "- - - - - >Iteration:  179 ----->Partial loss: 0.347036\n",
      "- - - - - >Iteration:  180 ----->Partial loss: 0.0509202\n",
      "- - - - - >Iteration:  181 ----->Partial loss: 0.0496859\n",
      "- - - - - >Iteration:  182 ----->Partial loss: 0.0737706\n",
      "- - - - - >Iteration:  183 ----->Partial loss: 0.132664\n",
      "- - - - - >Iteration:  184 ----->Partial loss: 0.132749\n",
      "- - - - - >Iteration:  185 ----->Partial loss: 0.108999\n",
      "- - - - - >Iteration:  186 ----->Partial loss: 0.0686743\n",
      "- - - - - >Iteration:  187 ----->Partial loss: 0.168212\n",
      "- - - - - >Iteration:  188 ----->Partial loss: 0.109924\n",
      "- - - - - >Iteration:  189 ----->Partial loss: 0.21699\n",
      "- - - - - >Iteration:  190 ----->Partial loss: 0.0490479\n",
      "- - - - - >Iteration:  191 ----->Partial loss: 0.0451701\n",
      "- - - - - >Iteration:  192 ----->Partial loss: 0.0364064\n",
      "- - - - - >Iteration:  193 ----->Partial loss: 0.055315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- - - - - >Iteration:  194 ----->Partial loss: 0.0893447\n",
      "- - - - - >Iteration:  195 ----->Partial loss: 0.077857\n",
      "- - - - - >Iteration:  196 ----->Partial loss: 0.0388135\n",
      "- - - - - >Iteration:  197 ----->Partial loss: 0.0461985\n",
      "- - - - - >Iteration:  198 ----->Partial loss: 0.116174\n",
      "- - - - - >Iteration:  199 ----->Partial loss: 0.0639507\n",
      "- - - - - >Iteration:  200 ----->Partial loss: 0.0495519\n",
      "- - - - - >Iteration:  201 ----->Partial loss: 0.0871566\n",
      "- - - - - >Iteration:  202 ----->Partial loss: 0.0781405\n",
      "- - - - - >Iteration:  203 ----->Partial loss: 0.102359\n",
      "- - - - - >Iteration:  204 ----->Partial loss: 0.183157\n",
      "- - - - - >Iteration:  205 ----->Partial loss: 0.0646126\n",
      "- - - - - >Iteration:  206 ----->Partial loss: 0.138069\n",
      "- - - - - >Iteration:  207 ----->Partial loss: 0.0468996\n",
      "- - - - - >Iteration:  208 ----->Partial loss: 0.0876171\n",
      "- - - - - >Iteration:  209 ----->Partial loss: 0.102555\n",
      "- - - - - >Iteration:  210 ----->Partial loss: 0.100871\n",
      "- - - - - >Iteration:  211 ----->Partial loss: 0.0584652\n",
      "- - - - - >Iteration:  212 ----->Partial loss: 0.118603\n",
      "- - - - - >Iteration:  213 ----->Partial loss: 0.112563\n",
      "- - - - - >Iteration:  214 ----->Partial loss: 0.069231\n",
      "- - - - - >Iteration:  215 ----->Partial loss: 0.121099\n",
      "- - - - - >Iteration:  216 ----->Partial loss: 0.0721022\n",
      "- - - - - >Iteration:  217 ----->Partial loss: 0.0827191\n",
      "- - - - - >Iteration:  218 ----->Partial loss: 0.0291254\n",
      "- - - - - >Iteration:  219 ----->Partial loss: 0.0389649\n",
      "- - - - - >Iteration:  220 ----->Partial loss: 0.0493629\n",
      "- - - - - >Iteration:  221 ----->Partial loss: 0.0416186\n",
      "- - - - - >Iteration:  222 ----->Partial loss: 0.138233\n",
      "- - - - - >Iteration:  223 ----->Partial loss: 0.0979134\n",
      "- - - - - >Iteration:  224 ----->Partial loss: 0.150433\n",
      "- - - - - >Iteration:  225 ----->Partial loss: 0.0855505\n",
      "- - - - - >Iteration:  226 ----->Partial loss: 0.160882\n",
      "- - - - - >Iteration:  227 ----->Partial loss: 0.0644997\n",
      "- - - - - >Iteration:  228 ----->Partial loss: 0.106974\n",
      "- - - - - >Iteration:  229 ----->Partial loss: 0.136499\n",
      "- - - - - >Iteration:  230 ----->Partial loss: 0.0364528\n",
      "- - - - - >Iteration:  231 ----->Partial loss: 0.043182\n",
      "- - - - - >Iteration:  232 ----->Partial loss: 0.0990393\n",
      "- - - - - >Iteration:  233 ----->Partial loss: 0.0987738\n",
      "- - - - - >Iteration:  234 ----->Partial loss: 0.113487\n",
      "- - - - - >Iteration:  235 ----->Partial loss: 0.0915391\n",
      "- - - - - >Iteration:  236 ----->Partial loss: 0.184329\n",
      "- - - - - >Iteration:  237 ----->Partial loss: 0.0765718\n",
      "- - - - - >Iteration:  238 ----->Partial loss: 0.113906\n",
      "- - - - - >Iteration:  239 ----->Partial loss: 0.0538798\n",
      "- - - - - >Iteration:  240 ----->Partial loss: 0.064722\n",
      "- - - - - >Iteration:  241 ----->Partial loss: 0.0607685\n",
      "- - - - - >Iteration:  242 ----->Partial loss: 0.047317\n",
      "- - - - - >Iteration:  243 ----->Partial loss: 0.0866885\n",
      "- - - - - >Iteration:  244 ----->Partial loss: 0.0809914\n",
      "- - - - - >Iteration:  245 ----->Partial loss: 0.0448197\n",
      "- - - - - >Iteration:  246 ----->Partial loss: 0.0328474\n",
      "- - - - - >Iteration:  247 ----->Partial loss: 0.0426204\n",
      "- - - - - >Iteration:  248 ----->Partial loss: 0.0514484\n",
      "- - - - - >Iteration:  249 ----->Partial loss: 0.0869584\n",
      "- - - - - >Iteration:  250 ----->Partial loss: 0.0867151\n",
      "- - - - - >Iteration:  251 ----->Partial loss: 0.128334\n",
      "- - - - - >Iteration:  252 ----->Partial loss: 0.0846674\n",
      "- - - - - >Iteration:  253 ----->Partial loss: 0.104819\n",
      "- - - - - >Iteration:  254 ----->Partial loss: 0.0770825\n",
      "- - - - - >Iteration:  255 ----->Partial loss: 0.0587566\n",
      "- - - - - >Iteration:  256 ----->Partial loss: 0.0645403\n",
      "- - - - - >Iteration:  257 ----->Partial loss: 0.0387412\n",
      "- - - - - >Iteration:  258 ----->Partial loss: 0.045548\n",
      "- - - - - >Iteration:  259 ----->Partial loss: 0.067329\n",
      "- - - - - >Iteration:  260 ----->Partial loss: 0.0589223\n",
      "- - - - - >Iteration:  261 ----->Partial loss: 0.155781\n",
      "- - - - - >Iteration:  262 ----->Partial loss: 0.075524\n",
      "- - - - - >Iteration:  263 ----->Partial loss: 0.087334\n",
      "- - - - - >Iteration:  264 ----->Partial loss: 0.0892087\n",
      "- - - - - >Iteration:  265 ----->Partial loss: 0.0814022\n",
      "- - - - - >Iteration:  266 ----->Partial loss: 0.0643615\n",
      "- - - - - >Iteration:  267 ----->Partial loss: 0.135839\n",
      "- - - - - >Iteration:  268 ----->Partial loss: 0.085988\n",
      "- - - - - >Iteration:  269 ----->Partial loss: 0.120433\n",
      "- - - - - >Iteration:  270 ----->Partial loss: 0.0778013\n",
      "- - - - - >Iteration:  271 ----->Partial loss: 0.164898\n",
      "- - - - - >Iteration:  272 ----->Partial loss: 0.0674995\n",
      "- - - - - >Iteration:  273 ----->Partial loss: 0.079155\n",
      "- - - - - >Iteration:  274 ----->Partial loss: 0.0922619\n",
      "- - - - - >Iteration:  275 ----->Partial loss: 0.0339965\n",
      "- - - - - >Iteration:  276 ----->Partial loss: 0.0637731\n",
      "- - - - - >Iteration:  277 ----->Partial loss: 0.0757226\n",
      "- - - - - >Iteration:  278 ----->Partial loss: 0.0505298\n",
      "- - - - - >Iteration:  279 ----->Partial loss: 0.086107\n",
      "- - - - - >Iteration:  280 ----->Partial loss: 0.0556513\n",
      "- - - - - >Iteration:  281 ----->Partial loss: 0.064918\n",
      "- - - - - >Iteration:  282 ----->Partial loss: 0.0452552\n",
      "- - - - - >Iteration:  283 ----->Partial loss: 0.0677656\n",
      "- - - - - >Iteration:  284 ----->Partial loss: 0.0899203\n",
      "- - - - - >Iteration:  285 ----->Partial loss: 0.0637879\n",
      "- - - - - >Iteration:  286 ----->Partial loss: 0.0404502\n",
      "- - - - - >Iteration:  287 ----->Partial loss: 0.0496371\n",
      "- - - - - >Iteration:  288 ----->Partial loss: 0.0809669\n",
      "- - - - - >Iteration:  289 ----->Partial loss: 0.0633024\n",
      "***************\n",
      "Epoch:  11  of  20 training loss:  0.0873064973221\n",
      "***************\n",
      "- - - - - >Iteration:  1 ----->Partial loss: 0.0558762\n",
      "- - - - - >Iteration:  2 ----->Partial loss: 0.0557037\n",
      "- - - - - >Iteration:  3 ----->Partial loss: 0.0507221\n",
      "- - - - - >Iteration:  4 ----->Partial loss: 0.0571067\n",
      "- - - - - >Iteration:  5 ----->Partial loss: 0.088112\n",
      "- - - - - >Iteration:  6 ----->Partial loss: 0.0730151\n",
      "- - - - - >Iteration:  7 ----->Partial loss: 0.0593601\n",
      "- - - - - >Iteration:  8 ----->Partial loss: 0.0937475\n",
      "- - - - - >Iteration:  9 ----->Partial loss: 0.0507737\n",
      "- - - - - >Iteration:  10 ----->Partial loss: 0.0785374\n",
      "- - - - - >Iteration:  11 ----->Partial loss: 0.0449465\n",
      "- - - - - >Iteration:  12 ----->Partial loss: 0.0649456\n",
      "- - - - - >Iteration:  13 ----->Partial loss: 0.0788812\n",
      "- - - - - >Iteration:  14 ----->Partial loss: 0.0654026\n",
      "- - - - - >Iteration:  15 ----->Partial loss: 0.0503761\n",
      "- - - - - >Iteration:  16 ----->Partial loss: 0.0456644\n",
      "- - - - - >Iteration:  17 ----->Partial loss: 0.168766\n",
      "- - - - - >Iteration:  18 ----->Partial loss: 0.0739956\n",
      "- - - - - >Iteration:  19 ----->Partial loss: 0.051011\n",
      "- - - - - >Iteration:  20 ----->Partial loss: 0.0451811\n",
      "- - - - - >Iteration:  21 ----->Partial loss: 0.177694\n",
      "- - - - - >Iteration:  22 ----->Partial loss: 0.184567\n",
      "- - - - - >Iteration:  23 ----->Partial loss: 0.0402463\n",
      "- - - - - >Iteration:  24 ----->Partial loss: 0.107074\n",
      "- - - - - >Iteration:  25 ----->Partial loss: 0.0325586\n",
      "- - - - - >Iteration:  26 ----->Partial loss: 0.0418999\n",
      "- - - - - >Iteration:  27 ----->Partial loss: 0.0893611\n",
      "- - - - - >Iteration:  28 ----->Partial loss: 0.0632195\n",
      "- - - - - >Iteration:  29 ----->Partial loss: 0.0463581\n",
      "- - - - - >Iteration:  30 ----->Partial loss: 0.0681987\n",
      "- - - - - >Iteration:  31 ----->Partial loss: 0.0566589\n",
      "- - - - - >Iteration:  32 ----->Partial loss: 0.0975783\n",
      "- - - - - >Iteration:  33 ----->Partial loss: 0.0363528\n",
      "- - - - - >Iteration:  34 ----->Partial loss: 0.0924996\n",
      "- - - - - >Iteration:  35 ----->Partial loss: 0.0737171\n",
      "- - - - - >Iteration:  36 ----->Partial loss: 0.131199\n",
      "- - - - - >Iteration:  37 ----->Partial loss: 0.114353\n",
      "- - - - - >Iteration:  38 ----->Partial loss: 0.081428\n",
      "- - - - - >Iteration:  39 ----->Partial loss: 0.0607407\n",
      "- - - - - >Iteration:  40 ----->Partial loss: 0.0640704\n",
      "- - - - - >Iteration:  41 ----->Partial loss: 0.0568897\n",
      "- - - - - >Iteration:  42 ----->Partial loss: 0.0639398\n",
      "- - - - - >Iteration:  43 ----->Partial loss: 0.0929697\n",
      "- - - - - >Iteration:  44 ----->Partial loss: 0.10595\n",
      "- - - - - >Iteration:  45 ----->Partial loss: 0.0790317\n",
      "- - - - - >Iteration:  46 ----->Partial loss: 0.0583352\n",
      "- - - - - >Iteration:  47 ----->Partial loss: 0.0524789\n",
      "- - - - - >Iteration:  48 ----->Partial loss: 0.0322265\n",
      "- - - - - >Iteration:  49 ----->Partial loss: 0.165006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- - - - - >Iteration:  50 ----->Partial loss: 0.180854\n",
      "- - - - - >Iteration:  51 ----->Partial loss: 0.0775176\n",
      "- - - - - >Iteration:  52 ----->Partial loss: 0.11217\n",
      "- - - - - >Iteration:  53 ----->Partial loss: 0.0306063\n",
      "- - - - - >Iteration:  54 ----->Partial loss: 0.15114\n",
      "- - - - - >Iteration:  55 ----->Partial loss: 0.115025\n",
      "- - - - - >Iteration:  56 ----->Partial loss: 0.068754\n",
      "- - - - - >Iteration:  57 ----->Partial loss: 0.0548161\n",
      "- - - - - >Iteration:  58 ----->Partial loss: 0.0614685\n",
      "- - - - - >Iteration:  59 ----->Partial loss: 0.0684955\n",
      "- - - - - >Iteration:  60 ----->Partial loss: 0.0690239\n",
      "- - - - - >Iteration:  61 ----->Partial loss: 0.0777814\n",
      "- - - - - >Iteration:  62 ----->Partial loss: 0.0600932\n",
      "- - - - - >Iteration:  63 ----->Partial loss: 0.0414629\n",
      "- - - - - >Iteration:  64 ----->Partial loss: 0.0426992\n",
      "- - - - - >Iteration:  65 ----->Partial loss: 0.0601651\n",
      "- - - - - >Iteration:  66 ----->Partial loss: 0.0350559\n",
      "- - - - - >Iteration:  67 ----->Partial loss: 0.090493\n",
      "- - - - - >Iteration:  68 ----->Partial loss: 0.103861\n",
      "- - - - - >Iteration:  69 ----->Partial loss: 0.0807427\n",
      "- - - - - >Iteration:  70 ----->Partial loss: 0.0801069\n",
      "- - - - - >Iteration:  71 ----->Partial loss: 0.0459876\n",
      "- - - - - >Iteration:  72 ----->Partial loss: 0.0418291\n",
      "- - - - - >Iteration:  73 ----->Partial loss: 0.161774\n",
      "- - - - - >Iteration:  74 ----->Partial loss: 0.0903026\n",
      "- - - - - >Iteration:  75 ----->Partial loss: 0.0543191\n",
      "- - - - - >Iteration:  76 ----->Partial loss: 0.186843\n",
      "- - - - - >Iteration:  77 ----->Partial loss: 0.0930098\n",
      "- - - - - >Iteration:  78 ----->Partial loss: 0.0883828\n",
      "- - - - - >Iteration:  79 ----->Partial loss: 0.112848\n",
      "- - - - - >Iteration:  80 ----->Partial loss: 0.111889\n",
      "- - - - - >Iteration:  81 ----->Partial loss: 0.0915041\n",
      "- - - - - >Iteration:  82 ----->Partial loss: 0.0331478\n",
      "- - - - - >Iteration:  83 ----->Partial loss: 0.0704406\n",
      "- - - - - >Iteration:  84 ----->Partial loss: 0.107602\n",
      "- - - - - >Iteration:  85 ----->Partial loss: 0.0306391\n",
      "- - - - - >Iteration:  86 ----->Partial loss: 0.0577737\n",
      "- - - - - >Iteration:  87 ----->Partial loss: 0.0607437\n",
      "- - - - - >Iteration:  88 ----->Partial loss: 0.0642776\n",
      "- - - - - >Iteration:  89 ----->Partial loss: 0.0497182\n",
      "- - - - - >Iteration:  90 ----->Partial loss: 0.0622411\n",
      "- - - - - >Iteration:  91 ----->Partial loss: 0.107731\n",
      "- - - - - >Iteration:  92 ----->Partial loss: 0.0345449\n",
      "- - - - - >Iteration:  93 ----->Partial loss: 0.0370001\n",
      "- - - - - >Iteration:  94 ----->Partial loss: 0.156357\n",
      "- - - - - >Iteration:  95 ----->Partial loss: 0.0522631\n",
      "- - - - - >Iteration:  96 ----->Partial loss: 0.0716137\n",
      "- - - - - >Iteration:  97 ----->Partial loss: 0.0700166\n",
      "- - - - - >Iteration:  98 ----->Partial loss: 0.081862\n",
      "- - - - - >Iteration:  99 ----->Partial loss: 0.0507522\n",
      "- - - - - >Iteration:  100 ----->Partial loss: 0.0302653\n",
      "- - - - - >Iteration:  101 ----->Partial loss: 0.0686381\n",
      "- - - - - >Iteration:  102 ----->Partial loss: 0.066073\n",
      "- - - - - >Iteration:  103 ----->Partial loss: 0.0664672\n",
      "- - - - - >Iteration:  104 ----->Partial loss: 0.0860925\n",
      "- - - - - >Iteration:  105 ----->Partial loss: 0.0680764\n",
      "- - - - - >Iteration:  106 ----->Partial loss: 0.0533296\n",
      "- - - - - >Iteration:  107 ----->Partial loss: 0.0705527\n",
      "- - - - - >Iteration:  108 ----->Partial loss: 0.132397\n",
      "- - - - - >Iteration:  109 ----->Partial loss: 0.056835\n",
      "- - - - - >Iteration:  110 ----->Partial loss: 0.109454\n",
      "- - - - - >Iteration:  111 ----->Partial loss: 0.0340454\n",
      "- - - - - >Iteration:  112 ----->Partial loss: 0.137502\n",
      "- - - - - >Iteration:  113 ----->Partial loss: 0.0404946\n",
      "- - - - - >Iteration:  114 ----->Partial loss: 0.109481\n",
      "- - - - - >Iteration:  115 ----->Partial loss: 0.0912316\n",
      "- - - - - >Iteration:  116 ----->Partial loss: 0.0422157\n",
      "- - - - - >Iteration:  117 ----->Partial loss: 0.0533477\n",
      "- - - - - >Iteration:  118 ----->Partial loss: 0.0591508\n",
      "- - - - - >Iteration:  119 ----->Partial loss: 0.0318753\n",
      "- - - - - >Iteration:  120 ----->Partial loss: 0.0529717\n",
      "- - - - - >Iteration:  121 ----->Partial loss: 0.0451635\n",
      "- - - - - >Iteration:  122 ----->Partial loss: 0.111711\n",
      "- - - - - >Iteration:  123 ----->Partial loss: 0.0587908\n",
      "- - - - - >Iteration:  124 ----->Partial loss: 0.0719604\n",
      "- - - - - >Iteration:  125 ----->Partial loss: 0.052834\n",
      "- - - - - >Iteration:  126 ----->Partial loss: 0.0384922\n",
      "- - - - - >Iteration:  127 ----->Partial loss: 0.0356126\n",
      "- - - - - >Iteration:  128 ----->Partial loss: 0.101794\n",
      "- - - - - >Iteration:  129 ----->Partial loss: 0.0956035\n",
      "- - - - - >Iteration:  130 ----->Partial loss: 0.06543\n",
      "- - - - - >Iteration:  131 ----->Partial loss: 0.135162\n",
      "- - - - - >Iteration:  132 ----->Partial loss: 0.0543785\n",
      "- - - - - >Iteration:  133 ----->Partial loss: 0.0372099\n",
      "- - - - - >Iteration:  134 ----->Partial loss: 0.0415704\n",
      "- - - - - >Iteration:  135 ----->Partial loss: 0.0340638\n",
      "- - - - - >Iteration:  136 ----->Partial loss: 0.125189\n",
      "- - - - - >Iteration:  137 ----->Partial loss: 0.104085\n",
      "- - - - - >Iteration:  138 ----->Partial loss: 0.037001\n",
      "- - - - - >Iteration:  139 ----->Partial loss: 0.162752\n",
      "- - - - - >Iteration:  140 ----->Partial loss: 0.0378022\n",
      "- - - - - >Iteration:  141 ----->Partial loss: 0.108019\n",
      "- - - - - >Iteration:  142 ----->Partial loss: 0.0532986\n",
      "- - - - - >Iteration:  143 ----->Partial loss: 0.0392106\n",
      "- - - - - >Iteration:  144 ----->Partial loss: 0.040776\n",
      "- - - - - >Iteration:  145 ----->Partial loss: 0.151609\n",
      "- - - - - >Iteration:  146 ----->Partial loss: 0.0362383\n",
      "- - - - - >Iteration:  147 ----->Partial loss: 0.0545482\n",
      "- - - - - >Iteration:  148 ----->Partial loss: 0.0383418\n",
      "- - - - - >Iteration:  149 ----->Partial loss: 0.0709886\n",
      "- - - - - >Iteration:  150 ----->Partial loss: 0.0792218\n",
      "- - - - - >Iteration:  151 ----->Partial loss: 0.0459773\n",
      "- - - - - >Iteration:  152 ----->Partial loss: 0.136792\n",
      "- - - - - >Iteration:  153 ----->Partial loss: 0.0502021\n",
      "- - - - - >Iteration:  154 ----->Partial loss: 0.0353583\n",
      "- - - - - >Iteration:  155 ----->Partial loss: 0.0719483\n",
      "- - - - - >Iteration:  156 ----->Partial loss: 0.0751759\n",
      "- - - - - >Iteration:  157 ----->Partial loss: 0.0880176\n",
      "- - - - - >Iteration:  158 ----->Partial loss: 0.0578248\n",
      "- - - - - >Iteration:  159 ----->Partial loss: 0.0972137\n",
      "- - - - - >Iteration:  160 ----->Partial loss: 0.0611539\n",
      "- - - - - >Iteration:  161 ----->Partial loss: 0.066137\n",
      "- - - - - >Iteration:  162 ----->Partial loss: 0.0481821\n",
      "- - - - - >Iteration:  163 ----->Partial loss: 0.0555671\n",
      "- - - - - >Iteration:  164 ----->Partial loss: 0.121625\n",
      "- - - - - >Iteration:  165 ----->Partial loss: 0.0872987\n",
      "- - - - - >Iteration:  166 ----->Partial loss: 0.0876534\n",
      "- - - - - >Iteration:  167 ----->Partial loss: 0.0669995\n",
      "- - - - - >Iteration:  168 ----->Partial loss: 0.113885\n",
      "- - - - - >Iteration:  169 ----->Partial loss: 0.0585533\n",
      "- - - - - >Iteration:  170 ----->Partial loss: 0.114137\n",
      "- - - - - >Iteration:  171 ----->Partial loss: 0.0550293\n",
      "- - - - - >Iteration:  172 ----->Partial loss: 0.0869495\n",
      "- - - - - >Iteration:  173 ----->Partial loss: 0.0597478\n",
      "- - - - - >Iteration:  174 ----->Partial loss: 0.0288878\n",
      "- - - - - >Iteration:  175 ----->Partial loss: 0.0425995\n",
      "- - - - - >Iteration:  176 ----->Partial loss: 0.0529665\n",
      "- - - - - >Iteration:  177 ----->Partial loss: 0.133088\n",
      "- - - - - >Iteration:  178 ----->Partial loss: 0.0647031\n",
      "- - - - - >Iteration:  179 ----->Partial loss: 0.0669432\n",
      "- - - - - >Iteration:  180 ----->Partial loss: 0.0875634\n",
      "- - - - - >Iteration:  181 ----->Partial loss: 0.0308409\n",
      "- - - - - >Iteration:  182 ----->Partial loss: 0.134473\n",
      "- - - - - >Iteration:  183 ----->Partial loss: 0.0602367\n",
      "- - - - - >Iteration:  184 ----->Partial loss: 0.126398\n",
      "- - - - - >Iteration:  185 ----->Partial loss: 0.136977\n",
      "- - - - - >Iteration:  186 ----->Partial loss: 0.0726584\n",
      "- - - - - >Iteration:  187 ----->Partial loss: 0.199976\n",
      "- - - - - >Iteration:  188 ----->Partial loss: 0.0460832\n",
      "- - - - - >Iteration:  189 ----->Partial loss: 0.0738792\n",
      "- - - - - >Iteration:  190 ----->Partial loss: 0.0719132\n",
      "- - - - - >Iteration:  191 ----->Partial loss: 0.057336\n",
      "- - - - - >Iteration:  192 ----->Partial loss: 0.0620668\n",
      "- - - - - >Iteration:  193 ----->Partial loss: 0.126246\n",
      "- - - - - >Iteration:  194 ----->Partial loss: 0.043099\n",
      "- - - - - >Iteration:  195 ----->Partial loss: 0.0991176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- - - - - >Iteration:  196 ----->Partial loss: 0.0665229\n",
      "- - - - - >Iteration:  197 ----->Partial loss: 0.0775683\n",
      "- - - - - >Iteration:  198 ----->Partial loss: 0.0391795\n",
      "- - - - - >Iteration:  199 ----->Partial loss: 0.0682605\n",
      "- - - - - >Iteration:  200 ----->Partial loss: 0.0567422\n",
      "- - - - - >Iteration:  201 ----->Partial loss: 0.0688155\n",
      "- - - - - >Iteration:  202 ----->Partial loss: 0.102982\n",
      "- - - - - >Iteration:  203 ----->Partial loss: 0.105551\n",
      "- - - - - >Iteration:  204 ----->Partial loss: 0.170164\n",
      "- - - - - >Iteration:  205 ----->Partial loss: 0.0415933\n",
      "- - - - - >Iteration:  206 ----->Partial loss: 0.0664755\n",
      "- - - - - >Iteration:  207 ----->Partial loss: 0.0597255\n",
      "- - - - - >Iteration:  208 ----->Partial loss: 0.0908422\n",
      "- - - - - >Iteration:  209 ----->Partial loss: 0.0349989\n",
      "- - - - - >Iteration:  210 ----->Partial loss: 0.0896437\n",
      "- - - - - >Iteration:  211 ----->Partial loss: 0.0556174\n",
      "- - - - - >Iteration:  212 ----->Partial loss: 0.042865\n",
      "- - - - - >Iteration:  213 ----->Partial loss: 0.0762986\n",
      "- - - - - >Iteration:  214 ----->Partial loss: 0.0618751\n",
      "- - - - - >Iteration:  215 ----->Partial loss: 0.0264122\n",
      "- - - - - >Iteration:  216 ----->Partial loss: 0.113083\n",
      "- - - - - >Iteration:  217 ----->Partial loss: 0.0806943\n",
      "- - - - - >Iteration:  218 ----->Partial loss: 0.10415\n",
      "- - - - - >Iteration:  219 ----->Partial loss: 0.047908\n",
      "- - - - - >Iteration:  220 ----->Partial loss: 0.0870906\n",
      "- - - - - >Iteration:  221 ----->Partial loss: 0.0688287\n",
      "- - - - - >Iteration:  222 ----->Partial loss: 0.114316\n",
      "- - - - - >Iteration:  223 ----->Partial loss: 0.027337\n",
      "- - - - - >Iteration:  224 ----->Partial loss: 0.0656768\n",
      "- - - - - >Iteration:  225 ----->Partial loss: 0.370438\n",
      "- - - - - >Iteration:  226 ----->Partial loss: 0.0676321\n",
      "- - - - - >Iteration:  227 ----->Partial loss: 0.0414315\n",
      "- - - - - >Iteration:  228 ----->Partial loss: 0.0793376\n",
      "- - - - - >Iteration:  229 ----->Partial loss: 0.0720954\n",
      "- - - - - >Iteration:  230 ----->Partial loss: 0.143869\n",
      "- - - - - >Iteration:  231 ----->Partial loss: 0.0716449\n",
      "- - - - - >Iteration:  232 ----->Partial loss: 0.0761156\n",
      "- - - - - >Iteration:  233 ----->Partial loss: 0.0440665\n",
      "- - - - - >Iteration:  234 ----->Partial loss: 0.103264\n",
      "- - - - - >Iteration:  235 ----->Partial loss: 0.0734878\n",
      "- - - - - >Iteration:  236 ----->Partial loss: 0.0741394\n",
      "- - - - - >Iteration:  237 ----->Partial loss: 0.0875487\n",
      "- - - - - >Iteration:  238 ----->Partial loss: 0.0652929\n",
      "- - - - - >Iteration:  239 ----->Partial loss: 0.044177\n",
      "- - - - - >Iteration:  240 ----->Partial loss: 0.0833111\n",
      "- - - - - >Iteration:  241 ----->Partial loss: 0.106072\n",
      "- - - - - >Iteration:  242 ----->Partial loss: 0.0816405\n",
      "- - - - - >Iteration:  243 ----->Partial loss: 0.0830854\n",
      "- - - - - >Iteration:  244 ----->Partial loss: 0.0601278\n",
      "- - - - - >Iteration:  245 ----->Partial loss: 0.110768\n",
      "- - - - - >Iteration:  246 ----->Partial loss: 0.106193\n",
      "- - - - - >Iteration:  247 ----->Partial loss: 0.0560033\n",
      "- - - - - >Iteration:  248 ----->Partial loss: 0.114923\n",
      "- - - - - >Iteration:  249 ----->Partial loss: 0.110199\n",
      "- - - - - >Iteration:  250 ----->Partial loss: 0.0325759\n",
      "- - - - - >Iteration:  251 ----->Partial loss: 0.0426839\n",
      "- - - - - >Iteration:  252 ----->Partial loss: 0.103515\n",
      "- - - - - >Iteration:  253 ----->Partial loss: 0.0674983\n",
      "- - - - - >Iteration:  254 ----->Partial loss: 0.0384429\n",
      "- - - - - >Iteration:  255 ----->Partial loss: 0.0958878\n",
      "- - - - - >Iteration:  256 ----->Partial loss: 0.0605257\n",
      "- - - - - >Iteration:  257 ----->Partial loss: 0.0740359\n",
      "- - - - - >Iteration:  258 ----->Partial loss: 0.110156\n",
      "- - - - - >Iteration:  259 ----->Partial loss: 0.0474963\n",
      "- - - - - >Iteration:  260 ----->Partial loss: 0.105705\n",
      "- - - - - >Iteration:  261 ----->Partial loss: 0.159187\n",
      "- - - - - >Iteration:  262 ----->Partial loss: 0.0409118\n",
      "- - - - - >Iteration:  263 ----->Partial loss: 0.0782656\n",
      "- - - - - >Iteration:  264 ----->Partial loss: 0.0726641\n",
      "- - - - - >Iteration:  265 ----->Partial loss: 0.102948\n",
      "- - - - - >Iteration:  266 ----->Partial loss: 0.0489639\n",
      "- - - - - >Iteration:  267 ----->Partial loss: 0.0982997\n",
      "- - - - - >Iteration:  268 ----->Partial loss: 0.0689794\n",
      "- - - - - >Iteration:  269 ----->Partial loss: 0.0654466\n",
      "- - - - - >Iteration:  270 ----->Partial loss: 0.0405415\n",
      "- - - - - >Iteration:  271 ----->Partial loss: 0.0498579\n",
      "- - - - - >Iteration:  272 ----->Partial loss: 0.0501459\n",
      "- - - - - >Iteration:  273 ----->Partial loss: 0.0897617\n",
      "- - - - - >Iteration:  274 ----->Partial loss: 0.0642929\n",
      "- - - - - >Iteration:  275 ----->Partial loss: 0.0377747\n",
      "- - - - - >Iteration:  276 ----->Partial loss: 0.15395\n",
      "- - - - - >Iteration:  277 ----->Partial loss: 0.093307\n",
      "- - - - - >Iteration:  278 ----->Partial loss: 0.0800294\n",
      "- - - - - >Iteration:  279 ----->Partial loss: 0.0473192\n",
      "- - - - - >Iteration:  280 ----->Partial loss: 0.12022\n",
      "- - - - - >Iteration:  281 ----->Partial loss: 0.0789141\n",
      "- - - - - >Iteration:  282 ----->Partial loss: 0.0393832\n",
      "- - - - - >Iteration:  283 ----->Partial loss: 0.078981\n",
      "- - - - - >Iteration:  284 ----->Partial loss: 0.0677562\n",
      "- - - - - >Iteration:  285 ----->Partial loss: 0.100586\n",
      "- - - - - >Iteration:  286 ----->Partial loss: 0.0526364\n",
      "- - - - - >Iteration:  287 ----->Partial loss: 0.0373018\n",
      "- - - - - >Iteration:  288 ----->Partial loss: 0.03144\n",
      "- - - - - >Iteration:  289 ----->Partial loss: 0.071517\n",
      "***************\n",
      "Epoch:  12  of  20 training loss:  0.0765927219151\n",
      "***************\n",
      "- - - - - >Iteration:  1 ----->Partial loss: 0.207489\n",
      "- - - - - >Iteration:  2 ----->Partial loss: 0.0313248\n",
      "- - - - - >Iteration:  3 ----->Partial loss: 0.0524891\n",
      "- - - - - >Iteration:  4 ----->Partial loss: 0.0752212\n",
      "- - - - - >Iteration:  5 ----->Partial loss: 0.0670505\n",
      "- - - - - >Iteration:  6 ----->Partial loss: 0.085767\n",
      "- - - - - >Iteration:  7 ----->Partial loss: 0.121672\n",
      "- - - - - >Iteration:  8 ----->Partial loss: 0.0406935\n",
      "- - - - - >Iteration:  9 ----->Partial loss: 0.231919\n",
      "- - - - - >Iteration:  10 ----->Partial loss: 0.0695532\n",
      "- - - - - >Iteration:  11 ----->Partial loss: 0.186245\n",
      "- - - - - >Iteration:  12 ----->Partial loss: 0.0420004\n",
      "- - - - - >Iteration:  13 ----->Partial loss: 0.0539618\n",
      "- - - - - >Iteration:  14 ----->Partial loss: 0.069763\n",
      "- - - - - >Iteration:  15 ----->Partial loss: 0.0916268\n",
      "- - - - - >Iteration:  16 ----->Partial loss: 0.0794039\n",
      "- - - - - >Iteration:  17 ----->Partial loss: 0.0447416\n",
      "- - - - - >Iteration:  18 ----->Partial loss: 0.0392587\n",
      "- - - - - >Iteration:  19 ----->Partial loss: 0.109311\n",
      "- - - - - >Iteration:  20 ----->Partial loss: 0.0388201\n",
      "- - - - - >Iteration:  21 ----->Partial loss: 0.0990633\n",
      "- - - - - >Iteration:  22 ----->Partial loss: 0.109552\n",
      "- - - - - >Iteration:  23 ----->Partial loss: 0.0898373\n",
      "- - - - - >Iteration:  24 ----->Partial loss: 0.103653\n",
      "- - - - - >Iteration:  25 ----->Partial loss: 0.0528631\n",
      "- - - - - >Iteration:  26 ----->Partial loss: 0.167019\n",
      "- - - - - >Iteration:  27 ----->Partial loss: 0.0584102\n",
      "- - - - - >Iteration:  28 ----->Partial loss: 0.0366006\n",
      "- - - - - >Iteration:  29 ----->Partial loss: 0.054441\n",
      "- - - - - >Iteration:  30 ----->Partial loss: 0.0383896\n",
      "- - - - - >Iteration:  31 ----->Partial loss: 0.0833675\n",
      "- - - - - >Iteration:  32 ----->Partial loss: 0.0593946\n",
      "- - - - - >Iteration:  33 ----->Partial loss: 0.0948743\n",
      "- - - - - >Iteration:  34 ----->Partial loss: 0.0302494\n",
      "- - - - - >Iteration:  35 ----->Partial loss: 0.0547643\n",
      "- - - - - >Iteration:  36 ----->Partial loss: 0.115059\n",
      "- - - - - >Iteration:  37 ----->Partial loss: 0.0372869\n",
      "- - - - - >Iteration:  38 ----->Partial loss: 0.0458788\n",
      "- - - - - >Iteration:  39 ----->Partial loss: 0.0444744\n",
      "- - - - - >Iteration:  40 ----->Partial loss: 0.0835133\n",
      "- - - - - >Iteration:  41 ----->Partial loss: 0.0356154\n",
      "- - - - - >Iteration:  42 ----->Partial loss: 0.0763898\n",
      "- - - - - >Iteration:  43 ----->Partial loss: 0.0248301\n",
      "- - - - - >Iteration:  44 ----->Partial loss: 0.0689842\n",
      "- - - - - >Iteration:  45 ----->Partial loss: 0.0421706\n",
      "- - - - - >Iteration:  46 ----->Partial loss: 0.0816427\n",
      "- - - - - >Iteration:  47 ----->Partial loss: 0.0645254\n",
      "- - - - - >Iteration:  48 ----->Partial loss: 0.0338996\n",
      "- - - - - >Iteration:  49 ----->Partial loss: 0.122718\n",
      "- - - - - >Iteration:  50 ----->Partial loss: 0.0494585\n",
      "- - - - - >Iteration:  51 ----->Partial loss: 0.0681189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- - - - - >Iteration:  52 ----->Partial loss: 0.0386078\n",
      "- - - - - >Iteration:  53 ----->Partial loss: 0.293213\n",
      "- - - - - >Iteration:  54 ----->Partial loss: 0.0509492\n",
      "- - - - - >Iteration:  55 ----->Partial loss: 0.15987\n",
      "- - - - - >Iteration:  56 ----->Partial loss: 0.132325\n",
      "- - - - - >Iteration:  57 ----->Partial loss: 0.0963751\n",
      "- - - - - >Iteration:  58 ----->Partial loss: 0.154217\n",
      "- - - - - >Iteration:  59 ----->Partial loss: 0.0894943\n",
      "- - - - - >Iteration:  60 ----->Partial loss: 0.373355\n",
      "- - - - - >Iteration:  61 ----->Partial loss: 0.0917842\n",
      "- - - - - >Iteration:  62 ----->Partial loss: 0.0843305\n",
      "- - - - - >Iteration:  63 ----->Partial loss: 0.0417987\n",
      "- - - - - >Iteration:  64 ----->Partial loss: 0.189898\n",
      "- - - - - >Iteration:  65 ----->Partial loss: 0.056564\n",
      "- - - - - >Iteration:  66 ----->Partial loss: 0.123927\n",
      "- - - - - >Iteration:  67 ----->Partial loss: 0.0780278\n",
      "- - - - - >Iteration:  68 ----->Partial loss: 0.185033\n",
      "- - - - - >Iteration:  69 ----->Partial loss: 0.0898064\n",
      "- - - - - >Iteration:  70 ----->Partial loss: 0.0774712\n",
      "- - - - - >Iteration:  71 ----->Partial loss: 0.126258\n",
      "- - - - - >Iteration:  72 ----->Partial loss: 0.121136\n",
      "- - - - - >Iteration:  73 ----->Partial loss: 0.0916621\n",
      "- - - - - >Iteration:  74 ----->Partial loss: 0.203547\n",
      "- - - - - >Iteration:  75 ----->Partial loss: 0.0964366\n",
      "- - - - - >Iteration:  76 ----->Partial loss: 0.157394\n",
      "- - - - - >Iteration:  77 ----->Partial loss: 0.111763\n",
      "- - - - - >Iteration:  78 ----->Partial loss: 0.308245\n",
      "- - - - - >Iteration:  79 ----->Partial loss: 0.151588\n",
      "- - - - - >Iteration:  80 ----->Partial loss: 0.158944\n",
      "- - - - - >Iteration:  81 ----->Partial loss: 0.0896641\n",
      "- - - - - >Iteration:  82 ----->Partial loss: 0.0569034\n",
      "- - - - - >Iteration:  83 ----->Partial loss: 0.129447\n",
      "- - - - - >Iteration:  84 ----->Partial loss: 0.0778457\n",
      "- - - - - >Iteration:  85 ----->Partial loss: 0.0958379\n",
      "- - - - - >Iteration:  86 ----->Partial loss: 0.0875122\n",
      "- - - - - >Iteration:  87 ----->Partial loss: 0.0558605\n",
      "- - - - - >Iteration:  88 ----->Partial loss: 0.32853\n",
      "- - - - - >Iteration:  89 ----->Partial loss: 0.0710906\n",
      "- - - - - >Iteration:  90 ----->Partial loss: 0.064206\n",
      "- - - - - >Iteration:  91 ----->Partial loss: 0.119633\n",
      "- - - - - >Iteration:  92 ----->Partial loss: 0.168403\n",
      "- - - - - >Iteration:  93 ----->Partial loss: 0.140775\n",
      "- - - - - >Iteration:  94 ----->Partial loss: 0.0847181\n",
      "- - - - - >Iteration:  95 ----->Partial loss: 0.0980538\n",
      "- - - - - >Iteration:  96 ----->Partial loss: 0.13312\n",
      "- - - - - >Iteration:  97 ----->Partial loss: 0.0503591\n",
      "- - - - - >Iteration:  98 ----->Partial loss: 0.0928149\n",
      "- - - - - >Iteration:  99 ----->Partial loss: 0.119519\n",
      "- - - - - >Iteration:  100 ----->Partial loss: 0.118543\n",
      "- - - - - >Iteration:  101 ----->Partial loss: 0.154225\n",
      "- - - - - >Iteration:  102 ----->Partial loss: 0.155703\n",
      "- - - - - >Iteration:  103 ----->Partial loss: 0.0334165\n",
      "- - - - - >Iteration:  104 ----->Partial loss: 0.0647276\n",
      "- - - - - >Iteration:  105 ----->Partial loss: 0.138969\n",
      "- - - - - >Iteration:  106 ----->Partial loss: 0.036576\n",
      "- - - - - >Iteration:  107 ----->Partial loss: 0.126203\n",
      "- - - - - >Iteration:  108 ----->Partial loss: 0.045435\n",
      "- - - - - >Iteration:  109 ----->Partial loss: 0.0481279\n",
      "- - - - - >Iteration:  110 ----->Partial loss: 0.088403\n",
      "- - - - - >Iteration:  111 ----->Partial loss: 0.0523404\n",
      "- - - - - >Iteration:  112 ----->Partial loss: 0.0979856\n",
      "- - - - - >Iteration:  113 ----->Partial loss: 0.0946534\n",
      "- - - - - >Iteration:  114 ----->Partial loss: 0.0938745\n",
      "- - - - - >Iteration:  115 ----->Partial loss: 0.0593389\n",
      "- - - - - >Iteration:  116 ----->Partial loss: 0.0455175\n",
      "- - - - - >Iteration:  117 ----->Partial loss: 0.0631725\n",
      "- - - - - >Iteration:  118 ----->Partial loss: 0.0857174\n",
      "- - - - - >Iteration:  119 ----->Partial loss: 0.0757794\n",
      "- - - - - >Iteration:  120 ----->Partial loss: 0.0574659\n",
      "- - - - - >Iteration:  121 ----->Partial loss: 0.0281153\n",
      "- - - - - >Iteration:  122 ----->Partial loss: 0.192058\n",
      "- - - - - >Iteration:  123 ----->Partial loss: 0.0810569\n",
      "- - - - - >Iteration:  124 ----->Partial loss: 0.0420343\n",
      "- - - - - >Iteration:  125 ----->Partial loss: 0.048829\n",
      "- - - - - >Iteration:  126 ----->Partial loss: 0.0757575\n",
      "- - - - - >Iteration:  127 ----->Partial loss: 0.061187\n",
      "- - - - - >Iteration:  128 ----->Partial loss: 0.221858\n",
      "- - - - - >Iteration:  129 ----->Partial loss: 0.0549956\n",
      "- - - - - >Iteration:  130 ----->Partial loss: 0.0967919\n",
      "- - - - - >Iteration:  131 ----->Partial loss: 0.0267022\n",
      "- - - - - >Iteration:  132 ----->Partial loss: 0.0750163\n",
      "- - - - - >Iteration:  133 ----->Partial loss: 0.124465\n",
      "- - - - - >Iteration:  134 ----->Partial loss: 0.0997662\n",
      "- - - - - >Iteration:  135 ----->Partial loss: 0.0497565\n",
      "- - - - - >Iteration:  136 ----->Partial loss: 0.0468901\n",
      "- - - - - >Iteration:  137 ----->Partial loss: 0.0489431\n",
      "- - - - - >Iteration:  138 ----->Partial loss: 0.0867621\n",
      "- - - - - >Iteration:  139 ----->Partial loss: 0.0646071\n",
      "- - - - - >Iteration:  140 ----->Partial loss: 0.0830965\n",
      "- - - - - >Iteration:  141 ----->Partial loss: 0.0977006\n",
      "- - - - - >Iteration:  142 ----->Partial loss: 0.0705688\n",
      "- - - - - >Iteration:  143 ----->Partial loss: 0.145783\n",
      "- - - - - >Iteration:  144 ----->Partial loss: 0.0386873\n",
      "- - - - - >Iteration:  145 ----->Partial loss: 0.061436\n",
      "- - - - - >Iteration:  146 ----->Partial loss: 0.0717017\n",
      "- - - - - >Iteration:  147 ----->Partial loss: 0.0627598\n",
      "- - - - - >Iteration:  148 ----->Partial loss: 0.0577683\n",
      "- - - - - >Iteration:  149 ----->Partial loss: 0.0686994\n",
      "- - - - - >Iteration:  150 ----->Partial loss: 0.0520566\n",
      "- - - - - >Iteration:  151 ----->Partial loss: 0.0813256\n",
      "- - - - - >Iteration:  152 ----->Partial loss: 0.0926864\n",
      "- - - - - >Iteration:  153 ----->Partial loss: 0.0857095\n",
      "- - - - - >Iteration:  154 ----->Partial loss: 0.125677\n",
      "- - - - - >Iteration:  155 ----->Partial loss: 0.0954519\n",
      "- - - - - >Iteration:  156 ----->Partial loss: 0.114174\n",
      "- - - - - >Iteration:  157 ----->Partial loss: 0.0468684\n",
      "- - - - - >Iteration:  158 ----->Partial loss: 0.0392689\n",
      "- - - - - >Iteration:  159 ----->Partial loss: 0.0531034\n",
      "- - - - - >Iteration:  160 ----->Partial loss: 0.0511973\n",
      "- - - - - >Iteration:  161 ----->Partial loss: 0.0492816\n",
      "- - - - - >Iteration:  162 ----->Partial loss: 0.0753972\n",
      "- - - - - >Iteration:  163 ----->Partial loss: 0.0280991\n",
      "- - - - - >Iteration:  164 ----->Partial loss: 0.0538176\n",
      "- - - - - >Iteration:  165 ----->Partial loss: 0.0485287\n",
      "- - - - - >Iteration:  166 ----->Partial loss: 0.141858\n",
      "- - - - - >Iteration:  167 ----->Partial loss: 0.0379431\n",
      "- - - - - >Iteration:  168 ----->Partial loss: 0.116317\n",
      "- - - - - >Iteration:  169 ----->Partial loss: 0.0626919\n",
      "- - - - - >Iteration:  170 ----->Partial loss: 0.129243\n",
      "- - - - - >Iteration:  171 ----->Partial loss: 0.0368766\n",
      "- - - - - >Iteration:  172 ----->Partial loss: 0.0617787\n",
      "- - - - - >Iteration:  173 ----->Partial loss: 0.0600484\n",
      "- - - - - >Iteration:  174 ----->Partial loss: 0.0286506\n",
      "- - - - - >Iteration:  175 ----->Partial loss: 0.0546469\n",
      "- - - - - >Iteration:  176 ----->Partial loss: 0.0847145\n",
      "- - - - - >Iteration:  177 ----->Partial loss: 0.0418206\n",
      "- - - - - >Iteration:  178 ----->Partial loss: 0.102425\n",
      "- - - - - >Iteration:  179 ----->Partial loss: 0.0574118\n",
      "- - - - - >Iteration:  180 ----->Partial loss: 0.0793616\n",
      "- - - - - >Iteration:  181 ----->Partial loss: 0.0780235\n",
      "- - - - - >Iteration:  182 ----->Partial loss: 0.0537706\n",
      "- - - - - >Iteration:  183 ----->Partial loss: 0.0807377\n",
      "- - - - - >Iteration:  184 ----->Partial loss: 0.0439961\n",
      "- - - - - >Iteration:  185 ----->Partial loss: 0.0328083\n",
      "- - - - - >Iteration:  186 ----->Partial loss: 0.0306964\n",
      "- - - - - >Iteration:  187 ----->Partial loss: 0.15238\n",
      "- - - - - >Iteration:  188 ----->Partial loss: 0.0956359\n",
      "- - - - - >Iteration:  189 ----->Partial loss: 0.0916236\n",
      "- - - - - >Iteration:  190 ----->Partial loss: 0.109438\n",
      "- - - - - >Iteration:  191 ----->Partial loss: 0.0493174\n",
      "- - - - - >Iteration:  192 ----->Partial loss: 0.0851757\n",
      "- - - - - >Iteration:  193 ----->Partial loss: 0.0568768\n",
      "- - - - - >Iteration:  194 ----->Partial loss: 0.0278519\n",
      "- - - - - >Iteration:  195 ----->Partial loss: 0.0299051\n",
      "- - - - - >Iteration:  196 ----->Partial loss: 0.100969\n",
      "- - - - - >Iteration:  197 ----->Partial loss: 0.0678102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- - - - - >Iteration:  198 ----->Partial loss: 0.10181\n",
      "- - - - - >Iteration:  199 ----->Partial loss: 0.0661837\n",
      "- - - - - >Iteration:  200 ----->Partial loss: 0.0488739\n",
      "- - - - - >Iteration:  201 ----->Partial loss: 0.0596359\n",
      "- - - - - >Iteration:  202 ----->Partial loss: 0.060148\n",
      "- - - - - >Iteration:  203 ----->Partial loss: 0.0980381\n",
      "- - - - - >Iteration:  204 ----->Partial loss: 0.144693\n",
      "- - - - - >Iteration:  205 ----->Partial loss: 0.106618\n",
      "- - - - - >Iteration:  206 ----->Partial loss: 0.0593085\n",
      "- - - - - >Iteration:  207 ----->Partial loss: 0.0357004\n",
      "- - - - - >Iteration:  208 ----->Partial loss: 0.0898905\n",
      "- - - - - >Iteration:  209 ----->Partial loss: 0.0622588\n",
      "- - - - - >Iteration:  210 ----->Partial loss: 0.0596272\n",
      "- - - - - >Iteration:  211 ----->Partial loss: 0.101107\n",
      "- - - - - >Iteration:  212 ----->Partial loss: 0.0674953\n",
      "- - - - - >Iteration:  213 ----->Partial loss: 0.0803027\n",
      "- - - - - >Iteration:  214 ----->Partial loss: 0.0718025\n",
      "- - - - - >Iteration:  215 ----->Partial loss: 0.0680606\n",
      "- - - - - >Iteration:  216 ----->Partial loss: 0.0441823\n",
      "- - - - - >Iteration:  217 ----->Partial loss: 0.0342679\n",
      "- - - - - >Iteration:  218 ----->Partial loss: 0.119252\n",
      "- - - - - >Iteration:  219 ----->Partial loss: 0.0729564\n",
      "- - - - - >Iteration:  220 ----->Partial loss: 0.077224\n",
      "- - - - - >Iteration:  221 ----->Partial loss: 0.0327719\n",
      "- - - - - >Iteration:  222 ----->Partial loss: 0.106385\n",
      "- - - - - >Iteration:  223 ----->Partial loss: 0.0435831\n",
      "- - - - - >Iteration:  224 ----->Partial loss: 0.116622\n",
      "- - - - - >Iteration:  225 ----->Partial loss: 0.091378\n",
      "- - - - - >Iteration:  226 ----->Partial loss: 0.0658631\n",
      "- - - - - >Iteration:  227 ----->Partial loss: 0.109064\n",
      "- - - - - >Iteration:  228 ----->Partial loss: 0.0382635\n",
      "- - - - - >Iteration:  229 ----->Partial loss: 0.062895\n",
      "- - - - - >Iteration:  230 ----->Partial loss: 0.0335786\n",
      "- - - - - >Iteration:  231 ----->Partial loss: 0.0764338\n",
      "- - - - - >Iteration:  232 ----->Partial loss: 0.088875\n",
      "- - - - - >Iteration:  233 ----->Partial loss: 0.0566506\n",
      "- - - - - >Iteration:  234 ----->Partial loss: 0.0319311\n",
      "- - - - - >Iteration:  235 ----->Partial loss: 0.0964604\n",
      "- - - - - >Iteration:  236 ----->Partial loss: 0.216346\n",
      "- - - - - >Iteration:  237 ----->Partial loss: 0.092783\n",
      "- - - - - >Iteration:  238 ----->Partial loss: 0.0822107\n",
      "- - - - - >Iteration:  239 ----->Partial loss: 0.0947544\n",
      "- - - - - >Iteration:  240 ----->Partial loss: 0.139393\n",
      "- - - - - >Iteration:  241 ----->Partial loss: 0.0768579\n",
      "- - - - - >Iteration:  242 ----->Partial loss: 0.0948426\n",
      "- - - - - >Iteration:  243 ----->Partial loss: 0.0890768\n",
      "- - - - - >Iteration:  244 ----->Partial loss: 0.133929\n",
      "- - - - - >Iteration:  245 ----->Partial loss: 0.10944\n",
      "- - - - - >Iteration:  246 ----->Partial loss: 0.0922787\n",
      "- - - - - >Iteration:  247 ----->Partial loss: 0.0425747\n",
      "- - - - - >Iteration:  248 ----->Partial loss: 0.0617101\n",
      "- - - - - >Iteration:  249 ----->Partial loss: 0.0523493\n",
      "- - - - - >Iteration:  250 ----->Partial loss: 0.0484498\n",
      "- - - - - >Iteration:  251 ----->Partial loss: 0.0451318\n",
      "- - - - - >Iteration:  252 ----->Partial loss: 0.036599\n",
      "- - - - - >Iteration:  253 ----->Partial loss: 0.123623\n",
      "- - - - - >Iteration:  254 ----->Partial loss: 0.0635159\n",
      "- - - - - >Iteration:  255 ----->Partial loss: 0.0604941\n",
      "- - - - - >Iteration:  256 ----->Partial loss: 0.133836\n",
      "- - - - - >Iteration:  257 ----->Partial loss: 0.04891\n",
      "- - - - - >Iteration:  258 ----->Partial loss: 0.0436721\n",
      "- - - - - >Iteration:  259 ----->Partial loss: 0.0633555\n",
      "- - - - - >Iteration:  260 ----->Partial loss: 0.0567701\n",
      "- - - - - >Iteration:  261 ----->Partial loss: 0.0579396\n",
      "- - - - - >Iteration:  262 ----->Partial loss: 0.0601905\n",
      "- - - - - >Iteration:  263 ----->Partial loss: 0.0421603\n",
      "- - - - - >Iteration:  264 ----->Partial loss: 0.0609628\n",
      "- - - - - >Iteration:  265 ----->Partial loss: 0.101121\n",
      "- - - - - >Iteration:  266 ----->Partial loss: 0.0951045\n",
      "- - - - - >Iteration:  267 ----->Partial loss: 0.0541925\n",
      "- - - - - >Iteration:  268 ----->Partial loss: 0.11116\n",
      "- - - - - >Iteration:  269 ----->Partial loss: 0.0583935\n",
      "- - - - - >Iteration:  270 ----->Partial loss: 0.146825\n",
      "- - - - - >Iteration:  271 ----->Partial loss: 0.0601629\n",
      "- - - - - >Iteration:  272 ----->Partial loss: 0.0718924\n",
      "- - - - - >Iteration:  273 ----->Partial loss: 0.0419338\n",
      "- - - - - >Iteration:  274 ----->Partial loss: 0.115689\n",
      "- - - - - >Iteration:  275 ----->Partial loss: 0.049191\n",
      "- - - - - >Iteration:  276 ----->Partial loss: 0.0599575\n",
      "- - - - - >Iteration:  277 ----->Partial loss: 0.0412982\n",
      "- - - - - >Iteration:  278 ----->Partial loss: 0.0354126\n",
      "- - - - - >Iteration:  279 ----->Partial loss: 0.039936\n",
      "- - - - - >Iteration:  280 ----->Partial loss: 0.0304023\n",
      "- - - - - >Iteration:  281 ----->Partial loss: 0.0735549\n",
      "- - - - - >Iteration:  282 ----->Partial loss: 0.0580421\n",
      "- - - - - >Iteration:  283 ----->Partial loss: 0.140668\n",
      "- - - - - >Iteration:  284 ----->Partial loss: 0.0429396\n",
      "- - - - - >Iteration:  285 ----->Partial loss: 0.141263\n",
      "- - - - - >Iteration:  286 ----->Partial loss: 0.0790116\n",
      "- - - - - >Iteration:  287 ----->Partial loss: 0.118201\n",
      "- - - - - >Iteration:  288 ----->Partial loss: 0.0698757\n",
      "- - - - - >Iteration:  289 ----->Partial loss: 0.0660396\n",
      "***************\n",
      "Epoch:  13  of  20 training loss:  0.0839643727176\n",
      "***************\n",
      "- - - - - >Iteration:  1 ----->Partial loss: 0.0879926\n",
      "- - - - - >Iteration:  2 ----->Partial loss: 0.0801633\n",
      "- - - - - >Iteration:  3 ----->Partial loss: 0.0633569\n",
      "- - - - - >Iteration:  4 ----->Partial loss: 0.0367178\n",
      "- - - - - >Iteration:  5 ----->Partial loss: 0.0869096\n",
      "- - - - - >Iteration:  6 ----->Partial loss: 0.086543\n",
      "- - - - - >Iteration:  7 ----->Partial loss: 0.0607973\n",
      "- - - - - >Iteration:  8 ----->Partial loss: 0.0438317\n",
      "- - - - - >Iteration:  9 ----->Partial loss: 0.0479948\n",
      "- - - - - >Iteration:  10 ----->Partial loss: 0.0536974\n",
      "- - - - - >Iteration:  11 ----->Partial loss: 0.0490379\n",
      "- - - - - >Iteration:  12 ----->Partial loss: 0.0323031\n",
      "- - - - - >Iteration:  13 ----->Partial loss: 0.0951169\n",
      "- - - - - >Iteration:  14 ----->Partial loss: 0.216642\n",
      "- - - - - >Iteration:  15 ----->Partial loss: 0.164391\n",
      "- - - - - >Iteration:  16 ----->Partial loss: 0.0619186\n",
      "- - - - - >Iteration:  17 ----->Partial loss: 0.0389073\n",
      "- - - - - >Iteration:  18 ----->Partial loss: 0.034929\n",
      "- - - - - >Iteration:  19 ----->Partial loss: 0.0488364\n",
      "- - - - - >Iteration:  20 ----->Partial loss: 0.0724438\n",
      "- - - - - >Iteration:  21 ----->Partial loss: 0.0306695\n",
      "- - - - - >Iteration:  22 ----->Partial loss: 0.0455927\n",
      "- - - - - >Iteration:  23 ----->Partial loss: 0.0564548\n",
      "- - - - - >Iteration:  24 ----->Partial loss: 0.0532428\n",
      "- - - - - >Iteration:  25 ----->Partial loss: 0.0614247\n",
      "- - - - - >Iteration:  26 ----->Partial loss: 0.0396821\n",
      "- - - - - >Iteration:  27 ----->Partial loss: 0.0922096\n",
      "- - - - - >Iteration:  28 ----->Partial loss: 0.0298499\n",
      "- - - - - >Iteration:  29 ----->Partial loss: 0.0290032\n",
      "- - - - - >Iteration:  30 ----->Partial loss: 0.0338452\n",
      "- - - - - >Iteration:  31 ----->Partial loss: 0.0296143\n",
      "- - - - - >Iteration:  32 ----->Partial loss: 0.08882\n",
      "- - - - - >Iteration:  33 ----->Partial loss: 0.0467892\n",
      "- - - - - >Iteration:  34 ----->Partial loss: 0.161581\n",
      "- - - - - >Iteration:  35 ----->Partial loss: 0.064087\n",
      "- - - - - >Iteration:  36 ----->Partial loss: 0.0750895\n",
      "- - - - - >Iteration:  37 ----->Partial loss: 0.0517676\n",
      "- - - - - >Iteration:  38 ----->Partial loss: 0.127139\n",
      "- - - - - >Iteration:  39 ----->Partial loss: 0.0553624\n",
      "- - - - - >Iteration:  40 ----->Partial loss: 0.0953192\n",
      "- - - - - >Iteration:  41 ----->Partial loss: 0.0752095\n",
      "- - - - - >Iteration:  42 ----->Partial loss: 0.0562939\n",
      "- - - - - >Iteration:  43 ----->Partial loss: 0.0535787\n",
      "- - - - - >Iteration:  44 ----->Partial loss: 0.0510986\n",
      "- - - - - >Iteration:  45 ----->Partial loss: 0.0870249\n",
      "- - - - - >Iteration:  46 ----->Partial loss: 0.0570413\n",
      "- - - - - >Iteration:  47 ----->Partial loss: 0.0990892\n",
      "- - - - - >Iteration:  48 ----->Partial loss: 0.0776245\n",
      "- - - - - >Iteration:  49 ----->Partial loss: 0.0564888\n",
      "- - - - - >Iteration:  50 ----->Partial loss: 0.0781583\n",
      "- - - - - >Iteration:  51 ----->Partial loss: 0.0781239\n",
      "- - - - - >Iteration:  52 ----->Partial loss: 0.0853541\n",
      "- - - - - >Iteration:  53 ----->Partial loss: 0.0932734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- - - - - >Iteration:  54 ----->Partial loss: 0.0591861\n",
      "- - - - - >Iteration:  55 ----->Partial loss: 0.124044\n",
      "- - - - - >Iteration:  56 ----->Partial loss: 0.0721578\n",
      "- - - - - >Iteration:  57 ----->Partial loss: 0.0417719\n",
      "- - - - - >Iteration:  58 ----->Partial loss: 0.0891359\n",
      "- - - - - >Iteration:  59 ----->Partial loss: 0.114705\n",
      "- - - - - >Iteration:  60 ----->Partial loss: 0.0775506\n",
      "- - - - - >Iteration:  61 ----->Partial loss: 0.0710011\n",
      "- - - - - >Iteration:  62 ----->Partial loss: 0.0474666\n",
      "- - - - - >Iteration:  63 ----->Partial loss: 0.0588236\n",
      "- - - - - >Iteration:  64 ----->Partial loss: 0.0343162\n",
      "- - - - - >Iteration:  65 ----->Partial loss: 0.0459805\n",
      "- - - - - >Iteration:  66 ----->Partial loss: 0.0700659\n",
      "- - - - - >Iteration:  67 ----->Partial loss: 0.0269744\n",
      "- - - - - >Iteration:  68 ----->Partial loss: 0.0697188\n",
      "- - - - - >Iteration:  69 ----->Partial loss: 0.073115\n",
      "- - - - - >Iteration:  70 ----->Partial loss: 0.101688\n",
      "- - - - - >Iteration:  71 ----->Partial loss: 0.0280094\n",
      "- - - - - >Iteration:  72 ----->Partial loss: 0.0836012\n",
      "- - - - - >Iteration:  73 ----->Partial loss: 0.0963614\n",
      "- - - - - >Iteration:  74 ----->Partial loss: 0.0966219\n",
      "- - - - - >Iteration:  75 ----->Partial loss: 0.061131\n",
      "- - - - - >Iteration:  76 ----->Partial loss: 0.0747359\n",
      "- - - - - >Iteration:  77 ----->Partial loss: 0.0505017\n",
      "- - - - - >Iteration:  78 ----->Partial loss: 0.0406311\n",
      "- - - - - >Iteration:  79 ----->Partial loss: 0.0376209\n",
      "- - - - - >Iteration:  80 ----->Partial loss: 0.111933\n",
      "- - - - - >Iteration:  81 ----->Partial loss: 0.0637977\n",
      "- - - - - >Iteration:  82 ----->Partial loss: 0.055702\n",
      "- - - - - >Iteration:  83 ----->Partial loss: 0.0642384\n",
      "- - - - - >Iteration:  84 ----->Partial loss: 0.0347817\n",
      "- - - - - >Iteration:  85 ----->Partial loss: 0.0575897\n",
      "- - - - - >Iteration:  86 ----->Partial loss: 0.0667823\n",
      "- - - - - >Iteration:  87 ----->Partial loss: 0.0642555\n",
      "- - - - - >Iteration:  88 ----->Partial loss: 0.0341831\n",
      "- - - - - >Iteration:  89 ----->Partial loss: 0.0793723\n",
      "- - - - - >Iteration:  90 ----->Partial loss: 0.0491233\n",
      "- - - - - >Iteration:  91 ----->Partial loss: 0.0534223\n",
      "- - - - - >Iteration:  92 ----->Partial loss: 0.0762162\n",
      "- - - - - >Iteration:  93 ----->Partial loss: 0.0907487\n",
      "- - - - - >Iteration:  94 ----->Partial loss: 0.0301578\n",
      "- - - - - >Iteration:  95 ----->Partial loss: 0.055903\n",
      "- - - - - >Iteration:  96 ----->Partial loss: 0.0302436\n",
      "- - - - - >Iteration:  97 ----->Partial loss: 0.0479915\n",
      "- - - - - >Iteration:  98 ----->Partial loss: 0.027794\n",
      "- - - - - >Iteration:  99 ----->Partial loss: 0.0759027\n",
      "- - - - - >Iteration:  100 ----->Partial loss: 0.0570999\n",
      "- - - - - >Iteration:  101 ----->Partial loss: 0.080269\n",
      "- - - - - >Iteration:  102 ----->Partial loss: 0.0510413\n",
      "- - - - - >Iteration:  103 ----->Partial loss: 0.064294\n",
      "- - - - - >Iteration:  104 ----->Partial loss: 0.0982542\n",
      "- - - - - >Iteration:  105 ----->Partial loss: 0.0319325\n",
      "- - - - - >Iteration:  106 ----->Partial loss: 0.0348928\n",
      "- - - - - >Iteration:  107 ----->Partial loss: 0.0464016\n",
      "- - - - - >Iteration:  108 ----->Partial loss: 0.0422406\n",
      "- - - - - >Iteration:  109 ----->Partial loss: 0.052327\n",
      "- - - - - >Iteration:  110 ----->Partial loss: 0.0449268\n",
      "- - - - - >Iteration:  111 ----->Partial loss: 0.041405\n",
      "- - - - - >Iteration:  112 ----->Partial loss: 0.0901739\n",
      "- - - - - >Iteration:  113 ----->Partial loss: 0.0715615\n",
      "- - - - - >Iteration:  114 ----->Partial loss: 0.162594\n",
      "- - - - - >Iteration:  115 ----->Partial loss: 0.0874728\n",
      "- - - - - >Iteration:  116 ----->Partial loss: 0.0597175\n",
      "- - - - - >Iteration:  117 ----->Partial loss: 0.0564698\n",
      "- - - - - >Iteration:  118 ----->Partial loss: 0.104102\n",
      "- - - - - >Iteration:  119 ----->Partial loss: 0.0502473\n",
      "- - - - - >Iteration:  120 ----->Partial loss: 0.049814\n",
      "- - - - - >Iteration:  121 ----->Partial loss: 0.0369931\n",
      "- - - - - >Iteration:  122 ----->Partial loss: 0.0263811\n",
      "- - - - - >Iteration:  123 ----->Partial loss: 0.0802385\n",
      "- - - - - >Iteration:  124 ----->Partial loss: 0.0493319\n",
      "- - - - - >Iteration:  125 ----->Partial loss: 0.0900884\n",
      "- - - - - >Iteration:  126 ----->Partial loss: 0.0966984\n",
      "- - - - - >Iteration:  127 ----->Partial loss: 0.160501\n",
      "- - - - - >Iteration:  128 ----->Partial loss: 0.103774\n",
      "- - - - - >Iteration:  129 ----->Partial loss: 0.081079\n",
      "- - - - - >Iteration:  130 ----->Partial loss: 0.0413082\n",
      "- - - - - >Iteration:  131 ----->Partial loss: 0.0768942\n",
      "- - - - - >Iteration:  132 ----->Partial loss: 0.0380971\n",
      "- - - - - >Iteration:  133 ----->Partial loss: 0.0547106\n",
      "- - - - - >Iteration:  134 ----->Partial loss: 0.10806\n",
      "- - - - - >Iteration:  135 ----->Partial loss: 0.0710947\n",
      "- - - - - >Iteration:  136 ----->Partial loss: 0.0530214\n",
      "- - - - - >Iteration:  137 ----->Partial loss: 0.0990176\n",
      "- - - - - >Iteration:  138 ----->Partial loss: 0.140264\n",
      "- - - - - >Iteration:  139 ----->Partial loss: 0.0679925\n",
      "- - - - - >Iteration:  140 ----->Partial loss: 0.0512478\n",
      "- - - - - >Iteration:  141 ----->Partial loss: 0.110718\n",
      "- - - - - >Iteration:  142 ----->Partial loss: 0.0415283\n",
      "- - - - - >Iteration:  143 ----->Partial loss: 0.101631\n",
      "- - - - - >Iteration:  144 ----->Partial loss: 0.073242\n",
      "- - - - - >Iteration:  145 ----->Partial loss: 0.0610559\n",
      "- - - - - >Iteration:  146 ----->Partial loss: 0.0631285\n",
      "- - - - - >Iteration:  147 ----->Partial loss: 0.05411\n",
      "- - - - - >Iteration:  148 ----->Partial loss: 0.0190753\n",
      "- - - - - >Iteration:  149 ----->Partial loss: 0.063709\n",
      "- - - - - >Iteration:  150 ----->Partial loss: 0.0331342\n",
      "- - - - - >Iteration:  151 ----->Partial loss: 0.0532403\n",
      "- - - - - >Iteration:  152 ----->Partial loss: 0.0247416\n",
      "- - - - - >Iteration:  153 ----->Partial loss: 0.105428\n",
      "- - - - - >Iteration:  154 ----->Partial loss: 0.0273244\n",
      "- - - - - >Iteration:  155 ----->Partial loss: 0.0779119\n",
      "- - - - - >Iteration:  156 ----->Partial loss: 0.0814295\n",
      "- - - - - >Iteration:  157 ----->Partial loss: 0.138459\n",
      "- - - - - >Iteration:  158 ----->Partial loss: 0.0626599\n",
      "- - - - - >Iteration:  159 ----->Partial loss: 0.191792\n",
      "- - - - - >Iteration:  160 ----->Partial loss: 0.127257\n",
      "- - - - - >Iteration:  161 ----->Partial loss: 0.0677442\n",
      "- - - - - >Iteration:  162 ----->Partial loss: 0.0678086\n",
      "- - - - - >Iteration:  163 ----->Partial loss: 0.048291\n",
      "- - - - - >Iteration:  164 ----->Partial loss: 0.0767525\n",
      "- - - - - >Iteration:  165 ----->Partial loss: 0.0833429\n",
      "- - - - - >Iteration:  166 ----->Partial loss: 0.0680449\n",
      "- - - - - >Iteration:  167 ----->Partial loss: 0.119095\n",
      "- - - - - >Iteration:  168 ----->Partial loss: 0.136895\n",
      "- - - - - >Iteration:  169 ----->Partial loss: 0.0955397\n",
      "- - - - - >Iteration:  170 ----->Partial loss: 0.0569732\n",
      "- - - - - >Iteration:  171 ----->Partial loss: 0.0338856\n",
      "- - - - - >Iteration:  172 ----->Partial loss: 0.0673944\n",
      "- - - - - >Iteration:  173 ----->Partial loss: 0.043679\n",
      "- - - - - >Iteration:  174 ----->Partial loss: 0.0331206\n",
      "- - - - - >Iteration:  175 ----->Partial loss: 0.0628829\n",
      "- - - - - >Iteration:  176 ----->Partial loss: 0.0959814\n",
      "- - - - - >Iteration:  177 ----->Partial loss: 0.050193\n",
      "- - - - - >Iteration:  178 ----->Partial loss: 0.0497943\n",
      "- - - - - >Iteration:  179 ----->Partial loss: 0.0511911\n",
      "- - - - - >Iteration:  180 ----->Partial loss: 0.138628\n",
      "- - - - - >Iteration:  181 ----->Partial loss: 0.0587419\n",
      "- - - - - >Iteration:  182 ----->Partial loss: 0.0350564\n",
      "- - - - - >Iteration:  183 ----->Partial loss: 0.0719659\n",
      "- - - - - >Iteration:  184 ----->Partial loss: 0.0329969\n",
      "- - - - - >Iteration:  185 ----->Partial loss: 0.0290933\n",
      "- - - - - >Iteration:  186 ----->Partial loss: 0.0566054\n",
      "- - - - - >Iteration:  187 ----->Partial loss: 0.0607677\n",
      "- - - - - >Iteration:  188 ----->Partial loss: 0.0807092\n",
      "- - - - - >Iteration:  189 ----->Partial loss: 0.0781206\n",
      "- - - - - >Iteration:  190 ----->Partial loss: 0.0378154\n",
      "- - - - - >Iteration:  191 ----->Partial loss: 0.0336065\n",
      "- - - - - >Iteration:  192 ----->Partial loss: 0.0507816\n",
      "- - - - - >Iteration:  193 ----->Partial loss: 0.0332469\n",
      "- - - - - >Iteration:  194 ----->Partial loss: 0.066476\n",
      "- - - - - >Iteration:  195 ----->Partial loss: 0.155118\n",
      "- - - - - >Iteration:  196 ----->Partial loss: 0.0533032\n",
      "- - - - - >Iteration:  197 ----->Partial loss: 0.0993479\n",
      "- - - - - >Iteration:  198 ----->Partial loss: 0.0561637\n",
      "- - - - - >Iteration:  199 ----->Partial loss: 0.079866\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- - - - - >Iteration:  200 ----->Partial loss: 0.118865\n",
      "- - - - - >Iteration:  201 ----->Partial loss: 0.0607168\n",
      "- - - - - >Iteration:  202 ----->Partial loss: 0.0587703\n",
      "- - - - - >Iteration:  203 ----->Partial loss: 0.115518\n",
      "- - - - - >Iteration:  204 ----->Partial loss: 0.0272108\n",
      "- - - - - >Iteration:  205 ----->Partial loss: 0.0523142\n",
      "- - - - - >Iteration:  206 ----->Partial loss: 0.0394617\n",
      "- - - - - >Iteration:  207 ----->Partial loss: 0.0351476\n",
      "- - - - - >Iteration:  208 ----->Partial loss: 0.077526\n",
      "- - - - - >Iteration:  209 ----->Partial loss: 0.0383749\n",
      "- - - - - >Iteration:  210 ----->Partial loss: 0.232621\n",
      "- - - - - >Iteration:  211 ----->Partial loss: 0.0460963\n",
      "- - - - - >Iteration:  212 ----->Partial loss: 0.175442\n",
      "- - - - - >Iteration:  213 ----->Partial loss: 0.0673144\n",
      "- - - - - >Iteration:  214 ----->Partial loss: 0.0575413\n",
      "- - - - - >Iteration:  215 ----->Partial loss: 0.0911175\n",
      "- - - - - >Iteration:  216 ----->Partial loss: 0.0379077\n",
      "- - - - - >Iteration:  217 ----->Partial loss: 0.0418617\n",
      "- - - - - >Iteration:  218 ----->Partial loss: 0.0617509\n",
      "- - - - - >Iteration:  219 ----->Partial loss: 0.0239432\n",
      "- - - - - >Iteration:  220 ----->Partial loss: 0.0428812\n",
      "- - - - - >Iteration:  221 ----->Partial loss: 0.0479907\n",
      "- - - - - >Iteration:  222 ----->Partial loss: 0.0348418\n",
      "- - - - - >Iteration:  223 ----->Partial loss: 0.0318107\n",
      "- - - - - >Iteration:  224 ----->Partial loss: 0.0671932\n",
      "- - - - - >Iteration:  225 ----->Partial loss: 0.08228\n",
      "- - - - - >Iteration:  226 ----->Partial loss: 0.0945157\n",
      "- - - - - >Iteration:  227 ----->Partial loss: 0.216466\n",
      "- - - - - >Iteration:  228 ----->Partial loss: 0.0605634\n",
      "- - - - - >Iteration:  229 ----->Partial loss: 0.0389502\n",
      "- - - - - >Iteration:  230 ----->Partial loss: 0.0590138\n",
      "- - - - - >Iteration:  231 ----->Partial loss: 0.0285076\n",
      "- - - - - >Iteration:  232 ----->Partial loss: 0.0499853\n",
      "- - - - - >Iteration:  233 ----->Partial loss: 0.0338485\n",
      "- - - - - >Iteration:  234 ----->Partial loss: 0.136729\n",
      "- - - - - >Iteration:  235 ----->Partial loss: 0.0366613\n",
      "- - - - - >Iteration:  236 ----->Partial loss: 0.0359023\n",
      "- - - - - >Iteration:  237 ----->Partial loss: 0.0770421\n",
      "- - - - - >Iteration:  238 ----->Partial loss: 0.0717364\n",
      "- - - - - >Iteration:  239 ----->Partial loss: 0.0981989\n",
      "- - - - - >Iteration:  240 ----->Partial loss: 0.0886063\n",
      "- - - - - >Iteration:  241 ----->Partial loss: 0.0356059\n",
      "- - - - - >Iteration:  242 ----->Partial loss: 0.0361395\n",
      "- - - - - >Iteration:  243 ----->Partial loss: 0.0763967\n",
      "- - - - - >Iteration:  244 ----->Partial loss: 0.158769\n",
      "- - - - - >Iteration:  245 ----->Partial loss: 0.0302567\n",
      "- - - - - >Iteration:  246 ----->Partial loss: 0.061811\n",
      "- - - - - >Iteration:  247 ----->Partial loss: 0.0542214\n",
      "- - - - - >Iteration:  248 ----->Partial loss: 0.036505\n",
      "- - - - - >Iteration:  249 ----->Partial loss: 0.0380351\n",
      "- - - - - >Iteration:  250 ----->Partial loss: 0.0410649\n",
      "- - - - - >Iteration:  251 ----->Partial loss: 0.0925324\n",
      "- - - - - >Iteration:  252 ----->Partial loss: 0.100869\n",
      "- - - - - >Iteration:  253 ----->Partial loss: 0.0662862\n",
      "- - - - - >Iteration:  254 ----->Partial loss: 0.0433676\n",
      "- - - - - >Iteration:  255 ----->Partial loss: 0.0243003\n",
      "- - - - - >Iteration:  256 ----->Partial loss: 0.10736\n",
      "- - - - - >Iteration:  257 ----->Partial loss: 0.0437546\n",
      "- - - - - >Iteration:  258 ----->Partial loss: 0.0813965\n",
      "- - - - - >Iteration:  259 ----->Partial loss: 0.0421741\n",
      "- - - - - >Iteration:  260 ----->Partial loss: 0.0885134\n",
      "- - - - - >Iteration:  261 ----->Partial loss: 0.0902965\n",
      "- - - - - >Iteration:  262 ----->Partial loss: 0.0961495\n",
      "- - - - - >Iteration:  263 ----->Partial loss: 0.028937\n",
      "- - - - - >Iteration:  264 ----->Partial loss: 0.063335\n",
      "- - - - - >Iteration:  265 ----->Partial loss: 0.120691\n",
      "- - - - - >Iteration:  266 ----->Partial loss: 0.0320769\n",
      "- - - - - >Iteration:  267 ----->Partial loss: 0.0664729\n",
      "- - - - - >Iteration:  268 ----->Partial loss: 0.0413797\n",
      "- - - - - >Iteration:  269 ----->Partial loss: 0.0914259\n",
      "- - - - - >Iteration:  270 ----->Partial loss: 0.0494793\n",
      "- - - - - >Iteration:  271 ----->Partial loss: 0.0747912\n",
      "- - - - - >Iteration:  272 ----->Partial loss: 0.04448\n",
      "- - - - - >Iteration:  273 ----->Partial loss: 0.0554628\n",
      "- - - - - >Iteration:  274 ----->Partial loss: 0.0409652\n",
      "- - - - - >Iteration:  275 ----->Partial loss: 0.0671539\n",
      "- - - - - >Iteration:  276 ----->Partial loss: 0.0371607\n",
      "- - - - - >Iteration:  277 ----->Partial loss: 0.101863\n",
      "- - - - - >Iteration:  278 ----->Partial loss: 0.0432407\n",
      "- - - - - >Iteration:  279 ----->Partial loss: 0.0689533\n",
      "- - - - - >Iteration:  280 ----->Partial loss: 0.0359741\n",
      "- - - - - >Iteration:  281 ----->Partial loss: 0.08815\n",
      "- - - - - >Iteration:  282 ----->Partial loss: 0.0789728\n",
      "- - - - - >Iteration:  283 ----->Partial loss: 0.045956\n",
      "- - - - - >Iteration:  284 ----->Partial loss: 0.0697646\n",
      "- - - - - >Iteration:  285 ----->Partial loss: 0.0540835\n",
      "- - - - - >Iteration:  286 ----->Partial loss: 0.0413984\n",
      "- - - - - >Iteration:  287 ----->Partial loss: 0.124053\n",
      "- - - - - >Iteration:  288 ----->Partial loss: 0.0248579\n",
      "- - - - - >Iteration:  289 ----->Partial loss: 0.0331142\n",
      "***************\n",
      "Epoch:  14  of  20 training loss:  0.0677901012082\n",
      "***************\n",
      "- - - - - >Iteration:  1 ----->Partial loss: 0.0929274\n",
      "- - - - - >Iteration:  2 ----->Partial loss: 0.135082\n",
      "- - - - - >Iteration:  3 ----->Partial loss: 0.0398937\n",
      "- - - - - >Iteration:  4 ----->Partial loss: 0.0442045\n",
      "- - - - - >Iteration:  5 ----->Partial loss: 0.0588316\n",
      "- - - - - >Iteration:  6 ----->Partial loss: 0.0667796\n",
      "- - - - - >Iteration:  7 ----->Partial loss: 0.102969\n",
      "- - - - - >Iteration:  8 ----->Partial loss: 0.0843774\n",
      "- - - - - >Iteration:  9 ----->Partial loss: 0.105713\n",
      "- - - - - >Iteration:  10 ----->Partial loss: 0.0624912\n",
      "- - - - - >Iteration:  11 ----->Partial loss: 0.0287419\n",
      "- - - - - >Iteration:  12 ----->Partial loss: 0.042468\n",
      "- - - - - >Iteration:  13 ----->Partial loss: 0.0271339\n",
      "- - - - - >Iteration:  14 ----->Partial loss: 0.0664791\n",
      "- - - - - >Iteration:  15 ----->Partial loss: 0.0284748\n",
      "- - - - - >Iteration:  16 ----->Partial loss: 0.0645344\n",
      "- - - - - >Iteration:  17 ----->Partial loss: 0.0548709\n",
      "- - - - - >Iteration:  18 ----->Partial loss: 0.0183985\n",
      "- - - - - >Iteration:  19 ----->Partial loss: 0.0264023\n",
      "- - - - - >Iteration:  20 ----->Partial loss: 0.0677927\n",
      "- - - - - >Iteration:  21 ----->Partial loss: 0.0285074\n",
      "- - - - - >Iteration:  22 ----->Partial loss: 0.0915249\n",
      "- - - - - >Iteration:  23 ----->Partial loss: 0.108133\n",
      "- - - - - >Iteration:  24 ----->Partial loss: 0.244418\n",
      "- - - - - >Iteration:  25 ----->Partial loss: 0.0631521\n",
      "- - - - - >Iteration:  26 ----->Partial loss: 0.0509222\n",
      "- - - - - >Iteration:  27 ----->Partial loss: 0.105121\n",
      "- - - - - >Iteration:  28 ----->Partial loss: 0.0510411\n",
      "- - - - - >Iteration:  29 ----->Partial loss: 0.049005\n",
      "- - - - - >Iteration:  30 ----->Partial loss: 0.064101\n",
      "- - - - - >Iteration:  31 ----->Partial loss: 0.052628\n",
      "- - - - - >Iteration:  32 ----->Partial loss: 0.0302873\n",
      "- - - - - >Iteration:  33 ----->Partial loss: 0.112718\n",
      "- - - - - >Iteration:  34 ----->Partial loss: 0.10902\n",
      "- - - - - >Iteration:  35 ----->Partial loss: 0.0539895\n",
      "- - - - - >Iteration:  36 ----->Partial loss: 0.0665394\n",
      "- - - - - >Iteration:  37 ----->Partial loss: 0.0488583\n",
      "- - - - - >Iteration:  38 ----->Partial loss: 0.0751863\n",
      "- - - - - >Iteration:  39 ----->Partial loss: 0.0669498\n",
      "- - - - - >Iteration:  40 ----->Partial loss: 0.0370096\n",
      "- - - - - >Iteration:  41 ----->Partial loss: 0.0459669\n",
      "- - - - - >Iteration:  42 ----->Partial loss: 0.162658\n",
      "- - - - - >Iteration:  43 ----->Partial loss: 0.100239\n",
      "- - - - - >Iteration:  44 ----->Partial loss: 0.0575164\n",
      "- - - - - >Iteration:  45 ----->Partial loss: 0.0337452\n",
      "- - - - - >Iteration:  46 ----->Partial loss: 0.0570441\n",
      "- - - - - >Iteration:  47 ----->Partial loss: 0.0779551\n",
      "- - - - - >Iteration:  48 ----->Partial loss: 0.0270162\n",
      "- - - - - >Iteration:  49 ----->Partial loss: 0.11582\n",
      "- - - - - >Iteration:  50 ----->Partial loss: 0.0977107\n",
      "- - - - - >Iteration:  51 ----->Partial loss: 0.0259728\n",
      "- - - - - >Iteration:  52 ----->Partial loss: 0.0336329\n",
      "- - - - - >Iteration:  53 ----->Partial loss: 0.0426188\n",
      "- - - - - >Iteration:  54 ----->Partial loss: 0.0322017\n",
      "- - - - - >Iteration:  55 ----->Partial loss: 0.0572508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- - - - - >Iteration:  56 ----->Partial loss: 0.0585238\n",
      "- - - - - >Iteration:  57 ----->Partial loss: 0.0327987\n",
      "- - - - - >Iteration:  58 ----->Partial loss: 0.0809374\n",
      "- - - - - >Iteration:  59 ----->Partial loss: 0.0940717\n",
      "- - - - - >Iteration:  60 ----->Partial loss: 0.0631223\n",
      "- - - - - >Iteration:  61 ----->Partial loss: 0.0513018\n",
      "- - - - - >Iteration:  62 ----->Partial loss: 0.222541\n",
      "- - - - - >Iteration:  63 ----->Partial loss: 0.0394849\n",
      "- - - - - >Iteration:  64 ----->Partial loss: 0.0190332\n",
      "- - - - - >Iteration:  65 ----->Partial loss: 0.0922703\n",
      "- - - - - >Iteration:  66 ----->Partial loss: 0.0350583\n",
      "- - - - - >Iteration:  67 ----->Partial loss: 0.10022\n",
      "- - - - - >Iteration:  68 ----->Partial loss: 0.0672486\n",
      "- - - - - >Iteration:  69 ----->Partial loss: 0.422048\n",
      "- - - - - >Iteration:  70 ----->Partial loss: 0.0428506\n",
      "- - - - - >Iteration:  71 ----->Partial loss: 0.0724252\n",
      "- - - - - >Iteration:  72 ----->Partial loss: 0.0894903\n",
      "- - - - - >Iteration:  73 ----->Partial loss: 0.0379104\n",
      "- - - - - >Iteration:  74 ----->Partial loss: 0.132205\n",
      "- - - - - >Iteration:  75 ----->Partial loss: 0.134053\n",
      "- - - - - >Iteration:  76 ----->Partial loss: 0.0367554\n",
      "- - - - - >Iteration:  77 ----->Partial loss: 0.0991093\n",
      "- - - - - >Iteration:  78 ----->Partial loss: 0.0844186\n",
      "- - - - - >Iteration:  79 ----->Partial loss: 0.0966364\n",
      "- - - - - >Iteration:  80 ----->Partial loss: 0.0790826\n",
      "- - - - - >Iteration:  81 ----->Partial loss: 0.0848297\n",
      "- - - - - >Iteration:  82 ----->Partial loss: 0.110124\n",
      "- - - - - >Iteration:  83 ----->Partial loss: 0.0912155\n",
      "- - - - - >Iteration:  84 ----->Partial loss: 0.0734139\n",
      "- - - - - >Iteration:  85 ----->Partial loss: 0.0328669\n",
      "- - - - - >Iteration:  86 ----->Partial loss: 0.0983327\n",
      "- - - - - >Iteration:  87 ----->Partial loss: 0.0604321\n",
      "- - - - - >Iteration:  88 ----->Partial loss: 0.0675944\n",
      "- - - - - >Iteration:  89 ----->Partial loss: 0.104065\n",
      "- - - - - >Iteration:  90 ----->Partial loss: 0.032251\n",
      "- - - - - >Iteration:  91 ----->Partial loss: 0.0908515\n",
      "- - - - - >Iteration:  92 ----->Partial loss: 0.0720291\n",
      "- - - - - >Iteration:  93 ----->Partial loss: 0.0912258\n",
      "- - - - - >Iteration:  94 ----->Partial loss: 0.0631617\n",
      "- - - - - >Iteration:  95 ----->Partial loss: 0.0353196\n",
      "- - - - - >Iteration:  96 ----->Partial loss: 0.0742311\n",
      "- - - - - >Iteration:  97 ----->Partial loss: 0.0730804\n",
      "- - - - - >Iteration:  98 ----->Partial loss: 0.0346627\n",
      "- - - - - >Iteration:  99 ----->Partial loss: 0.0771051\n",
      "- - - - - >Iteration:  100 ----->Partial loss: 0.159727\n",
      "- - - - - >Iteration:  101 ----->Partial loss: 0.0611474\n",
      "- - - - - >Iteration:  102 ----->Partial loss: 0.20971\n",
      "- - - - - >Iteration:  103 ----->Partial loss: 0.103334\n",
      "- - - - - >Iteration:  104 ----->Partial loss: 0.0509361\n",
      "- - - - - >Iteration:  105 ----->Partial loss: 0.185005\n",
      "- - - - - >Iteration:  106 ----->Partial loss: 0.0658314\n",
      "- - - - - >Iteration:  107 ----->Partial loss: 0.0529895\n",
      "- - - - - >Iteration:  108 ----->Partial loss: 0.0443855\n",
      "- - - - - >Iteration:  109 ----->Partial loss: 0.047015\n",
      "- - - - - >Iteration:  110 ----->Partial loss: 0.0521897\n",
      "- - - - - >Iteration:  111 ----->Partial loss: 0.0835735\n",
      "- - - - - >Iteration:  112 ----->Partial loss: 0.0411748\n",
      "- - - - - >Iteration:  113 ----->Partial loss: 0.0531064\n",
      "- - - - - >Iteration:  114 ----->Partial loss: 0.0464378\n",
      "- - - - - >Iteration:  115 ----->Partial loss: 0.130256\n",
      "- - - - - >Iteration:  116 ----->Partial loss: 0.10207\n",
      "- - - - - >Iteration:  117 ----->Partial loss: 0.0541172\n",
      "- - - - - >Iteration:  118 ----->Partial loss: 0.0289362\n",
      "- - - - - >Iteration:  119 ----->Partial loss: 0.0577414\n",
      "- - - - - >Iteration:  120 ----->Partial loss: 0.0540564\n",
      "- - - - - >Iteration:  121 ----->Partial loss: 0.144642\n",
      "- - - - - >Iteration:  122 ----->Partial loss: 0.0420222\n",
      "- - - - - >Iteration:  123 ----->Partial loss: 0.0244539\n",
      "- - - - - >Iteration:  124 ----->Partial loss: 0.0492614\n",
      "- - - - - >Iteration:  125 ----->Partial loss: 0.0413672\n",
      "- - - - - >Iteration:  126 ----->Partial loss: 0.0979574\n",
      "- - - - - >Iteration:  127 ----->Partial loss: 0.0607702\n",
      "- - - - - >Iteration:  128 ----->Partial loss: 0.0391385\n",
      "- - - - - >Iteration:  129 ----->Partial loss: 0.123664\n",
      "- - - - - >Iteration:  130 ----->Partial loss: 0.076209\n",
      "- - - - - >Iteration:  131 ----->Partial loss: 0.0764645\n",
      "- - - - - >Iteration:  132 ----->Partial loss: 0.050804\n",
      "- - - - - >Iteration:  133 ----->Partial loss: 0.0627268\n",
      "- - - - - >Iteration:  134 ----->Partial loss: 0.100638\n",
      "- - - - - >Iteration:  135 ----->Partial loss: 0.0546167\n",
      "- - - - - >Iteration:  136 ----->Partial loss: 0.0638276\n",
      "- - - - - >Iteration:  137 ----->Partial loss: 0.0698912\n",
      "- - - - - >Iteration:  138 ----->Partial loss: 0.0306259\n",
      "- - - - - >Iteration:  139 ----->Partial loss: 0.0359656\n",
      "- - - - - >Iteration:  140 ----->Partial loss: 0.0762143\n",
      "- - - - - >Iteration:  141 ----->Partial loss: 0.053365\n",
      "- - - - - >Iteration:  142 ----->Partial loss: 0.027196\n",
      "- - - - - >Iteration:  143 ----->Partial loss: 0.0979402\n",
      "- - - - - >Iteration:  144 ----->Partial loss: 0.0507001\n",
      "- - - - - >Iteration:  145 ----->Partial loss: 0.0725957\n",
      "- - - - - >Iteration:  146 ----->Partial loss: 0.133438\n",
      "- - - - - >Iteration:  147 ----->Partial loss: 0.0400278\n",
      "- - - - - >Iteration:  148 ----->Partial loss: 0.041174\n",
      "- - - - - >Iteration:  149 ----->Partial loss: 0.0747679\n",
      "- - - - - >Iteration:  150 ----->Partial loss: 0.101823\n",
      "- - - - - >Iteration:  151 ----->Partial loss: 0.0427226\n",
      "- - - - - >Iteration:  152 ----->Partial loss: 0.0752715\n",
      "- - - - - >Iteration:  153 ----->Partial loss: 0.0546566\n",
      "- - - - - >Iteration:  154 ----->Partial loss: 0.0261226\n",
      "- - - - - >Iteration:  155 ----->Partial loss: 0.0958314\n",
      "- - - - - >Iteration:  156 ----->Partial loss: 0.0812894\n",
      "- - - - - >Iteration:  157 ----->Partial loss: 0.0429638\n",
      "- - - - - >Iteration:  158 ----->Partial loss: 0.0418065\n",
      "- - - - - >Iteration:  159 ----->Partial loss: 0.175076\n",
      "- - - - - >Iteration:  160 ----->Partial loss: 0.0554089\n",
      "- - - - - >Iteration:  161 ----->Partial loss: 0.0551525\n",
      "- - - - - >Iteration:  162 ----->Partial loss: 0.040451\n",
      "- - - - - >Iteration:  163 ----->Partial loss: 0.0604386\n",
      "- - - - - >Iteration:  164 ----->Partial loss: 0.055813\n",
      "- - - - - >Iteration:  165 ----->Partial loss: 0.0514827\n",
      "- - - - - >Iteration:  166 ----->Partial loss: 0.0363003\n",
      "- - - - - >Iteration:  167 ----->Partial loss: 0.0747251\n",
      "- - - - - >Iteration:  168 ----->Partial loss: 0.0554715\n",
      "- - - - - >Iteration:  169 ----->Partial loss: 0.0382852\n",
      "- - - - - >Iteration:  170 ----->Partial loss: 0.0549291\n",
      "- - - - - >Iteration:  171 ----->Partial loss: 0.0293435\n",
      "- - - - - >Iteration:  172 ----->Partial loss: 0.0469365\n",
      "- - - - - >Iteration:  173 ----->Partial loss: 0.0450049\n",
      "- - - - - >Iteration:  174 ----->Partial loss: 0.028934\n",
      "- - - - - >Iteration:  175 ----->Partial loss: 0.0739732\n",
      "- - - - - >Iteration:  176 ----->Partial loss: 0.0607493\n",
      "- - - - - >Iteration:  177 ----->Partial loss: 0.0586653\n",
      "- - - - - >Iteration:  178 ----->Partial loss: 0.0591578\n",
      "- - - - - >Iteration:  179 ----->Partial loss: 0.0595645\n",
      "- - - - - >Iteration:  180 ----->Partial loss: 0.0501686\n",
      "- - - - - >Iteration:  181 ----->Partial loss: 0.133244\n",
      "- - - - - >Iteration:  182 ----->Partial loss: 0.0682392\n",
      "- - - - - >Iteration:  183 ----->Partial loss: 0.0927351\n",
      "- - - - - >Iteration:  184 ----->Partial loss: 0.041\n",
      "- - - - - >Iteration:  185 ----->Partial loss: 0.0918778\n",
      "- - - - - >Iteration:  186 ----->Partial loss: 0.0654887\n",
      "- - - - - >Iteration:  187 ----->Partial loss: 0.0277186\n",
      "- - - - - >Iteration:  188 ----->Partial loss: 0.0250684\n",
      "- - - - - >Iteration:  189 ----->Partial loss: 0.0405945\n",
      "- - - - - >Iteration:  190 ----->Partial loss: 0.0694913\n",
      "- - - - - >Iteration:  191 ----->Partial loss: 0.0902191\n",
      "- - - - - >Iteration:  192 ----->Partial loss: 0.0254891\n",
      "- - - - - >Iteration:  193 ----->Partial loss: 0.0784104\n",
      "- - - - - >Iteration:  194 ----->Partial loss: 0.0489072\n",
      "- - - - - >Iteration:  195 ----->Partial loss: 0.089\n",
      "- - - - - >Iteration:  196 ----->Partial loss: 0.070517\n",
      "- - - - - >Iteration:  197 ----->Partial loss: 0.0707008\n",
      "- - - - - >Iteration:  198 ----->Partial loss: 0.0577791\n",
      "- - - - - >Iteration:  199 ----->Partial loss: 0.0562833\n",
      "- - - - - >Iteration:  200 ----->Partial loss: 0.0548667\n",
      "- - - - - >Iteration:  201 ----->Partial loss: 0.0945832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- - - - - >Iteration:  202 ----->Partial loss: 0.0602559\n",
      "- - - - - >Iteration:  203 ----->Partial loss: 0.165062\n",
      "- - - - - >Iteration:  204 ----->Partial loss: 0.0299013\n",
      "- - - - - >Iteration:  205 ----->Partial loss: 0.0898617\n",
      "- - - - - >Iteration:  206 ----->Partial loss: 0.0342086\n",
      "- - - - - >Iteration:  207 ----->Partial loss: 0.0275766\n",
      "- - - - - >Iteration:  208 ----->Partial loss: 0.0567162\n",
      "- - - - - >Iteration:  209 ----->Partial loss: 0.0763726\n",
      "- - - - - >Iteration:  210 ----->Partial loss: 0.0735658\n",
      "- - - - - >Iteration:  211 ----->Partial loss: 0.0893281\n",
      "- - - - - >Iteration:  212 ----->Partial loss: 0.0542501\n",
      "- - - - - >Iteration:  213 ----->Partial loss: 0.0501441\n",
      "- - - - - >Iteration:  214 ----->Partial loss: 0.0749265\n",
      "- - - - - >Iteration:  215 ----->Partial loss: 0.0559242\n",
      "- - - - - >Iteration:  216 ----->Partial loss: 0.0310281\n",
      "- - - - - >Iteration:  217 ----->Partial loss: 0.0247962\n",
      "- - - - - >Iteration:  218 ----->Partial loss: 0.143315\n",
      "- - - - - >Iteration:  219 ----->Partial loss: 0.064256\n",
      "- - - - - >Iteration:  220 ----->Partial loss: 0.0295436\n",
      "- - - - - >Iteration:  221 ----->Partial loss: 0.0538973\n",
      "- - - - - >Iteration:  222 ----->Partial loss: 0.0239223\n",
      "- - - - - >Iteration:  223 ----->Partial loss: 0.113405\n",
      "- - - - - >Iteration:  224 ----->Partial loss: 0.0755992\n",
      "- - - - - >Iteration:  225 ----->Partial loss: 0.0196072\n",
      "- - - - - >Iteration:  226 ----->Partial loss: 0.0537171\n",
      "- - - - - >Iteration:  227 ----->Partial loss: 0.0354157\n",
      "- - - - - >Iteration:  228 ----->Partial loss: 0.118988\n",
      "- - - - - >Iteration:  229 ----->Partial loss: 0.108468\n",
      "- - - - - >Iteration:  230 ----->Partial loss: 0.0402727\n",
      "- - - - - >Iteration:  231 ----->Partial loss: 0.0575962\n",
      "- - - - - >Iteration:  232 ----->Partial loss: 0.0295123\n",
      "- - - - - >Iteration:  233 ----->Partial loss: 0.0712863\n",
      "- - - - - >Iteration:  234 ----->Partial loss: 0.0503184\n",
      "- - - - - >Iteration:  235 ----->Partial loss: 0.0455788\n",
      "- - - - - >Iteration:  236 ----->Partial loss: 0.0346855\n",
      "- - - - - >Iteration:  237 ----->Partial loss: 0.0672963\n",
      "- - - - - >Iteration:  238 ----->Partial loss: 0.044794\n",
      "- - - - - >Iteration:  239 ----->Partial loss: 0.112279\n",
      "- - - - - >Iteration:  240 ----->Partial loss: 0.035273\n",
      "- - - - - >Iteration:  241 ----->Partial loss: 0.0282721\n",
      "- - - - - >Iteration:  242 ----->Partial loss: 0.0280209\n",
      "- - - - - >Iteration:  243 ----->Partial loss: 0.0435946\n",
      "- - - - - >Iteration:  244 ----->Partial loss: 0.0293426\n",
      "- - - - - >Iteration:  245 ----->Partial loss: 0.121133\n",
      "- - - - - >Iteration:  246 ----->Partial loss: 0.0541413\n",
      "- - - - - >Iteration:  247 ----->Partial loss: 0.0517497\n",
      "- - - - - >Iteration:  248 ----->Partial loss: 0.0695049\n",
      "- - - - - >Iteration:  249 ----->Partial loss: 0.0558898\n",
      "- - - - - >Iteration:  250 ----->Partial loss: 0.029301\n",
      "- - - - - >Iteration:  251 ----->Partial loss: 0.0588611\n",
      "- - - - - >Iteration:  252 ----->Partial loss: 0.0342001\n",
      "- - - - - >Iteration:  253 ----->Partial loss: 0.0721277\n",
      "- - - - - >Iteration:  254 ----->Partial loss: 0.0301374\n",
      "- - - - - >Iteration:  255 ----->Partial loss: 0.0260508\n",
      "- - - - - >Iteration:  256 ----->Partial loss: 0.0609755\n",
      "- - - - - >Iteration:  257 ----->Partial loss: 0.0425041\n",
      "- - - - - >Iteration:  258 ----->Partial loss: 0.0714369\n",
      "- - - - - >Iteration:  259 ----->Partial loss: 0.0385771\n",
      "- - - - - >Iteration:  260 ----->Partial loss: 0.0601624\n",
      "- - - - - >Iteration:  261 ----->Partial loss: 0.0334597\n",
      "- - - - - >Iteration:  262 ----->Partial loss: 0.123855\n",
      "- - - - - >Iteration:  263 ----->Partial loss: 0.0779613\n",
      "- - - - - >Iteration:  264 ----->Partial loss: 0.0374757\n",
      "- - - - - >Iteration:  265 ----->Partial loss: 0.0432328\n",
      "- - - - - >Iteration:  266 ----->Partial loss: 0.0383419\n",
      "- - - - - >Iteration:  267 ----->Partial loss: 0.07865\n",
      "- - - - - >Iteration:  268 ----->Partial loss: 0.0494998\n",
      "- - - - - >Iteration:  269 ----->Partial loss: 0.0469673\n",
      "- - - - - >Iteration:  270 ----->Partial loss: 0.0645792\n",
      "- - - - - >Iteration:  271 ----->Partial loss: 0.0482199\n",
      "- - - - - >Iteration:  272 ----->Partial loss: 0.0494812\n",
      "- - - - - >Iteration:  273 ----->Partial loss: 0.0604707\n",
      "- - - - - >Iteration:  274 ----->Partial loss: 0.0557812\n",
      "- - - - - >Iteration:  275 ----->Partial loss: 0.0766239\n",
      "- - - - - >Iteration:  276 ----->Partial loss: 0.073711\n",
      "- - - - - >Iteration:  277 ----->Partial loss: 0.0248115\n",
      "- - - - - >Iteration:  278 ----->Partial loss: 0.103173\n",
      "- - - - - >Iteration:  279 ----->Partial loss: 0.0459563\n",
      "- - - - - >Iteration:  280 ----->Partial loss: 0.0284333\n",
      "- - - - - >Iteration:  281 ----->Partial loss: 0.0458069\n",
      "- - - - - >Iteration:  282 ----->Partial loss: 0.0489946\n",
      "- - - - - >Iteration:  283 ----->Partial loss: 0.121202\n",
      "- - - - - >Iteration:  284 ----->Partial loss: 0.0811738\n",
      "- - - - - >Iteration:  285 ----->Partial loss: 0.0249499\n",
      "- - - - - >Iteration:  286 ----->Partial loss: 0.093748\n",
      "- - - - - >Iteration:  287 ----->Partial loss: 0.0698993\n",
      "- - - - - >Iteration:  288 ----->Partial loss: 0.0337297\n",
      "- - - - - >Iteration:  289 ----->Partial loss: 0.0752244\n",
      "***************\n",
      "Epoch:  15  of  20 training loss:  0.0669435703399\n",
      "***************\n",
      "- - - - - >Iteration:  1 ----->Partial loss: 0.086869\n",
      "- - - - - >Iteration:  2 ----->Partial loss: 0.0540077\n",
      "- - - - - >Iteration:  3 ----->Partial loss: 0.031418\n",
      "- - - - - >Iteration:  4 ----->Partial loss: 0.0344704\n",
      "- - - - - >Iteration:  5 ----->Partial loss: 0.0744783\n",
      "- - - - - >Iteration:  6 ----->Partial loss: 0.0400028\n",
      "- - - - - >Iteration:  7 ----->Partial loss: 0.0420088\n",
      "- - - - - >Iteration:  8 ----->Partial loss: 0.0315072\n",
      "- - - - - >Iteration:  9 ----->Partial loss: 0.129756\n",
      "- - - - - >Iteration:  10 ----->Partial loss: 0.0340712\n",
      "- - - - - >Iteration:  11 ----->Partial loss: 0.0498852\n",
      "- - - - - >Iteration:  12 ----->Partial loss: 0.0628453\n",
      "- - - - - >Iteration:  13 ----->Partial loss: 0.096192\n",
      "- - - - - >Iteration:  14 ----->Partial loss: 0.103193\n",
      "- - - - - >Iteration:  15 ----->Partial loss: 0.0200775\n",
      "- - - - - >Iteration:  16 ----->Partial loss: 0.0588815\n",
      "- - - - - >Iteration:  17 ----->Partial loss: 0.115296\n",
      "- - - - - >Iteration:  18 ----->Partial loss: 0.0744556\n",
      "- - - - - >Iteration:  19 ----->Partial loss: 0.0618625\n",
      "- - - - - >Iteration:  20 ----->Partial loss: 0.0782404\n",
      "- - - - - >Iteration:  21 ----->Partial loss: 0.0275494\n",
      "- - - - - >Iteration:  22 ----->Partial loss: 0.057464\n",
      "- - - - - >Iteration:  23 ----->Partial loss: 0.0458382\n",
      "- - - - - >Iteration:  24 ----->Partial loss: 0.0583767\n",
      "- - - - - >Iteration:  25 ----->Partial loss: 0.106961\n",
      "- - - - - >Iteration:  26 ----->Partial loss: 0.0842162\n",
      "- - - - - >Iteration:  27 ----->Partial loss: 0.0715415\n",
      "- - - - - >Iteration:  28 ----->Partial loss: 0.0380108\n",
      "- - - - - >Iteration:  29 ----->Partial loss: 0.0446941\n",
      "- - - - - >Iteration:  30 ----->Partial loss: 0.052153\n",
      "- - - - - >Iteration:  31 ----->Partial loss: 0.0376802\n",
      "- - - - - >Iteration:  32 ----->Partial loss: 0.0386323\n",
      "- - - - - >Iteration:  33 ----->Partial loss: 0.0525638\n",
      "- - - - - >Iteration:  34 ----->Partial loss: 0.0518518\n",
      "- - - - - >Iteration:  35 ----->Partial loss: 0.0378897\n",
      "- - - - - >Iteration:  36 ----->Partial loss: 0.0417265\n",
      "- - - - - >Iteration:  37 ----->Partial loss: 0.0950417\n",
      "- - - - - >Iteration:  38 ----->Partial loss: 0.0235426\n",
      "- - - - - >Iteration:  39 ----->Partial loss: 0.0854854\n",
      "- - - - - >Iteration:  40 ----->Partial loss: 0.0364129\n",
      "- - - - - >Iteration:  41 ----->Partial loss: 0.0425538\n",
      "- - - - - >Iteration:  42 ----->Partial loss: 0.0581906\n",
      "- - - - - >Iteration:  43 ----->Partial loss: 0.0850895\n",
      "- - - - - >Iteration:  44 ----->Partial loss: 0.0759432\n",
      "- - - - - >Iteration:  45 ----->Partial loss: 0.0289509\n",
      "- - - - - >Iteration:  46 ----->Partial loss: 0.0544724\n",
      "- - - - - >Iteration:  47 ----->Partial loss: 0.0235466\n",
      "- - - - - >Iteration:  48 ----->Partial loss: 0.0315883\n",
      "- - - - - >Iteration:  49 ----->Partial loss: 0.0854888\n",
      "- - - - - >Iteration:  50 ----->Partial loss: 0.0594314\n",
      "- - - - - >Iteration:  51 ----->Partial loss: 0.0309051\n",
      "- - - - - >Iteration:  52 ----->Partial loss: 0.0946218\n",
      "- - - - - >Iteration:  53 ----->Partial loss: 0.111061\n",
      "- - - - - >Iteration:  54 ----->Partial loss: 0.0369222\n",
      "- - - - - >Iteration:  55 ----->Partial loss: 0.033177\n",
      "- - - - - >Iteration:  56 ----->Partial loss: 0.0779846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- - - - - >Iteration:  57 ----->Partial loss: 0.0740976\n",
      "- - - - - >Iteration:  58 ----->Partial loss: 0.0522282\n",
      "- - - - - >Iteration:  59 ----->Partial loss: 0.058247\n",
      "- - - - - >Iteration:  60 ----->Partial loss: 0.0729291\n",
      "- - - - - >Iteration:  61 ----->Partial loss: 0.0409946\n",
      "- - - - - >Iteration:  62 ----->Partial loss: 0.0472139\n",
      "- - - - - >Iteration:  63 ----->Partial loss: 0.0828183\n",
      "- - - - - >Iteration:  64 ----->Partial loss: 0.0258774\n",
      "- - - - - >Iteration:  65 ----->Partial loss: 0.026863\n",
      "- - - - - >Iteration:  66 ----->Partial loss: 0.0400247\n",
      "- - - - - >Iteration:  67 ----->Partial loss: 0.0772278\n",
      "- - - - - >Iteration:  68 ----->Partial loss: 0.0371286\n",
      "- - - - - >Iteration:  69 ----->Partial loss: 0.0602107\n",
      "- - - - - >Iteration:  70 ----->Partial loss: 0.0785193\n",
      "- - - - - >Iteration:  71 ----->Partial loss: 0.0677267\n",
      "- - - - - >Iteration:  72 ----->Partial loss: 0.052104\n",
      "- - - - - >Iteration:  73 ----->Partial loss: 0.0635927\n",
      "- - - - - >Iteration:  74 ----->Partial loss: 0.0283985\n",
      "- - - - - >Iteration:  75 ----->Partial loss: 0.0496277\n",
      "- - - - - >Iteration:  76 ----->Partial loss: 0.0549913\n",
      "- - - - - >Iteration:  77 ----->Partial loss: 0.0621158\n",
      "- - - - - >Iteration:  78 ----->Partial loss: 0.0520752\n",
      "- - - - - >Iteration:  79 ----->Partial loss: 0.0383983\n",
      "- - - - - >Iteration:  80 ----->Partial loss: 0.0922114\n",
      "- - - - - >Iteration:  81 ----->Partial loss: 0.0586444\n",
      "- - - - - >Iteration:  82 ----->Partial loss: 0.0230578\n",
      "- - - - - >Iteration:  83 ----->Partial loss: 0.0745583\n",
      "- - - - - >Iteration:  84 ----->Partial loss: 0.0786272\n",
      "- - - - - >Iteration:  85 ----->Partial loss: 0.0539857\n",
      "- - - - - >Iteration:  86 ----->Partial loss: 0.0582325\n",
      "- - - - - >Iteration:  87 ----->Partial loss: 0.0463647\n",
      "- - - - - >Iteration:  88 ----->Partial loss: 0.0507597\n",
      "- - - - - >Iteration:  89 ----->Partial loss: 0.0997668\n",
      "- - - - - >Iteration:  90 ----->Partial loss: 0.0749615\n",
      "- - - - - >Iteration:  91 ----->Partial loss: 0.0810358\n",
      "- - - - - >Iteration:  92 ----->Partial loss: 0.0353024\n",
      "- - - - - >Iteration:  93 ----->Partial loss: 0.0314383\n",
      "- - - - - >Iteration:  94 ----->Partial loss: 0.0414659\n",
      "- - - - - >Iteration:  95 ----->Partial loss: 0.0359672\n",
      "- - - - - >Iteration:  96 ----->Partial loss: 0.0519131\n",
      "- - - - - >Iteration:  97 ----->Partial loss: 0.0791705\n",
      "- - - - - >Iteration:  98 ----->Partial loss: 0.0379744\n",
      "- - - - - >Iteration:  99 ----->Partial loss: 0.0163651\n",
      "- - - - - >Iteration:  100 ----->Partial loss: 0.024553\n",
      "- - - - - >Iteration:  101 ----->Partial loss: 0.067426\n",
      "- - - - - >Iteration:  102 ----->Partial loss: 0.0451251\n",
      "- - - - - >Iteration:  103 ----->Partial loss: 0.0767468\n",
      "- - - - - >Iteration:  104 ----->Partial loss: 0.0790132\n",
      "- - - - - >Iteration:  105 ----->Partial loss: 0.038374\n",
      "- - - - - >Iteration:  106 ----->Partial loss: 0.02718\n",
      "- - - - - >Iteration:  107 ----->Partial loss: 0.0347043\n",
      "- - - - - >Iteration:  108 ----->Partial loss: 0.0654316\n",
      "- - - - - >Iteration:  109 ----->Partial loss: 0.0488647\n",
      "- - - - - >Iteration:  110 ----->Partial loss: 0.0459314\n",
      "- - - - - >Iteration:  111 ----->Partial loss: 0.0262529\n",
      "- - - - - >Iteration:  112 ----->Partial loss: 0.054912\n",
      "- - - - - >Iteration:  113 ----->Partial loss: 0.0285789\n",
      "- - - - - >Iteration:  114 ----->Partial loss: 0.0484146\n",
      "- - - - - >Iteration:  115 ----->Partial loss: 0.053739\n",
      "- - - - - >Iteration:  116 ----->Partial loss: 0.0709281\n",
      "- - - - - >Iteration:  117 ----->Partial loss: 0.0977651\n",
      "- - - - - >Iteration:  118 ----->Partial loss: 0.0305273\n",
      "- - - - - >Iteration:  119 ----->Partial loss: 0.0416564\n",
      "- - - - - >Iteration:  120 ----->Partial loss: 0.0489141\n",
      "- - - - - >Iteration:  121 ----->Partial loss: 0.10138\n",
      "- - - - - >Iteration:  122 ----->Partial loss: 0.0234939\n",
      "- - - - - >Iteration:  123 ----->Partial loss: 0.0223084\n",
      "- - - - - >Iteration:  124 ----->Partial loss: 0.0515944\n",
      "- - - - - >Iteration:  125 ----->Partial loss: 0.061677\n",
      "- - - - - >Iteration:  126 ----->Partial loss: 0.0244338\n",
      "- - - - - >Iteration:  127 ----->Partial loss: 0.0497343\n",
      "- - - - - >Iteration:  128 ----->Partial loss: 0.0383014\n",
      "- - - - - >Iteration:  129 ----->Partial loss: 0.056135\n",
      "- - - - - >Iteration:  130 ----->Partial loss: 0.0815531\n",
      "- - - - - >Iteration:  131 ----->Partial loss: 0.171922\n",
      "- - - - - >Iteration:  132 ----->Partial loss: 0.0637031\n",
      "- - - - - >Iteration:  133 ----->Partial loss: 0.045142\n",
      "- - - - - >Iteration:  134 ----->Partial loss: 0.0778955\n",
      "- - - - - >Iteration:  135 ----->Partial loss: 0.0840667\n",
      "- - - - - >Iteration:  136 ----->Partial loss: 0.0546918\n",
      "- - - - - >Iteration:  137 ----->Partial loss: 0.0714559\n",
      "- - - - - >Iteration:  138 ----->Partial loss: 0.0546547\n",
      "- - - - - >Iteration:  139 ----->Partial loss: 0.124583\n",
      "- - - - - >Iteration:  140 ----->Partial loss: 0.0577584\n",
      "- - - - - >Iteration:  141 ----->Partial loss: 0.0995571\n",
      "- - - - - >Iteration:  142 ----->Partial loss: 0.0903407\n",
      "- - - - - >Iteration:  143 ----->Partial loss: 0.0350474\n",
      "- - - - - >Iteration:  144 ----->Partial loss: 0.0623191\n",
      "- - - - - >Iteration:  145 ----->Partial loss: 0.0572015\n",
      "- - - - - >Iteration:  146 ----->Partial loss: 0.0476264\n",
      "- - - - - >Iteration:  147 ----->Partial loss: 0.0369708\n",
      "- - - - - >Iteration:  148 ----->Partial loss: 0.0891983\n",
      "- - - - - >Iteration:  149 ----->Partial loss: 0.0608465\n",
      "- - - - - >Iteration:  150 ----->Partial loss: 0.062746\n",
      "- - - - - >Iteration:  151 ----->Partial loss: 0.0575874\n",
      "- - - - - >Iteration:  152 ----->Partial loss: 0.055778\n",
      "- - - - - >Iteration:  153 ----->Partial loss: 0.0190453\n",
      "- - - - - >Iteration:  154 ----->Partial loss: 0.0265251\n",
      "- - - - - >Iteration:  155 ----->Partial loss: 0.0532758\n",
      "- - - - - >Iteration:  156 ----->Partial loss: 0.0574287\n",
      "- - - - - >Iteration:  157 ----->Partial loss: 0.0552808\n",
      "- - - - - >Iteration:  158 ----->Partial loss: 0.0343406\n",
      "- - - - - >Iteration:  159 ----->Partial loss: 0.0484169\n",
      "- - - - - >Iteration:  160 ----->Partial loss: 0.0765368\n",
      "- - - - - >Iteration:  161 ----->Partial loss: 0.0249977\n",
      "- - - - - >Iteration:  162 ----->Partial loss: 0.0232375\n",
      "- - - - - >Iteration:  163 ----->Partial loss: 0.0979276\n",
      "- - - - - >Iteration:  164 ----->Partial loss: 0.0627258\n",
      "- - - - - >Iteration:  165 ----->Partial loss: 0.043793\n",
      "- - - - - >Iteration:  166 ----->Partial loss: 0.065798\n",
      "- - - - - >Iteration:  167 ----->Partial loss: 0.0549104\n",
      "- - - - - >Iteration:  168 ----->Partial loss: 0.0718429\n",
      "- - - - - >Iteration:  169 ----->Partial loss: 0.0524573\n",
      "- - - - - >Iteration:  170 ----->Partial loss: 0.0598097\n",
      "- - - - - >Iteration:  171 ----->Partial loss: 0.0404688\n",
      "- - - - - >Iteration:  172 ----->Partial loss: 0.0459748\n",
      "- - - - - >Iteration:  173 ----->Partial loss: 0.029805\n",
      "- - - - - >Iteration:  174 ----->Partial loss: 0.0275273\n",
      "- - - - - >Iteration:  175 ----->Partial loss: 0.0625201\n",
      "- - - - - >Iteration:  176 ----->Partial loss: 0.0333928\n",
      "- - - - - >Iteration:  177 ----->Partial loss: 0.0209809\n",
      "- - - - - >Iteration:  178 ----->Partial loss: 0.0261231\n",
      "- - - - - >Iteration:  179 ----->Partial loss: 0.0572732\n",
      "- - - - - >Iteration:  180 ----->Partial loss: 0.0333709\n",
      "- - - - - >Iteration:  181 ----->Partial loss: 0.231161\n",
      "- - - - - >Iteration:  182 ----->Partial loss: 0.05616\n",
      "- - - - - >Iteration:  183 ----->Partial loss: 0.0190052\n",
      "- - - - - >Iteration:  184 ----->Partial loss: 0.048367\n",
      "- - - - - >Iteration:  185 ----->Partial loss: 0.115299\n",
      "- - - - - >Iteration:  186 ----->Partial loss: 0.0647912\n",
      "- - - - - >Iteration:  187 ----->Partial loss: 0.12256\n",
      "- - - - - >Iteration:  188 ----->Partial loss: 0.0289064\n",
      "- - - - - >Iteration:  189 ----->Partial loss: 0.0622838\n",
      "- - - - - >Iteration:  190 ----->Partial loss: 0.0455366\n",
      "- - - - - >Iteration:  191 ----->Partial loss: 0.0703661\n",
      "- - - - - >Iteration:  192 ----->Partial loss: 0.0482588\n",
      "- - - - - >Iteration:  193 ----->Partial loss: 0.0325051\n",
      "- - - - - >Iteration:  194 ----->Partial loss: 0.047985\n",
      "- - - - - >Iteration:  195 ----->Partial loss: 0.089389\n",
      "- - - - - >Iteration:  196 ----->Partial loss: 0.0301591\n",
      "- - - - - >Iteration:  197 ----->Partial loss: 0.0522065\n",
      "- - - - - >Iteration:  198 ----->Partial loss: 0.026657\n",
      "- - - - - >Iteration:  199 ----->Partial loss: 0.182095\n",
      "- - - - - >Iteration:  200 ----->Partial loss: 0.0474565\n",
      "- - - - - >Iteration:  201 ----->Partial loss: 0.0327611\n",
      "- - - - - >Iteration:  202 ----->Partial loss: 0.129758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- - - - - >Iteration:  203 ----->Partial loss: 0.0969772\n",
      "- - - - - >Iteration:  204 ----->Partial loss: 0.0270183\n",
      "- - - - - >Iteration:  205 ----->Partial loss: 0.0688211\n",
      "- - - - - >Iteration:  206 ----->Partial loss: 0.0328581\n",
      "- - - - - >Iteration:  207 ----->Partial loss: 0.0504267\n",
      "- - - - - >Iteration:  208 ----->Partial loss: 0.0243248\n",
      "- - - - - >Iteration:  209 ----->Partial loss: 0.0661094\n",
      "- - - - - >Iteration:  210 ----->Partial loss: 0.0256104\n",
      "- - - - - >Iteration:  211 ----->Partial loss: 0.0466877\n",
      "- - - - - >Iteration:  212 ----->Partial loss: 0.0256705\n",
      "- - - - - >Iteration:  213 ----->Partial loss: 0.0693844\n",
      "- - - - - >Iteration:  214 ----->Partial loss: 0.0765749\n",
      "- - - - - >Iteration:  215 ----->Partial loss: 0.064488\n",
      "- - - - - >Iteration:  216 ----->Partial loss: 0.0441181\n",
      "- - - - - >Iteration:  217 ----->Partial loss: 0.0513535\n",
      "- - - - - >Iteration:  218 ----->Partial loss: 0.137191\n",
      "- - - - - >Iteration:  219 ----->Partial loss: 0.087429\n",
      "- - - - - >Iteration:  220 ----->Partial loss: 0.0722113\n",
      "- - - - - >Iteration:  221 ----->Partial loss: 0.0873863\n",
      "- - - - - >Iteration:  222 ----->Partial loss: 0.0588091\n",
      "- - - - - >Iteration:  223 ----->Partial loss: 0.0695749\n",
      "- - - - - >Iteration:  224 ----->Partial loss: 0.084086\n",
      "- - - - - >Iteration:  225 ----->Partial loss: 0.0315376\n",
      "- - - - - >Iteration:  226 ----->Partial loss: 0.073859\n",
      "- - - - - >Iteration:  227 ----->Partial loss: 0.0255783\n",
      "- - - - - >Iteration:  228 ----->Partial loss: 0.0447987\n",
      "- - - - - >Iteration:  229 ----->Partial loss: 0.0482176\n",
      "- - - - - >Iteration:  230 ----->Partial loss: 0.0394033\n",
      "- - - - - >Iteration:  231 ----->Partial loss: 0.0466932\n",
      "- - - - - >Iteration:  232 ----->Partial loss: 0.0377246\n",
      "- - - - - >Iteration:  233 ----->Partial loss: 0.0239622\n",
      "- - - - - >Iteration:  234 ----->Partial loss: 0.026565\n",
      "- - - - - >Iteration:  235 ----->Partial loss: 0.0383124\n",
      "- - - - - >Iteration:  236 ----->Partial loss: 0.0446293\n",
      "- - - - - >Iteration:  237 ----->Partial loss: 0.0641793\n",
      "- - - - - >Iteration:  238 ----->Partial loss: 0.0773943\n",
      "- - - - - >Iteration:  239 ----->Partial loss: 0.0802868\n",
      "- - - - - >Iteration:  240 ----->Partial loss: 0.0615002\n",
      "- - - - - >Iteration:  241 ----->Partial loss: 0.0274014\n",
      "- - - - - >Iteration:  242 ----->Partial loss: 0.205523\n",
      "- - - - - >Iteration:  243 ----->Partial loss: 0.11071\n",
      "- - - - - >Iteration:  244 ----->Partial loss: 0.0230578\n",
      "- - - - - >Iteration:  245 ----->Partial loss: 0.0653052\n",
      "- - - - - >Iteration:  246 ----->Partial loss: 0.0345899\n",
      "- - - - - >Iteration:  247 ----->Partial loss: 0.0552559\n",
      "- - - - - >Iteration:  248 ----->Partial loss: 0.0377214\n",
      "- - - - - >Iteration:  249 ----->Partial loss: 0.0431577\n",
      "- - - - - >Iteration:  250 ----->Partial loss: 0.0548455\n",
      "- - - - - >Iteration:  251 ----->Partial loss: 0.0276675\n",
      "- - - - - >Iteration:  252 ----->Partial loss: 0.0494464\n",
      "- - - - - >Iteration:  253 ----->Partial loss: 0.0425038\n",
      "- - - - - >Iteration:  254 ----->Partial loss: 0.0750854\n",
      "- - - - - >Iteration:  255 ----->Partial loss: 0.0244407\n",
      "- - - - - >Iteration:  256 ----->Partial loss: 0.0810885\n",
      "- - - - - >Iteration:  257 ----->Partial loss: 0.0444305\n",
      "- - - - - >Iteration:  258 ----->Partial loss: 0.0441598\n",
      "- - - - - >Iteration:  259 ----->Partial loss: 0.0844172\n",
      "- - - - - >Iteration:  260 ----->Partial loss: 0.0521092\n",
      "- - - - - >Iteration:  261 ----->Partial loss: 0.0350953\n",
      "- - - - - >Iteration:  262 ----->Partial loss: 0.0580699\n",
      "- - - - - >Iteration:  263 ----->Partial loss: 0.0666494\n",
      "- - - - - >Iteration:  264 ----->Partial loss: 0.0507226\n",
      "- - - - - >Iteration:  265 ----->Partial loss: 0.028769\n",
      "- - - - - >Iteration:  266 ----->Partial loss: 0.0730001\n",
      "- - - - - >Iteration:  267 ----->Partial loss: 0.0829672\n",
      "- - - - - >Iteration:  268 ----->Partial loss: 0.0732881\n",
      "- - - - - >Iteration:  269 ----->Partial loss: 0.0568451\n",
      "- - - - - >Iteration:  270 ----->Partial loss: 0.0432764\n",
      "- - - - - >Iteration:  271 ----->Partial loss: 0.0328478\n",
      "- - - - - >Iteration:  272 ----->Partial loss: 0.0469041\n",
      "- - - - - >Iteration:  273 ----->Partial loss: 0.0280302\n",
      "- - - - - >Iteration:  274 ----->Partial loss: 0.0398979\n",
      "- - - - - >Iteration:  275 ----->Partial loss: 0.0303902\n",
      "- - - - - >Iteration:  276 ----->Partial loss: 0.0242663\n",
      "- - - - - >Iteration:  277 ----->Partial loss: 0.0211049\n",
      "- - - - - >Iteration:  278 ----->Partial loss: 0.0640309\n",
      "- - - - - >Iteration:  279 ----->Partial loss: 0.0303816\n",
      "- - - - - >Iteration:  280 ----->Partial loss: 0.0218138\n",
      "- - - - - >Iteration:  281 ----->Partial loss: 0.048294\n",
      "- - - - - >Iteration:  282 ----->Partial loss: 0.0784157\n",
      "- - - - - >Iteration:  283 ----->Partial loss: 0.119818\n",
      "- - - - - >Iteration:  284 ----->Partial loss: 0.0191626\n",
      "- - - - - >Iteration:  285 ----->Partial loss: 0.318174\n",
      "- - - - - >Iteration:  286 ----->Partial loss: 0.0341265\n",
      "- - - - - >Iteration:  287 ----->Partial loss: 0.0223818\n",
      "- - - - - >Iteration:  288 ----->Partial loss: 0.188931\n",
      "- - - - - >Iteration:  289 ----->Partial loss: 0.0667629\n",
      "***************\n",
      "Epoch:  16  of  20 training loss:  0.0581230977969\n",
      "***************\n",
      "- - - - - >Iteration:  1 ----->Partial loss: 0.137972\n",
      "- - - - - >Iteration:  2 ----->Partial loss: 0.0410883\n",
      "- - - - - >Iteration:  3 ----->Partial loss: 0.0630552\n",
      "- - - - - >Iteration:  4 ----->Partial loss: 0.0323497\n",
      "- - - - - >Iteration:  5 ----->Partial loss: 0.0754218\n",
      "- - - - - >Iteration:  6 ----->Partial loss: 0.0722684\n",
      "- - - - - >Iteration:  7 ----->Partial loss: 0.068889\n",
      "- - - - - >Iteration:  8 ----->Partial loss: 0.0358716\n",
      "- - - - - >Iteration:  9 ----->Partial loss: 0.0432376\n",
      "- - - - - >Iteration:  10 ----->Partial loss: 0.10886\n",
      "- - - - - >Iteration:  11 ----->Partial loss: 0.0728384\n",
      "- - - - - >Iteration:  12 ----->Partial loss: 0.0949803\n",
      "- - - - - >Iteration:  13 ----->Partial loss: 0.061712\n",
      "- - - - - >Iteration:  14 ----->Partial loss: 0.0267358\n",
      "- - - - - >Iteration:  15 ----->Partial loss: 0.039604\n",
      "- - - - - >Iteration:  16 ----->Partial loss: 0.0239074\n",
      "- - - - - >Iteration:  17 ----->Partial loss: 0.0225832\n",
      "- - - - - >Iteration:  18 ----->Partial loss: 0.0434253\n",
      "- - - - - >Iteration:  19 ----->Partial loss: 0.185011\n",
      "- - - - - >Iteration:  20 ----->Partial loss: 0.0648146\n",
      "- - - - - >Iteration:  21 ----->Partial loss: 0.056737\n",
      "- - - - - >Iteration:  22 ----->Partial loss: 0.0232039\n",
      "- - - - - >Iteration:  23 ----->Partial loss: 0.0425002\n",
      "- - - - - >Iteration:  24 ----->Partial loss: 0.0575052\n",
      "- - - - - >Iteration:  25 ----->Partial loss: 0.0262868\n",
      "- - - - - >Iteration:  26 ----->Partial loss: 0.0520949\n",
      "- - - - - >Iteration:  27 ----->Partial loss: 0.0696168\n",
      "- - - - - >Iteration:  28 ----->Partial loss: 0.0260873\n",
      "- - - - - >Iteration:  29 ----->Partial loss: 0.0600216\n",
      "- - - - - >Iteration:  30 ----->Partial loss: 0.0718076\n",
      "- - - - - >Iteration:  31 ----->Partial loss: 0.107196\n",
      "- - - - - >Iteration:  32 ----->Partial loss: 0.0332268\n",
      "- - - - - >Iteration:  33 ----->Partial loss: 0.0284818\n",
      "- - - - - >Iteration:  34 ----->Partial loss: 0.0784053\n",
      "- - - - - >Iteration:  35 ----->Partial loss: 0.0636467\n",
      "- - - - - >Iteration:  36 ----->Partial loss: 0.035901\n",
      "- - - - - >Iteration:  37 ----->Partial loss: 0.0374617\n",
      "- - - - - >Iteration:  38 ----->Partial loss: 0.0281144\n",
      "- - - - - >Iteration:  39 ----->Partial loss: 0.0750158\n",
      "- - - - - >Iteration:  40 ----->Partial loss: 0.0361445\n",
      "- - - - - >Iteration:  41 ----->Partial loss: 0.043097\n",
      "- - - - - >Iteration:  42 ----->Partial loss: 0.0498495\n",
      "- - - - - >Iteration:  43 ----->Partial loss: 0.0261182\n",
      "- - - - - >Iteration:  44 ----->Partial loss: 0.0435399\n",
      "- - - - - >Iteration:  45 ----->Partial loss: 0.0172748\n",
      "- - - - - >Iteration:  46 ----->Partial loss: 0.0270351\n",
      "- - - - - >Iteration:  47 ----->Partial loss: 0.0475836\n",
      "- - - - - >Iteration:  48 ----->Partial loss: 0.0675948\n",
      "- - - - - >Iteration:  49 ----->Partial loss: 0.0531254\n",
      "- - - - - >Iteration:  50 ----->Partial loss: 0.0356478\n",
      "- - - - - >Iteration:  51 ----->Partial loss: 0.0625251\n",
      "- - - - - >Iteration:  52 ----->Partial loss: 0.0337287\n",
      "- - - - - >Iteration:  53 ----->Partial loss: 0.0549641\n",
      "- - - - - >Iteration:  54 ----->Partial loss: 0.0445619\n",
      "- - - - - >Iteration:  55 ----->Partial loss: 0.084505\n",
      "- - - - - >Iteration:  56 ----->Partial loss: 0.0402407\n",
      "- - - - - >Iteration:  57 ----->Partial loss: 0.0658479\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- - - - - >Iteration:  58 ----->Partial loss: 0.0616782\n",
      "- - - - - >Iteration:  59 ----->Partial loss: 0.0295882\n",
      "- - - - - >Iteration:  60 ----->Partial loss: 0.0906742\n",
      "- - - - - >Iteration:  61 ----->Partial loss: 0.0387975\n",
      "- - - - - >Iteration:  62 ----->Partial loss: 0.0212835\n",
      "- - - - - >Iteration:  63 ----->Partial loss: 0.0283473\n",
      "- - - - - >Iteration:  64 ----->Partial loss: 0.0213135\n",
      "- - - - - >Iteration:  65 ----->Partial loss: 0.0330413\n",
      "- - - - - >Iteration:  66 ----->Partial loss: 0.0418594\n",
      "- - - - - >Iteration:  67 ----->Partial loss: 0.0288989\n",
      "- - - - - >Iteration:  68 ----->Partial loss: 0.0799608\n",
      "- - - - - >Iteration:  69 ----->Partial loss: 0.0972999\n",
      "- - - - - >Iteration:  70 ----->Partial loss: 0.0549197\n",
      "- - - - - >Iteration:  71 ----->Partial loss: 0.0735976\n",
      "- - - - - >Iteration:  72 ----->Partial loss: 0.124713\n",
      "- - - - - >Iteration:  73 ----->Partial loss: 0.0799902\n",
      "- - - - - >Iteration:  74 ----->Partial loss: 0.0368897\n",
      "- - - - - >Iteration:  75 ----->Partial loss: 0.0284235\n",
      "- - - - - >Iteration:  76 ----->Partial loss: 0.0504165\n",
      "- - - - - >Iteration:  77 ----->Partial loss: 0.0506673\n",
      "- - - - - >Iteration:  78 ----->Partial loss: 0.0220877\n",
      "- - - - - >Iteration:  79 ----->Partial loss: 0.0647212\n",
      "- - - - - >Iteration:  80 ----->Partial loss: 0.0767204\n",
      "- - - - - >Iteration:  81 ----->Partial loss: 0.100638\n",
      "- - - - - >Iteration:  82 ----->Partial loss: 0.0398124\n",
      "- - - - - >Iteration:  83 ----->Partial loss: 0.0826933\n",
      "- - - - - >Iteration:  84 ----->Partial loss: 0.0481865\n",
      "- - - - - >Iteration:  85 ----->Partial loss: 0.0763404\n",
      "- - - - - >Iteration:  86 ----->Partial loss: 0.0443052\n",
      "- - - - - >Iteration:  87 ----->Partial loss: 0.0426814\n",
      "- - - - - >Iteration:  88 ----->Partial loss: 0.0251977\n",
      "- - - - - >Iteration:  89 ----->Partial loss: 0.0631903\n",
      "- - - - - >Iteration:  90 ----->Partial loss: 0.0665854\n",
      "- - - - - >Iteration:  91 ----->Partial loss: 0.0588988\n",
      "- - - - - >Iteration:  92 ----->Partial loss: 0.0267668\n",
      "- - - - - >Iteration:  93 ----->Partial loss: 0.0749746\n",
      "- - - - - >Iteration:  94 ----->Partial loss: 0.0531164\n",
      "- - - - - >Iteration:  95 ----->Partial loss: 0.0578089\n",
      "- - - - - >Iteration:  96 ----->Partial loss: 0.0370101\n",
      "- - - - - >Iteration:  97 ----->Partial loss: 0.139079\n",
      "- - - - - >Iteration:  98 ----->Partial loss: 0.0609858\n",
      "- - - - - >Iteration:  99 ----->Partial loss: 0.0356763\n",
      "- - - - - >Iteration:  100 ----->Partial loss: 0.0282448\n",
      "- - - - - >Iteration:  101 ----->Partial loss: 0.0497105\n",
      "- - - - - >Iteration:  102 ----->Partial loss: 0.0253501\n",
      "- - - - - >Iteration:  103 ----->Partial loss: 0.0781655\n",
      "- - - - - >Iteration:  104 ----->Partial loss: 0.0345204\n",
      "- - - - - >Iteration:  105 ----->Partial loss: 0.0356321\n",
      "- - - - - >Iteration:  106 ----->Partial loss: 0.038341\n",
      "- - - - - >Iteration:  107 ----->Partial loss: 0.0475535\n",
      "- - - - - >Iteration:  108 ----->Partial loss: 0.0378817\n",
      "- - - - - >Iteration:  109 ----->Partial loss: 0.0634657\n",
      "- - - - - >Iteration:  110 ----->Partial loss: 0.0211839\n",
      "- - - - - >Iteration:  111 ----->Partial loss: 0.0311583\n",
      "- - - - - >Iteration:  112 ----->Partial loss: 0.0295849\n",
      "- - - - - >Iteration:  113 ----->Partial loss: 0.0564696\n",
      "- - - - - >Iteration:  114 ----->Partial loss: 0.0310597\n",
      "- - - - - >Iteration:  115 ----->Partial loss: 0.0319885\n",
      "- - - - - >Iteration:  116 ----->Partial loss: 0.0604134\n",
      "- - - - - >Iteration:  117 ----->Partial loss: 0.0437257\n",
      "- - - - - >Iteration:  118 ----->Partial loss: 0.0756711\n",
      "- - - - - >Iteration:  119 ----->Partial loss: 0.0301136\n",
      "- - - - - >Iteration:  120 ----->Partial loss: 0.0411809\n",
      "- - - - - >Iteration:  121 ----->Partial loss: 0.0318441\n",
      "- - - - - >Iteration:  122 ----->Partial loss: 0.0411513\n",
      "- - - - - >Iteration:  123 ----->Partial loss: 0.0222785\n",
      "- - - - - >Iteration:  124 ----->Partial loss: 0.048929\n",
      "- - - - - >Iteration:  125 ----->Partial loss: 0.0834986\n",
      "- - - - - >Iteration:  126 ----->Partial loss: 0.0846801\n",
      "- - - - - >Iteration:  127 ----->Partial loss: 0.0554535\n",
      "- - - - - >Iteration:  128 ----->Partial loss: 0.0883375\n",
      "- - - - - >Iteration:  129 ----->Partial loss: 0.0184316\n",
      "- - - - - >Iteration:  130 ----->Partial loss: 0.0916096\n",
      "- - - - - >Iteration:  131 ----->Partial loss: 0.040753\n",
      "- - - - - >Iteration:  132 ----->Partial loss: 0.0404457\n",
      "- - - - - >Iteration:  133 ----->Partial loss: 0.0215135\n",
      "- - - - - >Iteration:  134 ----->Partial loss: 0.0518082\n",
      "- - - - - >Iteration:  135 ----->Partial loss: 0.05611\n",
      "- - - - - >Iteration:  136 ----->Partial loss: 0.0627607\n",
      "- - - - - >Iteration:  137 ----->Partial loss: 0.0623239\n",
      "- - - - - >Iteration:  138 ----->Partial loss: 0.0774598\n",
      "- - - - - >Iteration:  139 ----->Partial loss: 0.0882451\n",
      "- - - - - >Iteration:  140 ----->Partial loss: 0.0483846\n",
      "- - - - - >Iteration:  141 ----->Partial loss: 0.0727711\n",
      "- - - - - >Iteration:  142 ----->Partial loss: 0.178679\n",
      "- - - - - >Iteration:  143 ----->Partial loss: 0.0292873\n",
      "- - - - - >Iteration:  144 ----->Partial loss: 0.0470657\n",
      "- - - - - >Iteration:  145 ----->Partial loss: 0.0552088\n",
      "- - - - - >Iteration:  146 ----->Partial loss: 0.0177636\n",
      "- - - - - >Iteration:  147 ----->Partial loss: 0.0428087\n",
      "- - - - - >Iteration:  148 ----->Partial loss: 0.0359316\n",
      "- - - - - >Iteration:  149 ----->Partial loss: 0.0541192\n",
      "- - - - - >Iteration:  150 ----->Partial loss: 0.051176\n",
      "- - - - - >Iteration:  151 ----->Partial loss: 0.0471769\n",
      "- - - - - >Iteration:  152 ----->Partial loss: 0.0346242\n",
      "- - - - - >Iteration:  153 ----->Partial loss: 0.025738\n",
      "- - - - - >Iteration:  154 ----->Partial loss: 0.0252742\n",
      "- - - - - >Iteration:  155 ----->Partial loss: 0.0313207\n",
      "- - - - - >Iteration:  156 ----->Partial loss: 0.0487674\n",
      "- - - - - >Iteration:  157 ----->Partial loss: 0.101191\n",
      "- - - - - >Iteration:  158 ----->Partial loss: 0.0389619\n",
      "- - - - - >Iteration:  159 ----->Partial loss: 0.0457334\n",
      "- - - - - >Iteration:  160 ----->Partial loss: 0.0199302\n",
      "- - - - - >Iteration:  161 ----->Partial loss: 0.0735105\n",
      "- - - - - >Iteration:  162 ----->Partial loss: 0.0546524\n",
      "- - - - - >Iteration:  163 ----->Partial loss: 0.0364237\n",
      "- - - - - >Iteration:  164 ----->Partial loss: 0.0540717\n",
      "- - - - - >Iteration:  165 ----->Partial loss: 0.0899651\n",
      "- - - - - >Iteration:  166 ----->Partial loss: 0.0781973\n",
      "- - - - - >Iteration:  167 ----->Partial loss: 0.0823729\n",
      "- - - - - >Iteration:  168 ----->Partial loss: 0.0190149\n",
      "- - - - - >Iteration:  169 ----->Partial loss: 0.0260746\n",
      "- - - - - >Iteration:  170 ----->Partial loss: 0.0671381\n",
      "- - - - - >Iteration:  171 ----->Partial loss: 0.0814902\n",
      "- - - - - >Iteration:  172 ----->Partial loss: 0.0827722\n",
      "- - - - - >Iteration:  173 ----->Partial loss: 0.0379259\n",
      "- - - - - >Iteration:  174 ----->Partial loss: 0.0810848\n",
      "- - - - - >Iteration:  175 ----->Partial loss: 0.0358261\n",
      "- - - - - >Iteration:  176 ----->Partial loss: 0.0332714\n",
      "- - - - - >Iteration:  177 ----->Partial loss: 0.0235682\n",
      "- - - - - >Iteration:  178 ----->Partial loss: 0.0449153\n",
      "- - - - - >Iteration:  179 ----->Partial loss: 0.051023\n",
      "- - - - - >Iteration:  180 ----->Partial loss: 0.0535098\n",
      "- - - - - >Iteration:  181 ----->Partial loss: 0.0538571\n",
      "- - - - - >Iteration:  182 ----->Partial loss: 0.043113\n",
      "- - - - - >Iteration:  183 ----->Partial loss: 0.0585525\n",
      "- - - - - >Iteration:  184 ----->Partial loss: 0.189568\n",
      "- - - - - >Iteration:  185 ----->Partial loss: 0.0532982\n",
      "- - - - - >Iteration:  186 ----->Partial loss: 0.0780833\n",
      "- - - - - >Iteration:  187 ----->Partial loss: 0.0459625\n",
      "- - - - - >Iteration:  188 ----->Partial loss: 0.0704975\n",
      "- - - - - >Iteration:  189 ----->Partial loss: 0.0682174\n",
      "- - - - - >Iteration:  190 ----->Partial loss: 0.0446323\n",
      "- - - - - >Iteration:  191 ----->Partial loss: 0.0220115\n",
      "- - - - - >Iteration:  192 ----->Partial loss: 0.0658461\n",
      "- - - - - >Iteration:  193 ----->Partial loss: 0.0350746\n",
      "- - - - - >Iteration:  194 ----->Partial loss: 0.0230796\n",
      "- - - - - >Iteration:  195 ----->Partial loss: 0.0462142\n",
      "- - - - - >Iteration:  196 ----->Partial loss: 0.0257024\n",
      "- - - - - >Iteration:  197 ----->Partial loss: 0.0208039\n",
      "- - - - - >Iteration:  198 ----->Partial loss: 0.0667311\n",
      "- - - - - >Iteration:  199 ----->Partial loss: 0.0282383\n",
      "- - - - - >Iteration:  200 ----->Partial loss: 0.0283439\n",
      "- - - - - >Iteration:  201 ----->Partial loss: 0.02498\n",
      "- - - - - >Iteration:  202 ----->Partial loss: 0.0860862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- - - - - >Iteration:  203 ----->Partial loss: 0.0311562\n",
      "- - - - - >Iteration:  204 ----->Partial loss: 0.0786565\n",
      "- - - - - >Iteration:  205 ----->Partial loss: 0.0403064\n",
      "- - - - - >Iteration:  206 ----->Partial loss: 0.0538435\n",
      "- - - - - >Iteration:  207 ----->Partial loss: 0.057483\n",
      "- - - - - >Iteration:  208 ----->Partial loss: 0.0879309\n",
      "- - - - - >Iteration:  209 ----->Partial loss: 0.0564899\n",
      "- - - - - >Iteration:  210 ----->Partial loss: 0.0301111\n",
      "- - - - - >Iteration:  211 ----->Partial loss: 0.071988\n",
      "- - - - - >Iteration:  212 ----->Partial loss: 0.0460751\n",
      "- - - - - >Iteration:  213 ----->Partial loss: 0.0362222\n",
      "- - - - - >Iteration:  214 ----->Partial loss: 0.0583738\n",
      "- - - - - >Iteration:  215 ----->Partial loss: 0.108648\n",
      "- - - - - >Iteration:  216 ----->Partial loss: 0.0238154\n",
      "- - - - - >Iteration:  217 ----->Partial loss: 0.0177635\n",
      "- - - - - >Iteration:  218 ----->Partial loss: 0.0306902\n",
      "- - - - - >Iteration:  219 ----->Partial loss: 0.0226281\n",
      "- - - - - >Iteration:  220 ----->Partial loss: 0.0457727\n",
      "- - - - - >Iteration:  221 ----->Partial loss: 0.0588297\n",
      "- - - - - >Iteration:  222 ----->Partial loss: 0.0445733\n",
      "- - - - - >Iteration:  223 ----->Partial loss: 0.0352222\n",
      "- - - - - >Iteration:  224 ----->Partial loss: 0.0367752\n",
      "- - - - - >Iteration:  225 ----->Partial loss: 0.0453279\n",
      "- - - - - >Iteration:  226 ----->Partial loss: 0.0526472\n",
      "- - - - - >Iteration:  227 ----->Partial loss: 0.142378\n",
      "- - - - - >Iteration:  228 ----->Partial loss: 0.0581998\n",
      "- - - - - >Iteration:  229 ----->Partial loss: 0.0393783\n",
      "- - - - - >Iteration:  230 ----->Partial loss: 0.0630493\n",
      "- - - - - >Iteration:  231 ----->Partial loss: 0.0532015\n",
      "- - - - - >Iteration:  232 ----->Partial loss: 0.0253458\n",
      "- - - - - >Iteration:  233 ----->Partial loss: 0.0793221\n",
      "- - - - - >Iteration:  234 ----->Partial loss: 0.04312\n",
      "- - - - - >Iteration:  235 ----->Partial loss: 0.0745259\n",
      "- - - - - >Iteration:  236 ----->Partial loss: 0.0655527\n",
      "- - - - - >Iteration:  237 ----->Partial loss: 0.0631212\n",
      "- - - - - >Iteration:  238 ----->Partial loss: 0.0441237\n",
      "- - - - - >Iteration:  239 ----->Partial loss: 0.0642002\n",
      "- - - - - >Iteration:  240 ----->Partial loss: 0.0257555\n",
      "- - - - - >Iteration:  241 ----->Partial loss: 0.0498708\n",
      "- - - - - >Iteration:  242 ----->Partial loss: 0.0345701\n",
      "- - - - - >Iteration:  243 ----->Partial loss: 0.0495924\n",
      "- - - - - >Iteration:  244 ----->Partial loss: 0.0169134\n",
      "- - - - - >Iteration:  245 ----->Partial loss: 0.0264296\n",
      "- - - - - >Iteration:  246 ----->Partial loss: 0.0571957\n",
      "- - - - - >Iteration:  247 ----->Partial loss: 0.0621911\n",
      "- - - - - >Iteration:  248 ----->Partial loss: 0.0752037\n",
      "- - - - - >Iteration:  249 ----->Partial loss: 0.0564309\n",
      "- - - - - >Iteration:  250 ----->Partial loss: 0.058005\n",
      "- - - - - >Iteration:  251 ----->Partial loss: 0.0272553\n",
      "- - - - - >Iteration:  252 ----->Partial loss: 0.0990438\n",
      "- - - - - >Iteration:  253 ----->Partial loss: 0.12416\n",
      "- - - - - >Iteration:  254 ----->Partial loss: 0.0228756\n",
      "- - - - - >Iteration:  255 ----->Partial loss: 0.0354149\n",
      "- - - - - >Iteration:  256 ----->Partial loss: 0.0299376\n",
      "- - - - - >Iteration:  257 ----->Partial loss: 0.0167795\n",
      "- - - - - >Iteration:  258 ----->Partial loss: 0.0408053\n",
      "- - - - - >Iteration:  259 ----->Partial loss: 0.0344025\n",
      "- - - - - >Iteration:  260 ----->Partial loss: 0.0979372\n",
      "- - - - - >Iteration:  261 ----->Partial loss: 0.131122\n",
      "- - - - - >Iteration:  262 ----->Partial loss: 0.101931\n",
      "- - - - - >Iteration:  263 ----->Partial loss: 0.094985\n",
      "- - - - - >Iteration:  264 ----->Partial loss: 0.0626099\n",
      "- - - - - >Iteration:  265 ----->Partial loss: 0.0306094\n",
      "- - - - - >Iteration:  266 ----->Partial loss: 0.0654226\n",
      "- - - - - >Iteration:  267 ----->Partial loss: 0.073509\n",
      "- - - - - >Iteration:  268 ----->Partial loss: 0.0373423\n",
      "- - - - - >Iteration:  269 ----->Partial loss: 0.0738904\n",
      "- - - - - >Iteration:  270 ----->Partial loss: 0.0879976\n",
      "- - - - - >Iteration:  271 ----->Partial loss: 0.0329084\n",
      "- - - - - >Iteration:  272 ----->Partial loss: 0.0386582\n",
      "- - - - - >Iteration:  273 ----->Partial loss: 0.0497327\n",
      "- - - - - >Iteration:  274 ----->Partial loss: 0.0482698\n",
      "- - - - - >Iteration:  275 ----->Partial loss: 0.0463634\n",
      "- - - - - >Iteration:  276 ----->Partial loss: 0.0337035\n",
      "- - - - - >Iteration:  277 ----->Partial loss: 0.0207418\n",
      "- - - - - >Iteration:  278 ----->Partial loss: 0.0446371\n",
      "- - - - - >Iteration:  279 ----->Partial loss: 0.0265626\n",
      "- - - - - >Iteration:  280 ----->Partial loss: 0.0450406\n",
      "- - - - - >Iteration:  281 ----->Partial loss: 0.0600511\n",
      "- - - - - >Iteration:  282 ----->Partial loss: 0.0546264\n",
      "- - - - - >Iteration:  283 ----->Partial loss: 0.131304\n",
      "- - - - - >Iteration:  284 ----->Partial loss: 0.0567666\n",
      "- - - - - >Iteration:  285 ----->Partial loss: 0.0369985\n",
      "- - - - - >Iteration:  286 ----->Partial loss: 0.0634533\n",
      "- - - - - >Iteration:  287 ----->Partial loss: 0.027249\n",
      "- - - - - >Iteration:  288 ----->Partial loss: 0.0471465\n",
      "- - - - - >Iteration:  289 ----->Partial loss: 0.0831655\n",
      "***************\n",
      "Epoch:  17  of  20 training loss:  0.053710165179\n",
      "***************\n",
      "- - - - - >Iteration:  1 ----->Partial loss: 0.0587861\n",
      "- - - - - >Iteration:  2 ----->Partial loss: 0.0440602\n",
      "- - - - - >Iteration:  3 ----->Partial loss: 0.0759929\n",
      "- - - - - >Iteration:  4 ----->Partial loss: 0.0437642\n",
      "- - - - - >Iteration:  5 ----->Partial loss: 0.0345015\n",
      "- - - - - >Iteration:  6 ----->Partial loss: 0.0249187\n",
      "- - - - - >Iteration:  7 ----->Partial loss: 0.0573778\n",
      "- - - - - >Iteration:  8 ----->Partial loss: 0.0630849\n",
      "- - - - - >Iteration:  9 ----->Partial loss: 0.0723775\n",
      "- - - - - >Iteration:  10 ----->Partial loss: 0.0315168\n",
      "- - - - - >Iteration:  11 ----->Partial loss: 0.0899623\n",
      "- - - - - >Iteration:  12 ----->Partial loss: 0.0752306\n",
      "- - - - - >Iteration:  13 ----->Partial loss: 0.070077\n",
      "- - - - - >Iteration:  14 ----->Partial loss: 0.0279863\n",
      "- - - - - >Iteration:  15 ----->Partial loss: 0.0302159\n",
      "- - - - - >Iteration:  16 ----->Partial loss: 0.0221442\n",
      "- - - - - >Iteration:  17 ----->Partial loss: 0.0252873\n",
      "- - - - - >Iteration:  18 ----->Partial loss: 0.0306154\n",
      "- - - - - >Iteration:  19 ----->Partial loss: 0.0319803\n",
      "- - - - - >Iteration:  20 ----->Partial loss: 0.165882\n",
      "- - - - - >Iteration:  21 ----->Partial loss: 0.0223618\n",
      "- - - - - >Iteration:  22 ----->Partial loss: 0.0703285\n",
      "- - - - - >Iteration:  23 ----->Partial loss: 0.0743377\n",
      "- - - - - >Iteration:  24 ----->Partial loss: 0.0767616\n",
      "- - - - - >Iteration:  25 ----->Partial loss: 0.0566184\n",
      "- - - - - >Iteration:  26 ----->Partial loss: 0.0507628\n",
      "- - - - - >Iteration:  27 ----->Partial loss: 0.068429\n",
      "- - - - - >Iteration:  28 ----->Partial loss: 0.0388787\n",
      "- - - - - >Iteration:  29 ----->Partial loss: 0.0994209\n",
      "- - - - - >Iteration:  30 ----->Partial loss: 0.0611972\n",
      "- - - - - >Iteration:  31 ----->Partial loss: 0.0275589\n",
      "- - - - - >Iteration:  32 ----->Partial loss: 0.0228618\n",
      "- - - - - >Iteration:  33 ----->Partial loss: 0.0494007\n",
      "- - - - - >Iteration:  34 ----->Partial loss: 0.0568226\n",
      "- - - - - >Iteration:  35 ----->Partial loss: 0.0731876\n",
      "- - - - - >Iteration:  36 ----->Partial loss: 0.0638085\n",
      "- - - - - >Iteration:  37 ----->Partial loss: 0.0377258\n",
      "- - - - - >Iteration:  38 ----->Partial loss: 0.0570703\n",
      "- - - - - >Iteration:  39 ----->Partial loss: 0.0298764\n",
      "- - - - - >Iteration:  40 ----->Partial loss: 0.0167224\n",
      "- - - - - >Iteration:  41 ----->Partial loss: 0.0190274\n",
      "- - - - - >Iteration:  42 ----->Partial loss: 0.0347356\n",
      "- - - - - >Iteration:  43 ----->Partial loss: 0.0410011\n",
      "- - - - - >Iteration:  44 ----->Partial loss: 0.0341289\n",
      "- - - - - >Iteration:  45 ----->Partial loss: 0.0418838\n",
      "- - - - - >Iteration:  46 ----->Partial loss: 0.088146\n",
      "- - - - - >Iteration:  47 ----->Partial loss: 0.0697297\n",
      "- - - - - >Iteration:  48 ----->Partial loss: 0.0511911\n",
      "- - - - - >Iteration:  49 ----->Partial loss: 0.0248273\n",
      "- - - - - >Iteration:  50 ----->Partial loss: 0.0487696\n",
      "- - - - - >Iteration:  51 ----->Partial loss: 0.039391\n",
      "- - - - - >Iteration:  52 ----->Partial loss: 0.0214007\n",
      "- - - - - >Iteration:  53 ----->Partial loss: 0.0345541\n",
      "- - - - - >Iteration:  54 ----->Partial loss: 0.0391458\n",
      "- - - - - >Iteration:  55 ----->Partial loss: 0.0296356\n",
      "- - - - - >Iteration:  56 ----->Partial loss: 0.0204676\n",
      "- - - - - >Iteration:  57 ----->Partial loss: 0.0398496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- - - - - >Iteration:  58 ----->Partial loss: 0.0290054\n",
      "- - - - - >Iteration:  59 ----->Partial loss: 0.0205299\n",
      "- - - - - >Iteration:  60 ----->Partial loss: 0.0268041\n",
      "- - - - - >Iteration:  61 ----->Partial loss: 0.0509347\n",
      "- - - - - >Iteration:  62 ----->Partial loss: 0.0483907\n",
      "- - - - - >Iteration:  63 ----->Partial loss: 0.0166029\n",
      "- - - - - >Iteration:  64 ----->Partial loss: 0.0257091\n",
      "- - - - - >Iteration:  65 ----->Partial loss: 0.0270514\n",
      "- - - - - >Iteration:  66 ----->Partial loss: 0.0818214\n",
      "- - - - - >Iteration:  67 ----->Partial loss: 0.0611532\n",
      "- - - - - >Iteration:  68 ----->Partial loss: 0.0210551\n",
      "- - - - - >Iteration:  69 ----->Partial loss: 0.0455788\n",
      "- - - - - >Iteration:  70 ----->Partial loss: 0.0312448\n",
      "- - - - - >Iteration:  71 ----->Partial loss: 0.0145633\n",
      "- - - - - >Iteration:  72 ----->Partial loss: 0.0561657\n",
      "- - - - - >Iteration:  73 ----->Partial loss: 0.0732571\n",
      "- - - - - >Iteration:  74 ----->Partial loss: 0.0197515\n",
      "- - - - - >Iteration:  75 ----->Partial loss: 0.0566221\n",
      "- - - - - >Iteration:  76 ----->Partial loss: 0.0420261\n",
      "- - - - - >Iteration:  77 ----->Partial loss: 0.0574319\n",
      "- - - - - >Iteration:  78 ----->Partial loss: 0.0224502\n",
      "- - - - - >Iteration:  79 ----->Partial loss: 0.0315519\n",
      "- - - - - >Iteration:  80 ----->Partial loss: 0.0445632\n",
      "- - - - - >Iteration:  81 ----->Partial loss: 0.0543094\n",
      "- - - - - >Iteration:  82 ----->Partial loss: 0.0286987\n",
      "- - - - - >Iteration:  83 ----->Partial loss: 0.069213\n",
      "- - - - - >Iteration:  84 ----->Partial loss: 0.100875\n",
      "- - - - - >Iteration:  85 ----->Partial loss: 0.0614925\n",
      "- - - - - >Iteration:  86 ----->Partial loss: 0.0243801\n",
      "- - - - - >Iteration:  87 ----->Partial loss: 0.047845\n",
      "- - - - - >Iteration:  88 ----->Partial loss: 0.0462505\n",
      "- - - - - >Iteration:  89 ----->Partial loss: 0.0443336\n",
      "- - - - - >Iteration:  90 ----->Partial loss: 0.0872515\n",
      "- - - - - >Iteration:  91 ----->Partial loss: 0.0789437\n",
      "- - - - - >Iteration:  92 ----->Partial loss: 0.0628213\n",
      "- - - - - >Iteration:  93 ----->Partial loss: 0.0477503\n",
      "- - - - - >Iteration:  94 ----->Partial loss: 0.0724157\n",
      "- - - - - >Iteration:  95 ----->Partial loss: 0.0447012\n",
      "- - - - - >Iteration:  96 ----->Partial loss: 0.0227269\n",
      "- - - - - >Iteration:  97 ----->Partial loss: 0.0700403\n",
      "- - - - - >Iteration:  98 ----->Partial loss: 0.0252195\n",
      "- - - - - >Iteration:  99 ----->Partial loss: 0.0602668\n",
      "- - - - - >Iteration:  100 ----->Partial loss: 0.0394894\n",
      "- - - - - >Iteration:  101 ----->Partial loss: 0.0239481\n",
      "- - - - - >Iteration:  102 ----->Partial loss: 0.0287764\n",
      "- - - - - >Iteration:  103 ----->Partial loss: 0.0171884\n",
      "- - - - - >Iteration:  104 ----->Partial loss: 0.041644\n",
      "- - - - - >Iteration:  105 ----->Partial loss: 0.0476586\n",
      "- - - - - >Iteration:  106 ----->Partial loss: 0.035286\n",
      "- - - - - >Iteration:  107 ----->Partial loss: 0.0432765\n",
      "- - - - - >Iteration:  108 ----->Partial loss: 0.0317889\n",
      "- - - - - >Iteration:  109 ----->Partial loss: 0.0257523\n",
      "- - - - - >Iteration:  110 ----->Partial loss: 0.104721\n",
      "- - - - - >Iteration:  111 ----->Partial loss: 0.0497165\n",
      "- - - - - >Iteration:  112 ----->Partial loss: 0.0241133\n",
      "- - - - - >Iteration:  113 ----->Partial loss: 0.0326119\n",
      "- - - - - >Iteration:  114 ----->Partial loss: 0.0425258\n",
      "- - - - - >Iteration:  115 ----->Partial loss: 0.027095\n",
      "- - - - - >Iteration:  116 ----->Partial loss: 0.024293\n",
      "- - - - - >Iteration:  117 ----->Partial loss: 0.0228055\n",
      "- - - - - >Iteration:  118 ----->Partial loss: 0.0995088\n",
      "- - - - - >Iteration:  119 ----->Partial loss: 0.0279534\n",
      "- - - - - >Iteration:  120 ----->Partial loss: 0.0489872\n",
      "- - - - - >Iteration:  121 ----->Partial loss: 0.0265263\n",
      "- - - - - >Iteration:  122 ----->Partial loss: 0.0684837\n",
      "- - - - - >Iteration:  123 ----->Partial loss: 0.0571402\n",
      "- - - - - >Iteration:  124 ----->Partial loss: 0.0404151\n",
      "- - - - - >Iteration:  125 ----->Partial loss: 0.0547505\n",
      "- - - - - >Iteration:  126 ----->Partial loss: 0.0963852\n",
      "- - - - - >Iteration:  127 ----->Partial loss: 0.053682\n",
      "- - - - - >Iteration:  128 ----->Partial loss: 0.0377093\n",
      "- - - - - >Iteration:  129 ----->Partial loss: 0.0515414\n",
      "- - - - - >Iteration:  130 ----->Partial loss: 0.050595\n",
      "- - - - - >Iteration:  131 ----->Partial loss: 0.0630647\n",
      "- - - - - >Iteration:  132 ----->Partial loss: 0.0418494\n",
      "- - - - - >Iteration:  133 ----->Partial loss: 0.0419454\n",
      "- - - - - >Iteration:  134 ----->Partial loss: 0.0337014\n",
      "- - - - - >Iteration:  135 ----->Partial loss: 0.0436257\n",
      "- - - - - >Iteration:  136 ----->Partial loss: 0.0357322\n",
      "- - - - - >Iteration:  137 ----->Partial loss: 0.0288764\n",
      "- - - - - >Iteration:  138 ----->Partial loss: 0.019943\n",
      "- - - - - >Iteration:  139 ----->Partial loss: 0.0294128\n",
      "- - - - - >Iteration:  140 ----->Partial loss: 0.0208548\n",
      "- - - - - >Iteration:  141 ----->Partial loss: 0.0443113\n",
      "- - - - - >Iteration:  142 ----->Partial loss: 0.0555156\n",
      "- - - - - >Iteration:  143 ----->Partial loss: 0.0991266\n",
      "- - - - - >Iteration:  144 ----->Partial loss: 0.0799396\n",
      "- - - - - >Iteration:  145 ----->Partial loss: 0.0576406\n",
      "- - - - - >Iteration:  146 ----->Partial loss: 0.0454965\n",
      "- - - - - >Iteration:  147 ----->Partial loss: 0.03436\n",
      "- - - - - >Iteration:  148 ----->Partial loss: 0.0891806\n",
      "- - - - - >Iteration:  149 ----->Partial loss: 0.0318508\n",
      "- - - - - >Iteration:  150 ----->Partial loss: 0.0229807\n",
      "- - - - - >Iteration:  151 ----->Partial loss: 0.0224155\n",
      "- - - - - >Iteration:  152 ----->Partial loss: 0.0684178\n",
      "- - - - - >Iteration:  153 ----->Partial loss: 0.0179321\n",
      "- - - - - >Iteration:  154 ----->Partial loss: 0.0458955\n",
      "- - - - - >Iteration:  155 ----->Partial loss: 0.085049\n",
      "- - - - - >Iteration:  156 ----->Partial loss: 0.0508212\n",
      "- - - - - >Iteration:  157 ----->Partial loss: 0.0637608\n",
      "- - - - - >Iteration:  158 ----->Partial loss: 0.0584207\n",
      "- - - - - >Iteration:  159 ----->Partial loss: 0.0433946\n",
      "- - - - - >Iteration:  160 ----->Partial loss: 0.0466847\n",
      "- - - - - >Iteration:  161 ----->Partial loss: 0.0633314\n",
      "- - - - - >Iteration:  162 ----->Partial loss: 0.0341472\n",
      "- - - - - >Iteration:  163 ----->Partial loss: 0.0240096\n",
      "- - - - - >Iteration:  164 ----->Partial loss: 0.0426458\n",
      "- - - - - >Iteration:  165 ----->Partial loss: 0.0585958\n",
      "- - - - - >Iteration:  166 ----->Partial loss: 0.0433905\n",
      "- - - - - >Iteration:  167 ----->Partial loss: 0.0287576\n",
      "- - - - - >Iteration:  168 ----->Partial loss: 0.0287298\n",
      "- - - - - >Iteration:  169 ----->Partial loss: 0.0309051\n",
      "- - - - - >Iteration:  170 ----->Partial loss: 0.0439012\n",
      "- - - - - >Iteration:  171 ----->Partial loss: 0.0604061\n",
      "- - - - - >Iteration:  172 ----->Partial loss: 0.0174929\n",
      "- - - - - >Iteration:  173 ----->Partial loss: 0.0300277\n",
      "- - - - - >Iteration:  174 ----->Partial loss: 0.0507831\n",
      "- - - - - >Iteration:  175 ----->Partial loss: 0.0428345\n",
      "- - - - - >Iteration:  176 ----->Partial loss: 0.0335942\n",
      "- - - - - >Iteration:  177 ----->Partial loss: 0.066744\n",
      "- - - - - >Iteration:  178 ----->Partial loss: 0.0512119\n",
      "- - - - - >Iteration:  179 ----->Partial loss: 0.0373813\n",
      "- - - - - >Iteration:  180 ----->Partial loss: 0.0319492\n",
      "- - - - - >Iteration:  181 ----->Partial loss: 0.0418707\n",
      "- - - - - >Iteration:  182 ----->Partial loss: 0.0682279\n",
      "- - - - - >Iteration:  183 ----->Partial loss: 0.0210034\n",
      "- - - - - >Iteration:  184 ----->Partial loss: 0.0251918\n",
      "- - - - - >Iteration:  185 ----->Partial loss: 0.0409322\n",
      "- - - - - >Iteration:  186 ----->Partial loss: 0.0313326\n",
      "- - - - - >Iteration:  187 ----->Partial loss: 0.063568\n",
      "- - - - - >Iteration:  188 ----->Partial loss: 0.0406129\n",
      "- - - - - >Iteration:  189 ----->Partial loss: 0.0282113\n",
      "- - - - - >Iteration:  190 ----->Partial loss: 0.0528607\n",
      "- - - - - >Iteration:  191 ----->Partial loss: 0.0949575\n",
      "- - - - - >Iteration:  192 ----->Partial loss: 0.044481\n",
      "- - - - - >Iteration:  193 ----->Partial loss: 0.0434839\n",
      "- - - - - >Iteration:  194 ----->Partial loss: 0.0247198\n",
      "- - - - - >Iteration:  195 ----->Partial loss: 0.0442283\n",
      "- - - - - >Iteration:  196 ----->Partial loss: 0.0188413\n",
      "- - - - - >Iteration:  197 ----->Partial loss: 0.176256\n",
      "- - - - - >Iteration:  198 ----->Partial loss: 0.0878109\n",
      "- - - - - >Iteration:  199 ----->Partial loss: 0.068934\n",
      "- - - - - >Iteration:  200 ----->Partial loss: 0.0605713\n",
      "- - - - - >Iteration:  201 ----->Partial loss: 0.0155084\n",
      "- - - - - >Iteration:  202 ----->Partial loss: 0.104118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- - - - - >Iteration:  203 ----->Partial loss: 0.0427529\n",
      "- - - - - >Iteration:  204 ----->Partial loss: 0.0523681\n",
      "- - - - - >Iteration:  205 ----->Partial loss: 0.0611443\n",
      "- - - - - >Iteration:  206 ----->Partial loss: 0.0407611\n",
      "- - - - - >Iteration:  207 ----->Partial loss: 0.0271534\n",
      "- - - - - >Iteration:  208 ----->Partial loss: 0.0842178\n",
      "- - - - - >Iteration:  209 ----->Partial loss: 0.0201427\n",
      "- - - - - >Iteration:  210 ----->Partial loss: 0.0615365\n",
      "- - - - - >Iteration:  211 ----->Partial loss: 0.0276625\n",
      "- - - - - >Iteration:  212 ----->Partial loss: 0.0578162\n",
      "- - - - - >Iteration:  213 ----->Partial loss: 0.0375062\n",
      "- - - - - >Iteration:  214 ----->Partial loss: 0.0558792\n",
      "- - - - - >Iteration:  215 ----->Partial loss: 0.0326467\n",
      "- - - - - >Iteration:  216 ----->Partial loss: 0.0657881\n",
      "- - - - - >Iteration:  217 ----->Partial loss: 0.0341761\n",
      "- - - - - >Iteration:  218 ----->Partial loss: 0.0583102\n",
      "- - - - - >Iteration:  219 ----->Partial loss: 0.0497262\n",
      "- - - - - >Iteration:  220 ----->Partial loss: 0.0789929\n",
      "- - - - - >Iteration:  221 ----->Partial loss: 0.0409779\n",
      "- - - - - >Iteration:  222 ----->Partial loss: 0.019265\n",
      "- - - - - >Iteration:  223 ----->Partial loss: 0.160772\n",
      "- - - - - >Iteration:  224 ----->Partial loss: 0.053253\n",
      "- - - - - >Iteration:  225 ----->Partial loss: 0.142849\n",
      "- - - - - >Iteration:  226 ----->Partial loss: 0.104887\n",
      "- - - - - >Iteration:  227 ----->Partial loss: 0.0562158\n",
      "- - - - - >Iteration:  228 ----->Partial loss: 0.0698329\n",
      "- - - - - >Iteration:  229 ----->Partial loss: 0.0455504\n",
      "- - - - - >Iteration:  230 ----->Partial loss: 0.0743724\n",
      "- - - - - >Iteration:  231 ----->Partial loss: 0.0192431\n",
      "- - - - - >Iteration:  232 ----->Partial loss: 0.067968\n",
      "- - - - - >Iteration:  233 ----->Partial loss: 0.0536246\n",
      "- - - - - >Iteration:  234 ----->Partial loss: 0.0806096\n",
      "- - - - - >Iteration:  235 ----->Partial loss: 0.0188967\n",
      "- - - - - >Iteration:  236 ----->Partial loss: 0.0160356\n",
      "- - - - - >Iteration:  237 ----->Partial loss: 0.0546504\n",
      "- - - - - >Iteration:  238 ----->Partial loss: 0.0219752\n",
      "- - - - - >Iteration:  239 ----->Partial loss: 0.0832528\n",
      "- - - - - >Iteration:  240 ----->Partial loss: 0.0180706\n",
      "- - - - - >Iteration:  241 ----->Partial loss: 0.0456921\n",
      "- - - - - >Iteration:  242 ----->Partial loss: 0.107101\n",
      "- - - - - >Iteration:  243 ----->Partial loss: 0.0441876\n",
      "- - - - - >Iteration:  244 ----->Partial loss: 0.0184324\n",
      "- - - - - >Iteration:  245 ----->Partial loss: 0.0205246\n",
      "- - - - - >Iteration:  246 ----->Partial loss: 0.0237458\n",
      "- - - - - >Iteration:  247 ----->Partial loss: 0.0222859\n",
      "- - - - - >Iteration:  248 ----->Partial loss: 0.0174417\n",
      "- - - - - >Iteration:  249 ----->Partial loss: 0.0916255\n",
      "- - - - - >Iteration:  250 ----->Partial loss: 0.0302501\n",
      "- - - - - >Iteration:  251 ----->Partial loss: 0.0365354\n",
      "- - - - - >Iteration:  252 ----->Partial loss: 0.0304567\n",
      "- - - - - >Iteration:  253 ----->Partial loss: 0.0256525\n",
      "- - - - - >Iteration:  254 ----->Partial loss: 0.0924861\n",
      "- - - - - >Iteration:  255 ----->Partial loss: 0.0233521\n",
      "- - - - - >Iteration:  256 ----->Partial loss: 0.075525\n",
      "- - - - - >Iteration:  257 ----->Partial loss: 0.0620056\n",
      "- - - - - >Iteration:  258 ----->Partial loss: 0.0323698\n",
      "- - - - - >Iteration:  259 ----->Partial loss: 0.0638913\n",
      "- - - - - >Iteration:  260 ----->Partial loss: 0.0364305\n",
      "- - - - - >Iteration:  261 ----->Partial loss: 0.0639994\n",
      "- - - - - >Iteration:  262 ----->Partial loss: 0.0735563\n",
      "- - - - - >Iteration:  263 ----->Partial loss: 0.0479842\n",
      "- - - - - >Iteration:  264 ----->Partial loss: 0.0432448\n",
      "- - - - - >Iteration:  265 ----->Partial loss: 0.0357161\n",
      "- - - - - >Iteration:  266 ----->Partial loss: 0.0254804\n",
      "- - - - - >Iteration:  267 ----->Partial loss: 0.0920824\n",
      "- - - - - >Iteration:  268 ----->Partial loss: 0.0514728\n",
      "- - - - - >Iteration:  269 ----->Partial loss: 0.0919149\n",
      "- - - - - >Iteration:  270 ----->Partial loss: 0.0312088\n",
      "- - - - - >Iteration:  271 ----->Partial loss: 0.0429813\n",
      "- - - - - >Iteration:  272 ----->Partial loss: 0.0643304\n",
      "- - - - - >Iteration:  273 ----->Partial loss: 0.0958352\n",
      "- - - - - >Iteration:  274 ----->Partial loss: 0.0468665\n",
      "- - - - - >Iteration:  275 ----->Partial loss: 0.0630316\n",
      "- - - - - >Iteration:  276 ----->Partial loss: 0.0979759\n",
      "- - - - - >Iteration:  277 ----->Partial loss: 0.0446232\n",
      "- - - - - >Iteration:  278 ----->Partial loss: 0.0442598\n",
      "- - - - - >Iteration:  279 ----->Partial loss: 0.0752629\n",
      "- - - - - >Iteration:  280 ----->Partial loss: 0.0443785\n",
      "- - - - - >Iteration:  281 ----->Partial loss: 0.0691489\n",
      "- - - - - >Iteration:  282 ----->Partial loss: 0.0296008\n",
      "- - - - - >Iteration:  283 ----->Partial loss: 0.0433474\n",
      "- - - - - >Iteration:  284 ----->Partial loss: 0.032404\n",
      "- - - - - >Iteration:  285 ----->Partial loss: 0.0181128\n",
      "- - - - - >Iteration:  286 ----->Partial loss: 0.039852\n",
      "- - - - - >Iteration:  287 ----->Partial loss: 0.0563361\n",
      "- - - - - >Iteration:  288 ----->Partial loss: 0.0752921\n",
      "- - - - - >Iteration:  289 ----->Partial loss: 0.0492319\n",
      "***************\n",
      "Epoch:  18  of  20 training loss:  0.0489934704598\n",
      "***************\n",
      "- - - - - >Iteration:  1 ----->Partial loss: 0.0582686\n",
      "- - - - - >Iteration:  2 ----->Partial loss: 0.0231707\n",
      "- - - - - >Iteration:  3 ----->Partial loss: 0.0474545\n",
      "- - - - - >Iteration:  4 ----->Partial loss: 0.0424014\n",
      "- - - - - >Iteration:  5 ----->Partial loss: 0.0421691\n",
      "- - - - - >Iteration:  6 ----->Partial loss: 0.0380166\n",
      "- - - - - >Iteration:  7 ----->Partial loss: 0.0230184\n",
      "- - - - - >Iteration:  8 ----->Partial loss: 0.0252536\n",
      "- - - - - >Iteration:  9 ----->Partial loss: 0.0443368\n",
      "- - - - - >Iteration:  10 ----->Partial loss: 0.0569815\n",
      "- - - - - >Iteration:  11 ----->Partial loss: 0.0251539\n",
      "- - - - - >Iteration:  12 ----->Partial loss: 0.0395693\n",
      "- - - - - >Iteration:  13 ----->Partial loss: 0.0449604\n",
      "- - - - - >Iteration:  14 ----->Partial loss: 0.0403825\n",
      "- - - - - >Iteration:  15 ----->Partial loss: 0.0861213\n",
      "- - - - - >Iteration:  16 ----->Partial loss: 0.024297\n",
      "- - - - - >Iteration:  17 ----->Partial loss: 0.097157\n",
      "- - - - - >Iteration:  18 ----->Partial loss: 0.0390821\n",
      "- - - - - >Iteration:  19 ----->Partial loss: 0.055813\n",
      "- - - - - >Iteration:  20 ----->Partial loss: 0.0631245\n",
      "- - - - - >Iteration:  21 ----->Partial loss: 0.0222963\n",
      "- - - - - >Iteration:  22 ----->Partial loss: 0.0178281\n",
      "- - - - - >Iteration:  23 ----->Partial loss: 0.028134\n",
      "- - - - - >Iteration:  24 ----->Partial loss: 0.0408188\n",
      "- - - - - >Iteration:  25 ----->Partial loss: 0.0317662\n",
      "- - - - - >Iteration:  26 ----->Partial loss: 0.0274302\n",
      "- - - - - >Iteration:  27 ----->Partial loss: 0.0898654\n",
      "- - - - - >Iteration:  28 ----->Partial loss: 0.083731\n",
      "- - - - - >Iteration:  29 ----->Partial loss: 0.0516151\n",
      "- - - - - >Iteration:  30 ----->Partial loss: 0.0183751\n",
      "- - - - - >Iteration:  31 ----->Partial loss: 0.0161014\n",
      "- - - - - >Iteration:  32 ----->Partial loss: 0.07764\n",
      "- - - - - >Iteration:  33 ----->Partial loss: 0.0513031\n",
      "- - - - - >Iteration:  34 ----->Partial loss: 0.0423742\n",
      "- - - - - >Iteration:  35 ----->Partial loss: 0.0474032\n",
      "- - - - - >Iteration:  36 ----->Partial loss: 0.0440456\n",
      "- - - - - >Iteration:  37 ----->Partial loss: 0.0360695\n",
      "- - - - - >Iteration:  38 ----->Partial loss: 0.0215169\n",
      "- - - - - >Iteration:  39 ----->Partial loss: 0.0421391\n",
      "- - - - - >Iteration:  40 ----->Partial loss: 0.0523997\n",
      "- - - - - >Iteration:  41 ----->Partial loss: 0.0581132\n",
      "- - - - - >Iteration:  42 ----->Partial loss: 0.0197968\n",
      "- - - - - >Iteration:  43 ----->Partial loss: 0.0644791\n",
      "- - - - - >Iteration:  44 ----->Partial loss: 0.0424062\n",
      "- - - - - >Iteration:  45 ----->Partial loss: 0.0227711\n",
      "- - - - - >Iteration:  46 ----->Partial loss: 0.0643937\n",
      "- - - - - >Iteration:  47 ----->Partial loss: 0.0458643\n",
      "- - - - - >Iteration:  48 ----->Partial loss: 0.0187492\n",
      "- - - - - >Iteration:  49 ----->Partial loss: 0.034328\n",
      "- - - - - >Iteration:  50 ----->Partial loss: 0.0494932\n",
      "- - - - - >Iteration:  51 ----->Partial loss: 0.0489842\n",
      "- - - - - >Iteration:  52 ----->Partial loss: 0.0201319\n",
      "- - - - - >Iteration:  53 ----->Partial loss: 0.047084\n",
      "- - - - - >Iteration:  54 ----->Partial loss: 0.0412428\n",
      "- - - - - >Iteration:  55 ----->Partial loss: 0.0368631\n",
      "- - - - - >Iteration:  56 ----->Partial loss: 0.0334786\n",
      "- - - - - >Iteration:  57 ----->Partial loss: 0.0295602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- - - - - >Iteration:  58 ----->Partial loss: 0.0384835\n",
      "- - - - - >Iteration:  59 ----->Partial loss: 0.0569299\n",
      "- - - - - >Iteration:  60 ----->Partial loss: 0.0729364\n",
      "- - - - - >Iteration:  61 ----->Partial loss: 0.0176293\n",
      "- - - - - >Iteration:  62 ----->Partial loss: 0.0234087\n",
      "- - - - - >Iteration:  63 ----->Partial loss: 0.0835781\n",
      "- - - - - >Iteration:  64 ----->Partial loss: 0.0564459\n",
      "- - - - - >Iteration:  65 ----->Partial loss: 0.0695205\n",
      "- - - - - >Iteration:  66 ----->Partial loss: 0.0329145\n",
      "- - - - - >Iteration:  67 ----->Partial loss: 0.0638219\n",
      "- - - - - >Iteration:  68 ----->Partial loss: 0.0174569\n",
      "- - - - - >Iteration:  69 ----->Partial loss: 0.0240342\n",
      "- - - - - >Iteration:  70 ----->Partial loss: 0.0433384\n",
      "- - - - - >Iteration:  71 ----->Partial loss: 0.0468117\n",
      "- - - - - >Iteration:  72 ----->Partial loss: 0.0337167\n",
      "- - - - - >Iteration:  73 ----->Partial loss: 0.025207\n",
      "- - - - - >Iteration:  74 ----->Partial loss: 0.0636339\n",
      "- - - - - >Iteration:  75 ----->Partial loss: 0.0627284\n",
      "- - - - - >Iteration:  76 ----->Partial loss: 0.0276917\n",
      "- - - - - >Iteration:  77 ----->Partial loss: 0.0301763\n",
      "- - - - - >Iteration:  78 ----->Partial loss: 0.0817729\n",
      "- - - - - >Iteration:  79 ----->Partial loss: 0.0435963\n",
      "- - - - - >Iteration:  80 ----->Partial loss: 0.0430692\n",
      "- - - - - >Iteration:  81 ----->Partial loss: 0.0659393\n",
      "- - - - - >Iteration:  82 ----->Partial loss: 0.0412721\n",
      "- - - - - >Iteration:  83 ----->Partial loss: 0.0243184\n",
      "- - - - - >Iteration:  84 ----->Partial loss: 0.0265859\n",
      "- - - - - >Iteration:  85 ----->Partial loss: 0.0272876\n",
      "- - - - - >Iteration:  86 ----->Partial loss: 0.0615992\n",
      "- - - - - >Iteration:  87 ----->Partial loss: 0.0509946\n",
      "- - - - - >Iteration:  88 ----->Partial loss: 0.135338\n",
      "- - - - - >Iteration:  89 ----->Partial loss: 0.0633322\n",
      "- - - - - >Iteration:  90 ----->Partial loss: 0.0344488\n",
      "- - - - - >Iteration:  91 ----->Partial loss: 0.048698\n",
      "- - - - - >Iteration:  92 ----->Partial loss: 0.0670138\n",
      "- - - - - >Iteration:  93 ----->Partial loss: 0.0383055\n",
      "- - - - - >Iteration:  94 ----->Partial loss: 0.0463772\n",
      "- - - - - >Iteration:  95 ----->Partial loss: 0.0597295\n",
      "- - - - - >Iteration:  96 ----->Partial loss: 0.0877335\n",
      "- - - - - >Iteration:  97 ----->Partial loss: 0.0305477\n",
      "- - - - - >Iteration:  98 ----->Partial loss: 0.0459925\n",
      "- - - - - >Iteration:  99 ----->Partial loss: 0.0434303\n",
      "- - - - - >Iteration:  100 ----->Partial loss: 0.106688\n",
      "- - - - - >Iteration:  101 ----->Partial loss: 0.0265603\n",
      "- - - - - >Iteration:  102 ----->Partial loss: 0.0607691\n",
      "- - - - - >Iteration:  103 ----->Partial loss: 0.0700623\n",
      "- - - - - >Iteration:  104 ----->Partial loss: 0.0370141\n",
      "- - - - - >Iteration:  105 ----->Partial loss: 0.0565717\n",
      "- - - - - >Iteration:  106 ----->Partial loss: 0.0187606\n",
      "- - - - - >Iteration:  107 ----->Partial loss: 0.0652033\n",
      "- - - - - >Iteration:  108 ----->Partial loss: 0.0390712\n",
      "- - - - - >Iteration:  109 ----->Partial loss: 0.0624503\n",
      "- - - - - >Iteration:  110 ----->Partial loss: 0.0351839\n",
      "- - - - - >Iteration:  111 ----->Partial loss: 0.0243815\n",
      "- - - - - >Iteration:  112 ----->Partial loss: 0.0290534\n",
      "- - - - - >Iteration:  113 ----->Partial loss: 0.0699523\n",
      "- - - - - >Iteration:  114 ----->Partial loss: 0.0400414\n",
      "- - - - - >Iteration:  115 ----->Partial loss: 0.0525788\n",
      "- - - - - >Iteration:  116 ----->Partial loss: 0.0424155\n",
      "- - - - - >Iteration:  117 ----->Partial loss: 0.0976013\n",
      "- - - - - >Iteration:  118 ----->Partial loss: 0.0459095\n",
      "- - - - - >Iteration:  119 ----->Partial loss: 0.0362176\n",
      "- - - - - >Iteration:  120 ----->Partial loss: 0.0209955\n",
      "- - - - - >Iteration:  121 ----->Partial loss: 0.0417379\n",
      "- - - - - >Iteration:  122 ----->Partial loss: 0.170323\n",
      "- - - - - >Iteration:  123 ----->Partial loss: 0.0493674\n",
      "- - - - - >Iteration:  124 ----->Partial loss: 0.0446556\n",
      "- - - - - >Iteration:  125 ----->Partial loss: 0.0382427\n",
      "- - - - - >Iteration:  126 ----->Partial loss: 0.0197286\n",
      "- - - - - >Iteration:  127 ----->Partial loss: 0.0607203\n",
      "- - - - - >Iteration:  128 ----->Partial loss: 0.0618667\n",
      "- - - - - >Iteration:  129 ----->Partial loss: 0.0281784\n",
      "- - - - - >Iteration:  130 ----->Partial loss: 0.0796539\n",
      "- - - - - >Iteration:  131 ----->Partial loss: 0.0769087\n",
      "- - - - - >Iteration:  132 ----->Partial loss: 0.0274396\n",
      "- - - - - >Iteration:  133 ----->Partial loss: 0.0473009\n",
      "- - - - - >Iteration:  134 ----->Partial loss: 0.0256316\n",
      "- - - - - >Iteration:  135 ----->Partial loss: 0.0505745\n",
      "- - - - - >Iteration:  136 ----->Partial loss: 0.0221645\n",
      "- - - - - >Iteration:  137 ----->Partial loss: 0.0658558\n",
      "- - - - - >Iteration:  138 ----->Partial loss: 0.0460287\n",
      "- - - - - >Iteration:  139 ----->Partial loss: 0.0255146\n",
      "- - - - - >Iteration:  140 ----->Partial loss: 0.0390176\n",
      "- - - - - >Iteration:  141 ----->Partial loss: 0.0214351\n",
      "- - - - - >Iteration:  142 ----->Partial loss: 0.133741\n",
      "- - - - - >Iteration:  143 ----->Partial loss: 0.0423115\n",
      "- - - - - >Iteration:  144 ----->Partial loss: 0.0244304\n",
      "- - - - - >Iteration:  145 ----->Partial loss: 0.033811\n",
      "- - - - - >Iteration:  146 ----->Partial loss: 0.0243108\n",
      "- - - - - >Iteration:  147 ----->Partial loss: 0.0680021\n",
      "- - - - - >Iteration:  148 ----->Partial loss: 0.0679838\n",
      "- - - - - >Iteration:  149 ----->Partial loss: 0.0317643\n",
      "- - - - - >Iteration:  150 ----->Partial loss: 0.0517758\n",
      "- - - - - >Iteration:  151 ----->Partial loss: 0.0226564\n",
      "- - - - - >Iteration:  152 ----->Partial loss: 0.0367141\n",
      "- - - - - >Iteration:  153 ----->Partial loss: 0.0161493\n",
      "- - - - - >Iteration:  154 ----->Partial loss: 0.0261538\n",
      "- - - - - >Iteration:  155 ----->Partial loss: 0.0292832\n",
      "- - - - - >Iteration:  156 ----->Partial loss: 0.0337851\n",
      "- - - - - >Iteration:  157 ----->Partial loss: 0.0431404\n",
      "- - - - - >Iteration:  158 ----->Partial loss: 0.0748877\n",
      "- - - - - >Iteration:  159 ----->Partial loss: 0.141414\n",
      "- - - - - >Iteration:  160 ----->Partial loss: 0.0389849\n",
      "- - - - - >Iteration:  161 ----->Partial loss: 0.047747\n",
      "- - - - - >Iteration:  162 ----->Partial loss: 0.0212241\n",
      "- - - - - >Iteration:  163 ----->Partial loss: 0.0603265\n",
      "- - - - - >Iteration:  164 ----->Partial loss: 0.041181\n",
      "- - - - - >Iteration:  165 ----->Partial loss: 0.0646497\n",
      "- - - - - >Iteration:  166 ----->Partial loss: 0.0475362\n",
      "- - - - - >Iteration:  167 ----->Partial loss: 0.0399772\n",
      "- - - - - >Iteration:  168 ----->Partial loss: 0.0290369\n",
      "- - - - - >Iteration:  169 ----->Partial loss: 0.0872979\n",
      "- - - - - >Iteration:  170 ----->Partial loss: 0.0432539\n",
      "- - - - - >Iteration:  171 ----->Partial loss: 0.0879823\n",
      "- - - - - >Iteration:  172 ----->Partial loss: 0.0374934\n",
      "- - - - - >Iteration:  173 ----->Partial loss: 0.0272068\n",
      "- - - - - >Iteration:  174 ----->Partial loss: 0.0573612\n",
      "- - - - - >Iteration:  175 ----->Partial loss: 0.0302387\n",
      "- - - - - >Iteration:  176 ----->Partial loss: 0.0180416\n",
      "- - - - - >Iteration:  177 ----->Partial loss: 0.0287827\n",
      "- - - - - >Iteration:  178 ----->Partial loss: 0.0310232\n",
      "- - - - - >Iteration:  179 ----->Partial loss: 0.0171348\n",
      "- - - - - >Iteration:  180 ----->Partial loss: 0.0634011\n",
      "- - - - - >Iteration:  181 ----->Partial loss: 0.044513\n",
      "- - - - - >Iteration:  182 ----->Partial loss: 0.0131398\n",
      "- - - - - >Iteration:  183 ----->Partial loss: 0.043751\n",
      "- - - - - >Iteration:  184 ----->Partial loss: 0.0649831\n",
      "- - - - - >Iteration:  185 ----->Partial loss: 0.0203578\n",
      "- - - - - >Iteration:  186 ----->Partial loss: 0.0303344\n",
      "- - - - - >Iteration:  187 ----->Partial loss: 0.0868232\n",
      "- - - - - >Iteration:  188 ----->Partial loss: 0.0692816\n",
      "- - - - - >Iteration:  189 ----->Partial loss: 0.0448197\n",
      "- - - - - >Iteration:  190 ----->Partial loss: 0.0272446\n",
      "- - - - - >Iteration:  191 ----->Partial loss: 0.0227527\n",
      "- - - - - >Iteration:  192 ----->Partial loss: 0.0657474\n",
      "- - - - - >Iteration:  193 ----->Partial loss: 0.0516973\n",
      "- - - - - >Iteration:  194 ----->Partial loss: 0.0486144\n",
      "- - - - - >Iteration:  195 ----->Partial loss: 0.0269008\n",
      "- - - - - >Iteration:  196 ----->Partial loss: 0.0549638\n",
      "- - - - - >Iteration:  197 ----->Partial loss: 0.0494368\n",
      "- - - - - >Iteration:  198 ----->Partial loss: 0.0190658\n",
      "- - - - - >Iteration:  199 ----->Partial loss: 0.0739687\n",
      "- - - - - >Iteration:  200 ----->Partial loss: 0.0535371\n",
      "- - - - - >Iteration:  201 ----->Partial loss: 0.0215218\n",
      "- - - - - >Iteration:  202 ----->Partial loss: 0.0222539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- - - - - >Iteration:  203 ----->Partial loss: 0.0629172\n",
      "- - - - - >Iteration:  204 ----->Partial loss: 0.0633882\n",
      "- - - - - >Iteration:  205 ----->Partial loss: 0.0296088\n",
      "- - - - - >Iteration:  206 ----->Partial loss: 0.0698123\n",
      "- - - - - >Iteration:  207 ----->Partial loss: 0.0247773\n",
      "- - - - - >Iteration:  208 ----->Partial loss: 0.0415263\n",
      "- - - - - >Iteration:  209 ----->Partial loss: 0.0423466\n",
      "- - - - - >Iteration:  210 ----->Partial loss: 0.0523625\n",
      "- - - - - >Iteration:  211 ----->Partial loss: 0.0176036\n",
      "- - - - - >Iteration:  212 ----->Partial loss: 0.0656363\n",
      "- - - - - >Iteration:  213 ----->Partial loss: 0.0554245\n",
      "- - - - - >Iteration:  214 ----->Partial loss: 0.0680479\n",
      "- - - - - >Iteration:  215 ----->Partial loss: 0.0307445\n",
      "- - - - - >Iteration:  216 ----->Partial loss: 0.0580732\n",
      "- - - - - >Iteration:  217 ----->Partial loss: 0.0185473\n",
      "- - - - - >Iteration:  218 ----->Partial loss: 0.0512995\n",
      "- - - - - >Iteration:  219 ----->Partial loss: 0.0353344\n",
      "- - - - - >Iteration:  220 ----->Partial loss: 0.0623347\n",
      "- - - - - >Iteration:  221 ----->Partial loss: 0.028117\n",
      "- - - - - >Iteration:  222 ----->Partial loss: 0.0346423\n",
      "- - - - - >Iteration:  223 ----->Partial loss: 0.0163397\n",
      "- - - - - >Iteration:  224 ----->Partial loss: 0.0695513\n",
      "- - - - - >Iteration:  225 ----->Partial loss: 0.022067\n",
      "- - - - - >Iteration:  226 ----->Partial loss: 0.0333025\n",
      "- - - - - >Iteration:  227 ----->Partial loss: 0.0441381\n",
      "- - - - - >Iteration:  228 ----->Partial loss: 0.0229094\n",
      "- - - - - >Iteration:  229 ----->Partial loss: 0.0425253\n",
      "- - - - - >Iteration:  230 ----->Partial loss: 0.0550893\n",
      "- - - - - >Iteration:  231 ----->Partial loss: 0.0165597\n",
      "- - - - - >Iteration:  232 ----->Partial loss: 0.0324366\n",
      "- - - - - >Iteration:  233 ----->Partial loss: 0.0805066\n",
      "- - - - - >Iteration:  234 ----->Partial loss: 0.0164392\n",
      "- - - - - >Iteration:  235 ----->Partial loss: 0.0192323\n",
      "- - - - - >Iteration:  236 ----->Partial loss: 0.0394116\n",
      "- - - - - >Iteration:  237 ----->Partial loss: 0.0306012\n",
      "- - - - - >Iteration:  238 ----->Partial loss: 0.0474371\n",
      "- - - - - >Iteration:  239 ----->Partial loss: 0.08759\n",
      "- - - - - >Iteration:  240 ----->Partial loss: 0.0618952\n",
      "- - - - - >Iteration:  241 ----->Partial loss: 0.0340115\n",
      "- - - - - >Iteration:  242 ----->Partial loss: 0.082574\n",
      "- - - - - >Iteration:  243 ----->Partial loss: 0.0476884\n",
      "- - - - - >Iteration:  244 ----->Partial loss: 0.0448714\n",
      "- - - - - >Iteration:  245 ----->Partial loss: 0.0589014\n",
      "- - - - - >Iteration:  246 ----->Partial loss: 0.0337296\n",
      "- - - - - >Iteration:  247 ----->Partial loss: 0.0382909\n",
      "- - - - - >Iteration:  248 ----->Partial loss: 0.0661149\n",
      "- - - - - >Iteration:  249 ----->Partial loss: 0.0526545\n",
      "- - - - - >Iteration:  250 ----->Partial loss: 0.0220248\n",
      "- - - - - >Iteration:  251 ----->Partial loss: 0.0335329\n",
      "- - - - - >Iteration:  252 ----->Partial loss: 0.0564541\n",
      "- - - - - >Iteration:  253 ----->Partial loss: 0.0195621\n",
      "- - - - - >Iteration:  254 ----->Partial loss: 0.0335089\n",
      "- - - - - >Iteration:  255 ----->Partial loss: 0.0501342\n",
      "- - - - - >Iteration:  256 ----->Partial loss: 0.0870982\n",
      "- - - - - >Iteration:  257 ----->Partial loss: 0.0294244\n",
      "- - - - - >Iteration:  258 ----->Partial loss: 0.0300084\n",
      "- - - - - >Iteration:  259 ----->Partial loss: 0.0455597\n",
      "- - - - - >Iteration:  260 ----->Partial loss: 0.120953\n",
      "- - - - - >Iteration:  261 ----->Partial loss: 0.0205641\n",
      "- - - - - >Iteration:  262 ----->Partial loss: 0.0203355\n",
      "- - - - - >Iteration:  263 ----->Partial loss: 0.0687497\n",
      "- - - - - >Iteration:  264 ----->Partial loss: 0.0254977\n",
      "- - - - - >Iteration:  265 ----->Partial loss: 0.0511071\n",
      "- - - - - >Iteration:  266 ----->Partial loss: 0.0566018\n",
      "- - - - - >Iteration:  267 ----->Partial loss: 0.0531979\n",
      "- - - - - >Iteration:  268 ----->Partial loss: 0.0534387\n",
      "- - - - - >Iteration:  269 ----->Partial loss: 0.0337915\n",
      "- - - - - >Iteration:  270 ----->Partial loss: 0.0200067\n",
      "- - - - - >Iteration:  271 ----->Partial loss: 0.076994\n",
      "- - - - - >Iteration:  272 ----->Partial loss: 0.0827893\n",
      "- - - - - >Iteration:  273 ----->Partial loss: 0.0313157\n",
      "- - - - - >Iteration:  274 ----->Partial loss: 0.0200171\n",
      "- - - - - >Iteration:  275 ----->Partial loss: 0.0491502\n",
      "- - - - - >Iteration:  276 ----->Partial loss: 0.0356926\n",
      "- - - - - >Iteration:  277 ----->Partial loss: 0.0418078\n",
      "- - - - - >Iteration:  278 ----->Partial loss: 0.0670892\n",
      "- - - - - >Iteration:  279 ----->Partial loss: 0.0410148\n",
      "- - - - - >Iteration:  280 ----->Partial loss: 0.0199627\n",
      "- - - - - >Iteration:  281 ----->Partial loss: 0.0172505\n",
      "- - - - - >Iteration:  282 ----->Partial loss: 0.125416\n",
      "- - - - - >Iteration:  283 ----->Partial loss: 0.0255307\n",
      "- - - - - >Iteration:  284 ----->Partial loss: 0.0347724\n",
      "- - - - - >Iteration:  285 ----->Partial loss: 0.0291261\n",
      "- - - - - >Iteration:  286 ----->Partial loss: 0.0310783\n",
      "- - - - - >Iteration:  287 ----->Partial loss: 0.0589424\n",
      "- - - - - >Iteration:  288 ----->Partial loss: 0.0439004\n",
      "- - - - - >Iteration:  289 ----->Partial loss: 0.0245547\n",
      "***************\n",
      "Epoch:  19  of  20 training loss:  0.0458486946461\n",
      "***************\n",
      "- - - - - >Iteration:  1 ----->Partial loss: 0.0674719\n",
      "- - - - - >Iteration:  2 ----->Partial loss: 0.0191913\n",
      "- - - - - >Iteration:  3 ----->Partial loss: 0.0685273\n",
      "- - - - - >Iteration:  4 ----->Partial loss: 0.02843\n",
      "- - - - - >Iteration:  5 ----->Partial loss: 0.0464097\n",
      "- - - - - >Iteration:  6 ----->Partial loss: 0.0273066\n",
      "- - - - - >Iteration:  7 ----->Partial loss: 0.0431428\n",
      "- - - - - >Iteration:  8 ----->Partial loss: 0.0445696\n",
      "- - - - - >Iteration:  9 ----->Partial loss: 0.0203998\n",
      "- - - - - >Iteration:  10 ----->Partial loss: 0.0314941\n",
      "- - - - - >Iteration:  11 ----->Partial loss: 0.0211623\n",
      "- - - - - >Iteration:  12 ----->Partial loss: 0.0204651\n",
      "- - - - - >Iteration:  13 ----->Partial loss: 0.100472\n",
      "- - - - - >Iteration:  14 ----->Partial loss: 0.0308361\n",
      "- - - - - >Iteration:  15 ----->Partial loss: 0.0374581\n",
      "- - - - - >Iteration:  16 ----->Partial loss: 0.0230789\n",
      "- - - - - >Iteration:  17 ----->Partial loss: 0.0450122\n",
      "- - - - - >Iteration:  18 ----->Partial loss: 0.0651627\n",
      "- - - - - >Iteration:  19 ----->Partial loss: 0.03372\n",
      "- - - - - >Iteration:  20 ----->Partial loss: 0.0230228\n",
      "- - - - - >Iteration:  21 ----->Partial loss: 0.0533476\n",
      "- - - - - >Iteration:  22 ----->Partial loss: 0.0603428\n",
      "- - - - - >Iteration:  23 ----->Partial loss: 0.0618994\n",
      "- - - - - >Iteration:  24 ----->Partial loss: 0.0196867\n",
      "- - - - - >Iteration:  25 ----->Partial loss: 0.0586551\n",
      "- - - - - >Iteration:  26 ----->Partial loss: 0.0279807\n",
      "- - - - - >Iteration:  27 ----->Partial loss: 0.033218\n",
      "- - - - - >Iteration:  28 ----->Partial loss: 0.0566801\n",
      "- - - - - >Iteration:  29 ----->Partial loss: 0.0599395\n",
      "- - - - - >Iteration:  30 ----->Partial loss: 0.036512\n",
      "- - - - - >Iteration:  31 ----->Partial loss: 0.0558193\n",
      "- - - - - >Iteration:  32 ----->Partial loss: 0.0321856\n",
      "- - - - - >Iteration:  33 ----->Partial loss: 0.0236847\n",
      "- - - - - >Iteration:  34 ----->Partial loss: 0.0674759\n",
      "- - - - - >Iteration:  35 ----->Partial loss: 0.0798121\n",
      "- - - - - >Iteration:  36 ----->Partial loss: 0.0685161\n",
      "- - - - - >Iteration:  37 ----->Partial loss: 0.01848\n",
      "- - - - - >Iteration:  38 ----->Partial loss: 0.0431039\n",
      "- - - - - >Iteration:  39 ----->Partial loss: 0.0688413\n",
      "- - - - - >Iteration:  40 ----->Partial loss: 0.0593461\n",
      "- - - - - >Iteration:  41 ----->Partial loss: 0.0624749\n",
      "- - - - - >Iteration:  42 ----->Partial loss: 0.0628826\n",
      "- - - - - >Iteration:  43 ----->Partial loss: 0.0366035\n",
      "- - - - - >Iteration:  44 ----->Partial loss: 0.07142\n",
      "- - - - - >Iteration:  45 ----->Partial loss: 0.0299582\n",
      "- - - - - >Iteration:  46 ----->Partial loss: 0.0320009\n",
      "- - - - - >Iteration:  47 ----->Partial loss: 0.0133764\n",
      "- - - - - >Iteration:  48 ----->Partial loss: 0.0681297\n",
      "- - - - - >Iteration:  49 ----->Partial loss: 0.0364767\n",
      "- - - - - >Iteration:  50 ----->Partial loss: 0.0405051\n",
      "- - - - - >Iteration:  51 ----->Partial loss: 0.0219961\n",
      "- - - - - >Iteration:  52 ----->Partial loss: 0.0457544\n",
      "- - - - - >Iteration:  53 ----->Partial loss: 0.0674371\n",
      "- - - - - >Iteration:  54 ----->Partial loss: 0.0205303\n",
      "- - - - - >Iteration:  55 ----->Partial loss: 0.0638957\n",
      "- - - - - >Iteration:  56 ----->Partial loss: 0.0388172\n",
      "- - - - - >Iteration:  57 ----->Partial loss: 0.02822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- - - - - >Iteration:  58 ----->Partial loss: 0.0149648\n",
      "- - - - - >Iteration:  59 ----->Partial loss: 0.0638513\n",
      "- - - - - >Iteration:  60 ----->Partial loss: 0.042743\n",
      "- - - - - >Iteration:  61 ----->Partial loss: 0.0412068\n",
      "- - - - - >Iteration:  62 ----->Partial loss: 0.0476743\n",
      "- - - - - >Iteration:  63 ----->Partial loss: 0.0480848\n",
      "- - - - - >Iteration:  64 ----->Partial loss: 0.0244154\n",
      "- - - - - >Iteration:  65 ----->Partial loss: 0.0173098\n",
      "- - - - - >Iteration:  66 ----->Partial loss: 0.0572133\n",
      "- - - - - >Iteration:  67 ----->Partial loss: 0.0247849\n",
      "- - - - - >Iteration:  68 ----->Partial loss: 0.0366062\n",
      "- - - - - >Iteration:  69 ----->Partial loss: 0.0307824\n",
      "- - - - - >Iteration:  70 ----->Partial loss: 0.0427546\n",
      "- - - - - >Iteration:  71 ----->Partial loss: 0.0539688\n",
      "- - - - - >Iteration:  72 ----->Partial loss: 0.0971707\n",
      "- - - - - >Iteration:  73 ----->Partial loss: 0.0290373\n",
      "- - - - - >Iteration:  74 ----->Partial loss: 0.0263919\n",
      "- - - - - >Iteration:  75 ----->Partial loss: 0.0217156\n",
      "- - - - - >Iteration:  76 ----->Partial loss: 0.0308354\n",
      "- - - - - >Iteration:  77 ----->Partial loss: 0.0593552\n",
      "- - - - - >Iteration:  78 ----->Partial loss: 0.0413319\n",
      "- - - - - >Iteration:  79 ----->Partial loss: 0.0202445\n",
      "- - - - - >Iteration:  80 ----->Partial loss: 0.0485202\n",
      "- - - - - >Iteration:  81 ----->Partial loss: 0.0155973\n",
      "- - - - - >Iteration:  82 ----->Partial loss: 0.0423535\n",
      "- - - - - >Iteration:  83 ----->Partial loss: 0.0159341\n",
      "- - - - - >Iteration:  84 ----->Partial loss: 0.0623547\n",
      "- - - - - >Iteration:  85 ----->Partial loss: 0.0190125\n",
      "- - - - - >Iteration:  86 ----->Partial loss: 0.0422493\n",
      "- - - - - >Iteration:  87 ----->Partial loss: 0.0416792\n",
      "- - - - - >Iteration:  88 ----->Partial loss: 0.0250341\n",
      "- - - - - >Iteration:  89 ----->Partial loss: 0.0174981\n",
      "- - - - - >Iteration:  90 ----->Partial loss: 0.0653793\n",
      "- - - - - >Iteration:  91 ----->Partial loss: 0.0144792\n",
      "- - - - - >Iteration:  92 ----->Partial loss: 0.0656361\n",
      "- - - - - >Iteration:  93 ----->Partial loss: 0.0502317\n",
      "- - - - - >Iteration:  94 ----->Partial loss: 0.0520447\n",
      "- - - - - >Iteration:  95 ----->Partial loss: 0.0474078\n",
      "- - - - - >Iteration:  96 ----->Partial loss: 0.0199767\n",
      "- - - - - >Iteration:  97 ----->Partial loss: 0.0512461\n",
      "- - - - - >Iteration:  98 ----->Partial loss: 0.0183805\n",
      "- - - - - >Iteration:  99 ----->Partial loss: 0.0369199\n",
      "- - - - - >Iteration:  100 ----->Partial loss: 0.0267808\n",
      "- - - - - >Iteration:  101 ----->Partial loss: 0.0371589\n",
      "- - - - - >Iteration:  102 ----->Partial loss: 0.0141487\n",
      "- - - - - >Iteration:  103 ----->Partial loss: 0.0176964\n",
      "- - - - - >Iteration:  104 ----->Partial loss: 0.0782533\n",
      "- - - - - >Iteration:  105 ----->Partial loss: 0.058414\n",
      "- - - - - >Iteration:  106 ----->Partial loss: 0.037915\n",
      "- - - - - >Iteration:  107 ----->Partial loss: 0.0659276\n",
      "- - - - - >Iteration:  108 ----->Partial loss: 0.0341044\n",
      "- - - - - >Iteration:  109 ----->Partial loss: 0.0386102\n",
      "- - - - - >Iteration:  110 ----->Partial loss: 0.046568\n",
      "- - - - - >Iteration:  111 ----->Partial loss: 0.0406894\n",
      "- - - - - >Iteration:  112 ----->Partial loss: 0.0584325\n",
      "- - - - - >Iteration:  113 ----->Partial loss: 0.0373307\n",
      "- - - - - >Iteration:  114 ----->Partial loss: 0.0293941\n",
      "- - - - - >Iteration:  115 ----->Partial loss: 0.0184876\n",
      "- - - - - >Iteration:  116 ----->Partial loss: 0.0820637\n",
      "- - - - - >Iteration:  117 ----->Partial loss: 0.0265072\n",
      "- - - - - >Iteration:  118 ----->Partial loss: 0.0313568\n",
      "- - - - - >Iteration:  119 ----->Partial loss: 0.0274371\n",
      "- - - - - >Iteration:  120 ----->Partial loss: 0.043596\n",
      "- - - - - >Iteration:  121 ----->Partial loss: 0.0731488\n",
      "- - - - - >Iteration:  122 ----->Partial loss: 0.0843906\n",
      "- - - - - >Iteration:  123 ----->Partial loss: 0.0422378\n",
      "- - - - - >Iteration:  124 ----->Partial loss: 0.0756964\n",
      "- - - - - >Iteration:  125 ----->Partial loss: 0.0223662\n",
      "- - - - - >Iteration:  126 ----->Partial loss: 0.0329984\n",
      "- - - - - >Iteration:  127 ----->Partial loss: 0.0460585\n",
      "- - - - - >Iteration:  128 ----->Partial loss: 0.0649458\n",
      "- - - - - >Iteration:  129 ----->Partial loss: 0.0454776\n",
      "- - - - - >Iteration:  130 ----->Partial loss: 0.0222063\n",
      "- - - - - >Iteration:  131 ----->Partial loss: 0.0432986\n",
      "- - - - - >Iteration:  132 ----->Partial loss: 0.0562818\n",
      "- - - - - >Iteration:  133 ----->Partial loss: 0.0400383\n",
      "- - - - - >Iteration:  134 ----->Partial loss: 0.0676112\n",
      "- - - - - >Iteration:  135 ----->Partial loss: 0.052515\n",
      "- - - - - >Iteration:  136 ----->Partial loss: 0.0255223\n",
      "- - - - - >Iteration:  137 ----->Partial loss: 0.0424667\n",
      "- - - - - >Iteration:  138 ----->Partial loss: 0.0370289\n",
      "- - - - - >Iteration:  139 ----->Partial loss: 0.0289099\n",
      "- - - - - >Iteration:  140 ----->Partial loss: 0.0580903\n",
      "- - - - - >Iteration:  141 ----->Partial loss: 0.0210798\n",
      "- - - - - >Iteration:  142 ----->Partial loss: 0.0524045\n",
      "- - - - - >Iteration:  143 ----->Partial loss: 0.0236423\n",
      "- - - - - >Iteration:  144 ----->Partial loss: 0.138776\n",
      "- - - - - >Iteration:  145 ----->Partial loss: 0.0515485\n",
      "- - - - - >Iteration:  146 ----->Partial loss: 0.0365501\n",
      "- - - - - >Iteration:  147 ----->Partial loss: 0.0391364\n",
      "- - - - - >Iteration:  148 ----->Partial loss: 0.0152747\n",
      "- - - - - >Iteration:  149 ----->Partial loss: 0.0539442\n",
      "- - - - - >Iteration:  150 ----->Partial loss: 0.0830435\n",
      "- - - - - >Iteration:  151 ----->Partial loss: 0.0248715\n",
      "- - - - - >Iteration:  152 ----->Partial loss: 0.0590406\n",
      "- - - - - >Iteration:  153 ----->Partial loss: 0.0259198\n",
      "- - - - - >Iteration:  154 ----->Partial loss: 0.032655\n",
      "- - - - - >Iteration:  155 ----->Partial loss: 0.0259969\n",
      "- - - - - >Iteration:  156 ----->Partial loss: 0.0273229\n",
      "- - - - - >Iteration:  157 ----->Partial loss: 0.0462329\n",
      "- - - - - >Iteration:  158 ----->Partial loss: 0.0369637\n",
      "- - - - - >Iteration:  159 ----->Partial loss: 0.0904331\n",
      "- - - - - >Iteration:  160 ----->Partial loss: 0.071442\n",
      "- - - - - >Iteration:  161 ----->Partial loss: 0.0271859\n",
      "- - - - - >Iteration:  162 ----->Partial loss: 0.0266859\n",
      "- - - - - >Iteration:  163 ----->Partial loss: 0.0251444\n",
      "- - - - - >Iteration:  164 ----->Partial loss: 0.0389484\n",
      "- - - - - >Iteration:  165 ----->Partial loss: 0.164013\n",
      "- - - - - >Iteration:  166 ----->Partial loss: 0.0220313\n",
      "- - - - - >Iteration:  167 ----->Partial loss: 0.0169181\n",
      "- - - - - >Iteration:  168 ----->Partial loss: 0.0185526\n",
      "- - - - - >Iteration:  169 ----->Partial loss: 0.0528596\n",
      "- - - - - >Iteration:  170 ----->Partial loss: 0.032148\n",
      "- - - - - >Iteration:  171 ----->Partial loss: 0.0234659\n",
      "- - - - - >Iteration:  172 ----->Partial loss: 0.0629596\n",
      "- - - - - >Iteration:  173 ----->Partial loss: 0.0710197\n",
      "- - - - - >Iteration:  174 ----->Partial loss: 0.0484303\n",
      "- - - - - >Iteration:  175 ----->Partial loss: 0.0209429\n",
      "- - - - - >Iteration:  176 ----->Partial loss: 0.0183341\n",
      "- - - - - >Iteration:  177 ----->Partial loss: 0.0279296\n",
      "- - - - - >Iteration:  178 ----->Partial loss: 0.039004\n",
      "- - - - - >Iteration:  179 ----->Partial loss: 0.041963\n",
      "- - - - - >Iteration:  180 ----->Partial loss: 0.0393672\n",
      "- - - - - >Iteration:  181 ----->Partial loss: 0.0497764\n",
      "- - - - - >Iteration:  182 ----->Partial loss: 0.0256274\n",
      "- - - - - >Iteration:  183 ----->Partial loss: 0.0355602\n",
      "- - - - - >Iteration:  184 ----->Partial loss: 0.0274708\n",
      "- - - - - >Iteration:  185 ----->Partial loss: 0.0509929\n",
      "- - - - - >Iteration:  186 ----->Partial loss: 0.0607946\n",
      "- - - - - >Iteration:  187 ----->Partial loss: 0.0354799\n",
      "- - - - - >Iteration:  188 ----->Partial loss: 0.0195967\n",
      "- - - - - >Iteration:  189 ----->Partial loss: 0.0243823\n",
      "- - - - - >Iteration:  190 ----->Partial loss: 0.0210763\n",
      "- - - - - >Iteration:  191 ----->Partial loss: 0.040782\n",
      "- - - - - >Iteration:  192 ----->Partial loss: 0.036768\n",
      "- - - - - >Iteration:  193 ----->Partial loss: 0.0345366\n",
      "- - - - - >Iteration:  194 ----->Partial loss: 0.0235753\n",
      "- - - - - >Iteration:  195 ----->Partial loss: 0.0391034\n",
      "- - - - - >Iteration:  196 ----->Partial loss: 0.0218464\n",
      "- - - - - >Iteration:  197 ----->Partial loss: 0.0247215\n",
      "- - - - - >Iteration:  198 ----->Partial loss: 0.0250151\n",
      "- - - - - >Iteration:  199 ----->Partial loss: 0.0623835\n",
      "- - - - - >Iteration:  200 ----->Partial loss: 0.0161675\n",
      "- - - - - >Iteration:  201 ----->Partial loss: 0.0306015\n",
      "- - - - - >Iteration:  202 ----->Partial loss: 0.0506661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- - - - - >Iteration:  203 ----->Partial loss: 0.0508945\n",
      "- - - - - >Iteration:  204 ----->Partial loss: 0.0316139\n",
      "- - - - - >Iteration:  205 ----->Partial loss: 0.0428977\n",
      "- - - - - >Iteration:  206 ----->Partial loss: 0.0753169\n",
      "- - - - - >Iteration:  207 ----->Partial loss: 0.0605241\n",
      "- - - - - >Iteration:  208 ----->Partial loss: 0.0431367\n",
      "- - - - - >Iteration:  209 ----->Partial loss: 0.064796\n",
      "- - - - - >Iteration:  210 ----->Partial loss: 0.053781\n",
      "- - - - - >Iteration:  211 ----->Partial loss: 0.0463295\n",
      "- - - - - >Iteration:  212 ----->Partial loss: 0.0537562\n",
      "- - - - - >Iteration:  213 ----->Partial loss: 0.0289772\n",
      "- - - - - >Iteration:  214 ----->Partial loss: 0.0752088\n",
      "- - - - - >Iteration:  215 ----->Partial loss: 0.0411044\n",
      "- - - - - >Iteration:  216 ----->Partial loss: 0.0308116\n",
      "- - - - - >Iteration:  217 ----->Partial loss: 0.0191307\n",
      "- - - - - >Iteration:  218 ----->Partial loss: 0.0509622\n",
      "- - - - - >Iteration:  219 ----->Partial loss: 0.067949\n",
      "- - - - - >Iteration:  220 ----->Partial loss: 0.02895\n",
      "- - - - - >Iteration:  221 ----->Partial loss: 0.0332607\n",
      "- - - - - >Iteration:  222 ----->Partial loss: 0.0268471\n",
      "- - - - - >Iteration:  223 ----->Partial loss: 0.0199426\n",
      "- - - - - >Iteration:  224 ----->Partial loss: 0.0173327\n",
      "- - - - - >Iteration:  225 ----->Partial loss: 0.0474586\n",
      "- - - - - >Iteration:  226 ----->Partial loss: 0.0461449\n",
      "- - - - - >Iteration:  227 ----->Partial loss: 0.124467\n",
      "- - - - - >Iteration:  228 ----->Partial loss: 0.0172154\n",
      "- - - - - >Iteration:  229 ----->Partial loss: 0.0418939\n",
      "- - - - - >Iteration:  230 ----->Partial loss: 0.049481\n",
      "- - - - - >Iteration:  231 ----->Partial loss: 0.0396071\n",
      "- - - - - >Iteration:  232 ----->Partial loss: 0.0265701\n",
      "- - - - - >Iteration:  233 ----->Partial loss: 0.0826187\n",
      "- - - - - >Iteration:  234 ----->Partial loss: 0.0434829\n",
      "- - - - - >Iteration:  235 ----->Partial loss: 0.131587\n",
      "- - - - - >Iteration:  236 ----->Partial loss: 0.0410269\n",
      "- - - - - >Iteration:  237 ----->Partial loss: 0.0343798\n",
      "- - - - - >Iteration:  238 ----->Partial loss: 0.0298476\n",
      "- - - - - >Iteration:  239 ----->Partial loss: 0.0584973\n",
      "- - - - - >Iteration:  240 ----->Partial loss: 0.0232765\n",
      "- - - - - >Iteration:  241 ----->Partial loss: 0.0453895\n",
      "- - - - - >Iteration:  242 ----->Partial loss: 0.065223\n",
      "- - - - - >Iteration:  243 ----->Partial loss: 0.0255697\n",
      "- - - - - >Iteration:  244 ----->Partial loss: 0.0260916\n",
      "- - - - - >Iteration:  245 ----->Partial loss: 0.026434\n",
      "- - - - - >Iteration:  246 ----->Partial loss: 0.0251665\n",
      "- - - - - >Iteration:  247 ----->Partial loss: 0.0266927\n",
      "- - - - - >Iteration:  248 ----->Partial loss: 0.0181674\n",
      "- - - - - >Iteration:  249 ----->Partial loss: 0.0742804\n",
      "- - - - - >Iteration:  250 ----->Partial loss: 0.0394266\n",
      "- - - - - >Iteration:  251 ----->Partial loss: 0.0414255\n",
      "- - - - - >Iteration:  252 ----->Partial loss: 0.0967944\n",
      "- - - - - >Iteration:  253 ----->Partial loss: 0.0596428\n",
      "- - - - - >Iteration:  254 ----->Partial loss: 0.0555192\n",
      "- - - - - >Iteration:  255 ----->Partial loss: 0.104256\n",
      "- - - - - >Iteration:  256 ----->Partial loss: 0.0418618\n",
      "- - - - - >Iteration:  257 ----->Partial loss: 0.0416693\n",
      "- - - - - >Iteration:  258 ----->Partial loss: 0.0370489\n",
      "- - - - - >Iteration:  259 ----->Partial loss: 0.0586612\n",
      "- - - - - >Iteration:  260 ----->Partial loss: 0.054154\n",
      "- - - - - >Iteration:  261 ----->Partial loss: 0.0497689\n",
      "- - - - - >Iteration:  262 ----->Partial loss: 0.0602555\n",
      "- - - - - >Iteration:  263 ----->Partial loss: 0.0249189\n",
      "- - - - - >Iteration:  264 ----->Partial loss: 0.020327\n",
      "- - - - - >Iteration:  265 ----->Partial loss: 0.0186609\n",
      "- - - - - >Iteration:  266 ----->Partial loss: 0.0849279\n",
      "- - - - - >Iteration:  267 ----->Partial loss: 0.0206035\n",
      "- - - - - >Iteration:  268 ----->Partial loss: 0.0146175\n",
      "- - - - - >Iteration:  269 ----->Partial loss: 0.0182353\n",
      "- - - - - >Iteration:  270 ----->Partial loss: 0.0337015\n",
      "- - - - - >Iteration:  271 ----->Partial loss: 0.0722812\n",
      "- - - - - >Iteration:  272 ----->Partial loss: 0.0366016\n",
      "- - - - - >Iteration:  273 ----->Partial loss: 0.0290374\n",
      "- - - - - >Iteration:  274 ----->Partial loss: 0.0407105\n",
      "- - - - - >Iteration:  275 ----->Partial loss: 0.0139493\n",
      "- - - - - >Iteration:  276 ----->Partial loss: 0.0272773\n",
      "- - - - - >Iteration:  277 ----->Partial loss: 0.0416159\n",
      "- - - - - >Iteration:  278 ----->Partial loss: 0.0264258\n",
      "- - - - - >Iteration:  279 ----->Partial loss: 0.039259\n",
      "- - - - - >Iteration:  280 ----->Partial loss: 0.0202117\n",
      "- - - - - >Iteration:  281 ----->Partial loss: 0.064238\n",
      "- - - - - >Iteration:  282 ----->Partial loss: 0.0742806\n",
      "- - - - - >Iteration:  283 ----->Partial loss: 0.0146004\n",
      "- - - - - >Iteration:  284 ----->Partial loss: 0.0657385\n",
      "- - - - - >Iteration:  285 ----->Partial loss: 0.0501647\n",
      "- - - - - >Iteration:  286 ----->Partial loss: 0.0580429\n",
      "- - - - - >Iteration:  287 ----->Partial loss: 0.0459948\n",
      "- - - - - >Iteration:  288 ----->Partial loss: 0.0217737\n",
      "- - - - - >Iteration:  289 ----->Partial loss: 0.0322783\n",
      "***************\n",
      "Epoch:  20  of  20 training loss:  0.0428236604001\n",
      "***************\n",
      "Training Finished. Saving test images to: ./runs/1504272994.0275266\n"
     ]
    }
   ],
   "source": [
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from b'./data/vgg/variables/variables'\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Variable layer3conv1x1/kernel already exists, disallowed. Did you mean to set reuse=True in VarScope? Originally defined at:\n\n  File \"<ipython-input-9-684fcb842599>\", line 7, in conv_1x1\n    name = layer_name)\n  File \"<ipython-input-11-97e822571b92>\", line 11, in layers\n    layer_3x = conv_1x1(layer = vgg_layer_3_out, layer_name = \"layer3conv1x1\")\n  File \"<ipython-input-16-1d5ce9f4975f>\", line 18, in run\n    model_output = layers(layer_3, layer_4, layer_7, num_classes_)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-c7b449c03ddb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnetwork_shapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-bb6ea1101e6f>\u001b[0m in \u001b[0;36mnetwork_shapes\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# Create verbose layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers_verbose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# initialize the variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-145a139143c1>\u001b[0m in \u001b[0;36mlayers_verbose\u001b[0;34m(vgg_layer_3_out, vgg_layer_4_out, vgg_layer7_out, num_classes)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \"\"\"\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Apply a 1x1 convolution to encoder layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mlayer3x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_1x1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvgg_layer_3_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"layer3conv1x1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mlayer4x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_1x1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvgg_layer_4_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"layer4conv1x1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mlayer7x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_1x1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvgg_layer7_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"layer7conv1x1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-684fcb842599>\u001b[0m in \u001b[0;36mconv_1x1\u001b[0;34m(layer, layer_name)\u001b[0m\n\u001b[1;32m      5\u001b[0m                           \u001b[0mkernel_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                           \u001b[0mstrides\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                           name = layer_name)\n\u001b[0m",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/layers/convolutional.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(inputs, filters, kernel_size, strides, padding, data_format, dilation_rate, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, trainable, name, reuse)\u001b[0m\n\u001b[1;32m    549\u001b[0m       \u001b[0m_reuse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreuse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m       _scope=name)\n\u001b[0;32m--> 551\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/layers/base.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    490\u001b[0m       \u001b[0mOutput\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m     \"\"\"\n\u001b[0;32m--> 492\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_assert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/layers/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    432\u001b[0m           \u001b[0minput_shapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m           \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/layers/convolutional.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    135\u001b[0m                                     \u001b[0mregularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_regularizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                                     \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m                                     dtype=self.dtype)\n\u001b[0m\u001b[1;32m    138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m       self.bias = self.add_variable(name='bias',\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/layers/base.py\u001b[0m in \u001b[0;36madd_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, trainable)\u001b[0m\n\u001b[1;32m    372\u001b[0m                                    \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m                                    \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m                                    trainable=trainable and self.trainable)\n\u001b[0m\u001b[1;32m    375\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvariable\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexisting_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mvariable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter)\u001b[0m\n\u001b[1;32m   1063\u001b[0m       \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1064\u001b[0m       \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1065\u001b[0;31m       use_resource=use_resource, custom_getter=custom_getter)\n\u001b[0m\u001b[1;32m   1066\u001b[0m get_variable_or_local_docstring = (\n\u001b[1;32m   1067\u001b[0m     \"\"\"%s\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter)\u001b[0m\n\u001b[1;32m    960\u001b[0m           \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m           \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 962\u001b[0;31m           use_resource=use_resource, custom_getter=custom_getter)\n\u001b[0m\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter)\u001b[0m\n\u001b[1;32m    365\u001b[0m           \u001b[0mreuse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreuse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m           \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m           validate_shape=validate_shape, use_resource=use_resource)\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m   def _get_partitioned_variable(\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_true_getter\u001b[0;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource)\u001b[0m\n\u001b[1;32m    350\u001b[0m           \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m           \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m           use_resource=use_resource)\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcustom_getter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_get_single_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource)\u001b[0m\n\u001b[1;32m    662\u001b[0m                          \u001b[0;34m\" Did you mean to set reuse=True in VarScope? \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m                          \"Originally defined at:\\n\\n%s\" % (\n\u001b[0;32m--> 664\u001b[0;31m                              name, \"\".join(traceback.format_list(tb))))\n\u001b[0m\u001b[1;32m    665\u001b[0m       \u001b[0mfound_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfound_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Variable layer3conv1x1/kernel already exists, disallowed. Did you mean to set reuse=True in VarScope? Originally defined at:\n\n  File \"<ipython-input-9-684fcb842599>\", line 7, in conv_1x1\n    name = layer_name)\n  File \"<ipython-input-11-97e822571b92>\", line 11, in layers\n    layer_3x = conv_1x1(layer = vgg_layer_3_out, layer_name = \"layer3conv1x1\")\n  File \"<ipython-input-16-1d5ce9f4975f>\", line 18, in run\n    model_output = layers(layer_3, layer_4, layer_7, num_classes_)\n"
     ]
    }
   ],
   "source": [
    "network_shapes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
